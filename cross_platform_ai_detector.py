#!/usr/bin/env python3
"""
ğŸŒ è·¨å¹³å°AIæª¢æ¸¬ç³»çµ±
æ”¯æŒMacBook Pro M4å’ŒSnapdragon X Eliteçš„çµ±ä¸€æ¥å£
"""

import os
import platform
import logging
from typing import Dict, Any, List, Optional
from abc import ABC, abstractmethod
import json

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PlatformDetector:
    """å¹³å°æª¢æ¸¬å™¨"""
    
    @staticmethod
    def detect_platform() -> Dict[str, str]:
        """æª¢æ¸¬ç•¶å‰é‹è¡Œå¹³å°"""
        system = platform.system().lower()
        machine = platform.machine().lower()
        processor = platform.processor().lower()
        
        platform_info = {
            "system": system,
            "machine": machine,
            "processor": processor,
            "platform_type": "unknown"
        }
        
        # MacBook Pro M4æª¢æ¸¬
        if system == "darwin" and ("arm" in machine or "arm64" in machine):
            platform_info["platform_type"] = "mac_apple_silicon"
            platform_info["ai_accelerator"] = "apple_neural_engine"
            platform_info["primary_provider"] = "CoreMLExecutionProvider"
            
        # Snapdragon X Eliteæª¢æ¸¬
        elif "snapdragon" in processor.lower() or "qualcomm" in processor.lower():
            platform_info["platform_type"] = "snapdragon_x_elite"
            platform_info["ai_accelerator"] = "hexagon_npu"
            platform_info["primary_provider"] = "QNNExecutionProvider"
            
        # Windows ARM (å¯èƒ½çš„Snapdragonè¨­å‚™)
        elif system == "windows" and ("arm" in machine or "aarch64" in machine):
            platform_info["platform_type"] = "windows_arm"
            platform_info["ai_accelerator"] = "hexagon_npu"
            platform_info["primary_provider"] = "QNNExecutionProvider"
            
        # é€šç”¨x86/x64
        elif "x86" in machine or "amd64" in machine:
            platform_info["platform_type"] = "x86_generic"
            platform_info["ai_accelerator"] = "cpu_generic"
            platform_info["primary_provider"] = "CPUExecutionProvider"
        
        return platform_info

class ONNXRuntimeManager(ABC):
    """ONNX Runtimeç®¡ç†å™¨æŠ½è±¡åŸºé¡"""
    
    def __init__(self, platform_info: Dict[str, str]):
        self.platform_info = platform_info
        self.providers = []
        self.sessions = {}
        
    @abstractmethod
    def get_providers(self) -> List[str]:
        """ç²å–ONNX Runtimeæä¾›å•†åˆ—è¡¨"""
        pass
    
    @abstractmethod
    def optimize_session_options(self) -> Any:
        """å„ªåŒ–æœƒè©±é¸é …"""
        pass

class MacONNXManager(ONNXRuntimeManager):
    """Macå¹³å°ONNX Runtimeç®¡ç†å™¨"""
    
    def get_providers(self) -> List[str]:
        """ç²å–Macå¹³å°æä¾›å•†"""
        try:
            import onnxruntime as ort
            available = ort.get_available_providers()
            
            providers = []
            if 'CoreMLExecutionProvider' in available:
                providers.append('CoreMLExecutionProvider')
                logger.info("âœ… å•Ÿç”¨Apple Neural EngineåŠ é€Ÿ")
            else:
                logger.warning("âš ï¸ CoreMLæä¾›å•†ä¸å¯ç”¨")
            
            providers.append('CPUExecutionProvider')
            logger.info("âœ… æ·»åŠ CPUå¾Œå‚™æ”¯æ´")
            
            return providers
            
        except ImportError:
            logger.error("âŒ ONNX Runtimeæœªå®‰è£")
            return ['CPUExecutionProvider']
    
    def optimize_session_options(self) -> Any:
        """Macå¹³å°æœƒè©±å„ªåŒ–"""
        try:
            import onnxruntime as ort
            
            session_options = ort.SessionOptions()
            session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
            session_options.enable_cpu_mem_arena = True
            session_options.enable_mem_pattern = True
            
            # Macç‰¹å®šå„ªåŒ–
            session_options.add_session_config_entry("session.load_model_format", "ORT")
            
            return session_options
            
        except ImportError:
            return None

class SnapdragonONNXManager(ONNXRuntimeManager):
    """Snapdragonå¹³å°ONNX Runtimeç®¡ç†å™¨"""
    
    def get_providers(self) -> List[str]:
        """ç²å–Snapdragonå¹³å°æä¾›å•†"""
        try:
            import onnxruntime as ort
            available = ort.get_available_providers()
            
            providers = []
            if 'QNNExecutionProvider' in available:
                providers.append('QNNExecutionProvider')
                logger.info("âœ… å•Ÿç”¨Qualcomm Hexagon NPUåŠ é€Ÿ")
            else:
                logger.warning("âš ï¸ QNNæä¾›å•†ä¸å¯ç”¨ï¼Œæª¢æŸ¥QNN SDKå®‰è£")
            
            providers.append('CPUExecutionProvider')
            logger.info("âœ… æ·»åŠ CPUå¾Œå‚™æ”¯æ´")
            
            return providers
            
        except ImportError:
            logger.error("âŒ ONNX Runtimeæœªå®‰è£")
            return ['CPUExecutionProvider']
    
    def optimize_session_options(self) -> Any:
        """Snapdragonå¹³å°æœƒè©±å„ªåŒ–"""
        try:
            import onnxruntime as ort
            
            session_options = ort.SessionOptions()
            session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
            session_options.enable_cpu_mem_arena = True
            session_options.enable_mem_pattern = True
            
            # Snapdragonç‰¹å®šå„ªåŒ–
            session_options.add_session_config_entry("session.load_model_format", "ORT")
            
            return session_options
            
        except ImportError:
            return None

class GenericONNXManager(ONNXRuntimeManager):
    """é€šç”¨å¹³å°ONNX Runtimeç®¡ç†å™¨"""
    
    def get_providers(self) -> List[str]:
        """ç²å–é€šç”¨å¹³å°æä¾›å•†"""
        try:
            import onnxruntime as ort
            available = ort.get_available_providers()
            
            providers = []
            
            # å˜—è©¦CUDA
            if 'CUDAExecutionProvider' in available:
                providers.append('CUDAExecutionProvider')
                logger.info("âœ… å•Ÿç”¨CUDAåŠ é€Ÿ")
            
            # å˜—è©¦DirectML (Windows)
            elif 'DmlExecutionProvider' in available:
                providers.append('DmlExecutionProvider')
                logger.info("âœ… å•Ÿç”¨DirectMLåŠ é€Ÿ")
            
            providers.append('CPUExecutionProvider')
            logger.info("âœ… æ·»åŠ CPUå¾Œå‚™æ”¯æ´")
            
            return providers
            
        except ImportError:
            logger.error("âŒ ONNX Runtimeæœªå®‰è£")
            return ['CPUExecutionProvider']
    
    def optimize_session_options(self) -> Any:
        """é€šç”¨å¹³å°æœƒè©±å„ªåŒ–"""
        try:
            import onnxruntime as ort
            
            session_options = ort.SessionOptions()
            session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
            session_options.enable_cpu_mem_arena = True
            session_options.enable_mem_pattern = True
            
            return session_options
            
        except ImportError:
            return None

class CrossPlatformAIDetector:
    """è·¨å¹³å°AIæª¢æ¸¬ç³»çµ±"""
    
    def __init__(self, config_path: Optional[str] = None):
        """åˆå§‹åŒ–è·¨å¹³å°æª¢æ¸¬ç³»çµ±"""
        self.platform_info = PlatformDetector.detect_platform()
        self.config = self._load_config(config_path)
        self.onnx_manager = self._create_onnx_manager()
        self.qai_hub_enabled = self._check_qai_hub_availability()
        
        logger.info("ğŸŒ åˆå§‹åŒ–è·¨å¹³å°AIæª¢æ¸¬ç³»çµ±...")
        self._log_platform_info()
    
    def _load_config(self, config_path: Optional[str]) -> Dict[str, Any]:
        """è¼‰å…¥é…ç½®æ–‡ä»¶"""
        default_config = {
            "mac_apple_silicon": {
                "model_path": "./models/mac",
                "batch_size": 1,
                "num_threads": 4,
                "enable_coreml": True
            },
            "snapdragon_x_elite": {
                "model_path": "./models/snapdragon", 
                "batch_size": 1,
                "num_threads": 8,
                "enable_qnn": True
            },
            "fallback": {
                "model_path": "./models/generic",
                "batch_size": 1,
                "num_threads": 2,
                "enable_acceleration": False
            }
        }
        
        if config_path and os.path.exists(config_path):
            try:
                with open(config_path, 'r') as f:
                    user_config = json.load(f)
                    default_config.update(user_config)
            except Exception as e:
                logger.warning(f"âš ï¸ é…ç½®æ–‡ä»¶è¼‰å…¥å¤±æ•—: {e}")
        
        return default_config
    
    def _create_onnx_manager(self) -> ONNXRuntimeManager:
        """å‰µå»ºé©åˆçš„ONNX Runtimeç®¡ç†å™¨"""
        platform_type = self.platform_info["platform_type"]
        
        if platform_type == "mac_apple_silicon":
            return MacONNXManager(self.platform_info)
        elif platform_type in ["snapdragon_x_elite", "windows_arm"]:
            return SnapdragonONNXManager(self.platform_info)
        else:
            return GenericONNXManager(self.platform_info)
    
    def _check_qai_hub_availability(self) -> bool:
        """æª¢æŸ¥QAI Hubå¯ç”¨æ€§"""
        try:
            import qai_hub as hub
            api_token = os.getenv('QAI_HUB_API_TOKEN')
            return bool(api_token)
        except ImportError:
            logger.warning("âš ï¸ QAI Hub SDKæœªå®‰è£")
            return False
    
    def _log_platform_info(self):
        """è¨˜éŒ„å¹³å°ä¿¡æ¯"""
        logger.info(f"ğŸ–¥ï¸ æª¢æ¸¬åˆ°å¹³å°: {self.platform_info['platform_type']}")
        logger.info(f"ğŸ’» ç³»çµ±: {self.platform_info['system']}")
        logger.info(f"ğŸ”§ æ¶æ§‹: {self.platform_info['machine']}")
        logger.info(f"ğŸ§  AIåŠ é€Ÿå™¨: {self.platform_info.get('ai_accelerator', 'Unknown')}")
        logger.info(f"âš¡ ä¸»è¦æä¾›å•†: {self.platform_info.get('primary_provider', 'Unknown')}")
        logger.info(f"â˜ï¸ QAI Hub: {'âœ… å¯ç”¨' if self.qai_hub_enabled else 'âŒ ä¸å¯ç”¨'}")
    
    def get_platform_config(self) -> Dict[str, Any]:
        """ç²å–ç•¶å‰å¹³å°é…ç½®"""
        platform_type = self.platform_info["platform_type"]
        return self.config.get(platform_type, self.config["fallback"])
    
    def initialize_onnx_runtime(self) -> bool:
        """åˆå§‹åŒ–ONNX Runtime"""
        try:
            providers = self.onnx_manager.get_providers()
            session_options = self.onnx_manager.optimize_session_options()
            
            logger.info(f"ğŸ“‹ å¯ç”¨æä¾›å•†: {providers}")
            
            # é€™è£¡å¯ä»¥è¼‰å…¥å¯¦éš›çš„ONNXæ¨¡å‹
            # self.load_models(providers, session_options)
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ONNX Runtimeåˆå§‹åŒ–å¤±æ•—: {e}")
            return False
    
    def setup_qai_hub_integration(self) -> bool:
        """è¨­ç½®QAI Hubé›†æˆ"""
        if not self.qai_hub_enabled:
            logger.warning("âš ï¸ QAI Hubä¸å¯ç”¨ï¼Œè·³éé›²ç«¯é›†æˆ")
            return False
        
        try:
            import qai_hub as hub
            
            # ç²å–è¨­å‚™åˆ—è¡¨
            devices = hub.get_devices()
            logger.info(f"â˜ï¸ QAI Hubé€£æ¥æˆåŠŸï¼Œå¯ç”¨è¨­å‚™: {len(devices)}")
            
            # æ ¹æ“šå¹³å°é¸æ“‡ç›®æ¨™è¨­å‚™
            platform_type = self.platform_info["platform_type"]
            if platform_type == "snapdragon_x_elite":
                # å„ªå…ˆé¸æ“‡Snapdragon Xè¨­å‚™
                target_devices = [d for d in devices if 'Snapdragon X' in d.name or 'X Elite' in d.name]
            else:
                # Macé–‹ç™¼ç’°å¢ƒä¸‹ä¹Ÿå¯ä»¥é¸æ“‡Snapdragonè¨­å‚™é€²è¡Œé›²ç«¯æ¸¬è©¦
                target_devices = [d for d in devices if 'Snapdragon' in d.name]
            
            if target_devices:
                self.target_device = target_devices[0]
                logger.info(f"ğŸ¯ é¸æ“‡ç›®æ¨™è¨­å‚™: {self.target_device.name}")
            else:
                self.target_device = devices[0] if devices else None
                logger.info(f"ğŸ¯ ä½¿ç”¨é è¨­è¨­å‚™: {self.target_device.name if self.target_device else 'None'}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ QAI Hubé›†æˆå¤±æ•—: {e}")
            return False
    
    def get_deployment_strategy(self) -> Dict[str, Any]:
        """ç²å–éƒ¨ç½²ç­–ç•¥"""
        platform_type = self.platform_info["platform_type"]
        
        strategies = {
            "mac_apple_silicon": {
                "development_mode": True,
                "primary_execution": "local_coreml",
                "cloud_testing": "qai_hub_validation",
                "model_source": "local_onnx_models",
                "optimization_target": "development_speed"
            },
            "snapdragon_x_elite": {
                "development_mode": False,
                "primary_execution": "local_qnn",
                "cloud_integration": "qai_hub_optimized",
                "model_source": "qai_hub_compiled_models",
                "optimization_target": "inference_performance"
            },
            "generic": {
                "development_mode": True,
                "primary_execution": "cpu_fallback",
                "cloud_testing": "qai_hub_validation",
                "model_source": "generic_onnx_models",
                "optimization_target": "compatibility"
            }
        }
        
        return strategies.get(platform_type, strategies["generic"])
    
    def generate_migration_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆç§»æ¤å ±å‘Š"""
        platform_config = self.get_platform_config()
        deployment_strategy = self.get_deployment_strategy()
        
        report = {
            "platform_analysis": {
                "current_platform": self.platform_info,
                "qai_hub_available": self.qai_hub_enabled,
                "onnx_providers": self.onnx_manager.get_providers(),
                "platform_config": platform_config
            },
            "deployment_strategy": deployment_strategy,
            "migration_readiness": {
                "mac_development": self.platform_info["platform_type"] == "mac_apple_silicon",
                "snapdragon_ready": self.qai_hub_enabled,
                "cross_platform_code": True,
                "hardware_abstraction": True
            },
            "recommendations": self._generate_recommendations()
        }
        
        return report
    
    def _generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆå»ºè­°"""
        recommendations = []
        platform_type = self.platform_info["platform_type"]
        
        if platform_type == "mac_apple_silicon":
            recommendations.extend([
                "ğŸ åœ¨Macä¸Šé€²è¡Œæ ¸å¿ƒåŠŸèƒ½é–‹ç™¼å’Œæ¸¬è©¦",
                "â˜ï¸ ä½¿ç”¨QAI Hubé€²è¡ŒSnapdragonè¨­å‚™é›²ç«¯é©—è­‰",
                "ğŸ”§ å¯¦ç¾ç¡¬ä»¶æŠ½è±¡å±¤ä»¥æ”¯æŒæœªä¾†ç§»æ¤",
                "ğŸ“Š å»ºç«‹æ€§èƒ½åŸºæº–ä»¥å°æ¯”ä¸åŒå¹³å°"
            ])
        elif platform_type == "snapdragon_x_elite":
            recommendations.extend([
                "ğŸ‰ å•Ÿç”¨QNNåŠ é€Ÿç²å¾—æœ€ä½³æ€§èƒ½",
                "âš¡ ä½¿ç”¨QAI Hubå„ªåŒ–çš„æ¨¡å‹",
                "ğŸ“ˆ ç›£æ§NPUä½¿ç”¨ç‡å’Œæ€§èƒ½æŒ‡æ¨™",
                "ğŸ”„ å»ºç«‹èˆ‡é›²ç«¯çš„æŒçºŒé›†æˆ"
            ])
        else:
            recommendations.extend([
                "ğŸ–¥ï¸ è€ƒæ…®å‡ç´šåˆ°æ”¯æŒçš„å¹³å°",
                "â˜ï¸ å……åˆ†åˆ©ç”¨QAI Hubé›²ç«¯è³‡æº",
                "âš¡ å°‹æ‰¾åˆé©çš„ç¡¬ä»¶åŠ é€Ÿé¸é …"
            ])
        
        if not self.qai_hub_enabled:
            recommendations.append("ğŸ”‘ é…ç½®QAI Hub API Tokenä»¥å•Ÿç”¨é›²ç«¯åŠŸèƒ½")
        
        return recommendations

def main():
    """ä¸»å‡½æ•¸ï¼šè·¨å¹³å°ç³»çµ±æ¸¬è©¦"""
    print("ğŸŒ è·¨å¹³å°AIæª¢æ¸¬ç³»çµ±åˆ†æ")
    print("=" * 50)
    
    try:
        # åˆå§‹åŒ–è·¨å¹³å°æª¢æ¸¬å™¨
        detector = CrossPlatformAIDetector()
        
        # åˆå§‹åŒ–ONNX Runtime
        onnx_success = detector.initialize_onnx_runtime()
        
        # è¨­ç½®QAI Hub
        qai_hub_success = detector.setup_qai_hub_integration()
        
        # ç”Ÿæˆç§»æ¤å ±å‘Š
        migration_report = detector.generate_migration_report()
        
        # é¡¯ç¤ºçµæœ
        print("\nğŸ“Š å¹³å°åˆ†æçµæœ:")
        platform = migration_report["platform_analysis"]["current_platform"]
        print(f"   å¹³å°é¡å‹: {platform['platform_type']}")
        print(f"   AIåŠ é€Ÿå™¨: {platform.get('ai_accelerator', 'Unknown')}")
        print(f"   ONNX Runtime: {'âœ… æˆåŠŸ' if onnx_success else 'âŒ å¤±æ•—'}")
        print(f"   QAI Hub: {'âœ… æˆåŠŸ' if qai_hub_success else 'âŒ å¤±æ•—'}")
        
        print("\nğŸš€ éƒ¨ç½²ç­–ç•¥:")
        strategy = migration_report["deployment_strategy"]
        print(f"   åŸ·è¡Œæ¨¡å¼: {strategy['primary_execution']}")
        print(f"   å„ªåŒ–ç›®æ¨™: {strategy['optimization_target']}")
        
        print("\nğŸ’¡ å»ºè­°:")
        for rec in migration_report["recommendations"]:
            print(f"   {rec}")
        
        # ä¿å­˜å ±å‘Š
        with open('cross_platform_analysis.json', 'w') as f:
            json.dump(migration_report, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“ è©³ç´°å ±å‘Šå·²ä¿å­˜: cross_platform_analysis.json")
        print("âœ… è·¨å¹³å°åˆ†æå®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
