#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
QAI Hub MediaPipe è¼¸å‡ºæ ¼å¼èª¿è©¦å™¨
ç”¨æ–¼ç†è§£ QAI Hub MediaPipe çš„å¯¦éš›è¼¸å‡ºçµæ§‹
"""

import cv2
import numpy as np
from PIL import Image
import torch

from qai_hub_models.models.mediapipe_pose.app import MediaPipePoseApp
from qai_hub_models.models.mediapipe_pose.model import MediaPipePose

def debug_qai_hub_output():
    """èª¿è©¦ QAI Hub MediaPipe çš„è¼¸å‡ºæ ¼å¼"""
    print("ğŸ” èª¿è©¦ QAI Hub MediaPipe è¼¸å‡ºæ ¼å¼...")
    
    # è¼‰å…¥æ¨¡å‹
    print("ğŸ“¥ è¼‰å…¥æ¨¡å‹...")
    pose_model = MediaPipePose.from_pretrained()
    pose_app = MediaPipePoseApp.from_pretrained(pose_model)
    print("âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ")
    
    # å‰µå»ºæ¸¬è©¦åœ–åƒï¼ˆä¸€å€‹ç°¡å–®çš„ç™½è‰²èƒŒæ™¯ï¼‰
    test_image = np.ones((480, 640, 3), dtype=np.uint8) * 255
    pil_image = Image.fromarray(test_image)
    
    print("\nğŸ§ª æ¸¬è©¦ 1: æª¢æŸ¥é raw_output æ¨¡å¼...")
    try:
        result_normal = pose_app.predict_landmarks_from_image(pil_image, raw_output=False)
        print(f"normal æ¨¡å¼çµæœé¡å‹: {type(result_normal)}")
        if isinstance(result_normal, (list, tuple)):
            print(f"normal æ¨¡å¼çµæœé•·åº¦: {len(result_normal)}")
            for i, item in enumerate(result_normal):
                print(f"  é …ç›® {i}: é¡å‹={type(item)}, å½¢ç‹€={(item.shape if hasattr(item, 'shape') else 'ç„¡å½¢ç‹€')}")
    except Exception as e:
        print(f"normal æ¨¡å¼éŒ¯èª¤: {e}")
    
    print("\nğŸ§ª æ¸¬è©¦ 2: æª¢æŸ¥ raw_output æ¨¡å¼...")
    try:
        result_raw = pose_app.predict_landmarks_from_image(pil_image, raw_output=True)
        print(f"raw æ¨¡å¼çµæœé¡å‹: {type(result_raw)}")
        if isinstance(result_raw, (list, tuple)):
            print(f"raw æ¨¡å¼çµæœé•·åº¦: {len(result_raw)}")
            for i, item in enumerate(result_raw):
                print(f"  é …ç›® {i}: é¡å‹={type(item)}")
                if isinstance(item, list):
                    print(f"    åˆ—è¡¨é•·åº¦: {len(item)}")
                    for j, subitem in enumerate(item):
                        print(f"      å­é …ç›® {j}: é¡å‹={type(subitem)}, å½¢ç‹€={(subitem.shape if hasattr(subitem, 'shape') else 'ç„¡å½¢ç‹€')}")
                        if hasattr(subitem, 'shape') and len(subitem.shape) > 0:
                            print(f"        å…§å®¹é è¦½: {subitem}")
                elif hasattr(item, 'shape'):
                    print(f"    å½¢ç‹€: {item.shape}")
                    if len(item.shape) > 0:
                        print(f"    å…§å®¹é è¦½: {item}")
    except Exception as e:
        print(f"raw æ¨¡å¼éŒ¯èª¤: {e}")
    
    # å˜—è©¦ä½¿ç”¨ä¸€å€‹åŒ…å«äººçš„æ¸¬è©¦åœ–åƒ
    print("\nğŸ§ª æ¸¬è©¦ 3: ä½¿ç”¨çœŸå¯¦äººåƒæ¸¬è©¦...")
    try:
        # å‰µå»ºä¸€å€‹ç°¡å–®çš„äººå½¢è¼ªå»“åœ–åƒ
        person_image = create_simple_person_image()
        pil_person = Image.fromarray(person_image)
        
        result_person = pose_app.predict_landmarks_from_image(pil_person, raw_output=True)
        print(f"äººåƒæ¸¬è©¦çµæœé¡å‹: {type(result_person)}")
        if isinstance(result_person, (list, tuple)):
            print(f"äººåƒæ¸¬è©¦çµæœé•·åº¦: {len(result_person)}")
            for i, item in enumerate(result_person):
                print(f"  é …ç›® {i}: é¡å‹={type(item)}")
                if isinstance(item, list):
                    print(f"    åˆ—è¡¨é•·åº¦: {len(item)}")
                    if len(item) > 0:
                        print(f"      ç¬¬ä¸€å€‹å…ƒç´ é¡å‹: {type(item[0])}")
                        if hasattr(item[0], 'shape'):
                            print(f"      ç¬¬ä¸€å€‹å…ƒç´ å½¢ç‹€: {item[0].shape}")
    except Exception as e:
        print(f"äººåƒæ¸¬è©¦éŒ¯èª¤: {e}")

def create_simple_person_image():
    """å‰µå»ºä¸€å€‹ç°¡å–®çš„äººå½¢è¼ªå»“åœ–åƒç”¨æ–¼æ¸¬è©¦"""
    image = np.zeros((480, 640, 3), dtype=np.uint8)
    
    # ç•«ä¸€å€‹ç°¡å–®çš„äººå½¢è¼ªå»“
    center_x, center_y = 320, 240
    
    # é ­éƒ¨ï¼ˆåœ“å½¢ï¼‰
    cv2.circle(image, (center_x, center_y - 100), 30, (255, 255, 255), -1)
    
    # èº«é«”ï¼ˆçŸ©å½¢ï¼‰
    cv2.rectangle(image, (center_x - 25, center_y - 70), (center_x + 25, center_y + 50), (255, 255, 255), -1)
    
    # æ‰‹è‡‚
    cv2.rectangle(image, (center_x - 60, center_y - 50), (center_x - 25, center_y), (255, 255, 255), -1)
    cv2.rectangle(image, (center_x + 25, center_y - 50), (center_x + 60, center_y), (255, 255, 255), -1)
    
    # è…¿éƒ¨
    cv2.rectangle(image, (center_x - 15, center_y + 50), (center_x - 5, center_y + 120), (255, 255, 255), -1)
    cv2.rectangle(image, (center_x + 5, center_y + 50), (center_x + 15, center_y + 120), (255, 255, 255), -1)
    
    return image

if __name__ == "__main__":
    debug_qai_hub_output()
