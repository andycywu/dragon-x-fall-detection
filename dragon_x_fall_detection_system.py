#!/usr/bin/env python3
"""
ğŸ‰ Dragon Xå°ˆç”¨è€äººè·Œå€’é é˜²æª¢æ¸¬ç³»çµ±
å°ˆç‚ºé»‘å®¢æ¾å„ªåŒ–ï¼Œä½¿ç”¨Snapdragon X Eliteå¹³å°
"""

import os
import sys
import subprocess
import shutil
import zipfile
import qai_hub as hub
import numpy as np
import cv2
import onnxruntime as ort
try:
    import onnx  # å‹å¼é©—è­‰ç”¨ (é¿å…åè¦† INVALID_PROTOBUF)
except ImportError:  # å¯é¸
    onnx = None
import logging
try:
    from dotenv import load_dotenv  # type: ignore
except ImportError:  # make optional
    def load_dotenv(*args, **kwargs):
        print("âš ï¸ æœªå®‰è£ python-dotenvï¼Œè·³é .env è¼‰å…¥ (å¯åŸ·è¡Œ: pip install python-dotenv)")
        return False
from typing import Dict, Any, List, Optional
import time
import json
import argparse
import re

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ===== ç‰ˆæœ¬è³‡è¨Š (ç”¨æ–¼è·¨æ©Ÿå™¨åŒæ­¥æª¢æŸ¥) =====
__DRAGON_X_SYSTEM_VERSION__ = "2025-08-14.1"


class DragonXFallDetectionSystem:
    """Dragon Xå°ˆç”¨è€äººè·Œå€’é é˜²æª¢æ¸¬ç³»çµ± (å« Edge éƒ¨ç½²é¸é …)"""

    def __init__(self,
                 full_pipeline: bool = False,
                 wait: bool = False,
                 poll_interval: int = 15,
                 debug_link: bool = False,
                 link_python: bool = False,
                 export_local_onnx: bool = False,
                 wait_compile_only: bool = False,
                 download_compiled: bool = False,
                 realtime: bool = False,
                 camera_index: int = 0,
                 max_frames: Optional[int] = None,
                 edge_only: bool = False,
                 no_qnn_dlc: bool = False,
                 offline: bool = False,
                 use_qnn: bool = False,
                 force_qnn: bool = False,
                 simulate_fall: bool = False,
                 demo_pose: bool = False,
                 summarize_edge: bool = False):
        """åˆå§‹åŒ–Dragon Xæª¢æ¸¬ç³»çµ±"""
        # -------- åŸºæœ¬å±¬æ€§èˆ‡å·¥ä½œè¿½è¹¤çµæ§‹ --------
        self.api_token = os.getenv('QAI_HUB_API_TOKEN')
        self.target_device = None
        self.qai_hub_models: Dict[str, Any] = {}
        self.compiled_models: Dict[str, Any] = {}
        self.onnx_sessions: Dict[str, Any] = {}
        self.profile_jobs: Dict[str, Any] = {}
        self.link_jobs: Dict[str, Any] = {}
        self.target_models: Dict[str, Any] = {}
        self.inference_jobs: Dict[str, Any] = {}
        self.inference_outputs: Dict[str, Any] = {}

        # -------- åƒæ•¸ --------
        self.full_pipeline = full_pipeline
        self.wait_for_jobs = wait
        self.poll_interval = poll_interval
        self.debug_link = debug_link
        self.python_link_requested = link_python
        self.export_local_onnx = export_local_onnx
        self.wait_compile_only = wait_compile_only
        self.download_compiled = download_compiled
        self.realtime = realtime
        self.camera_index = camera_index
        self.max_frames = max_frames
        self.edge_only = edge_only
        self.no_qnn_dlc = no_qnn_dlc
        self.offline = offline
        self.use_qnn = use_qnn
        self.force_qnn = force_qnn
        self.simulate_fall = simulate_fall
        self.demo_pose = demo_pose
        self.summarize_edge = summarize_edge
        # è‡ªå‹•è¨­å®š: ç›´æ¥å„ªå…ˆä½¿ç”¨ original ONNX ä¸¦åŒ¯å‡ºæ‰€æœ‰æ¨¡å‹
        self.prefer_original = True
        self.export_all_onnx = True
        self.qnn_backend_path = None  # å¯é¸: æŒ‡å®š QNN backend path
        self._edge_sessions_initialized = False
        self._benchmark_runs = 0

        # -------- ç‹€æ…‹ --------
        self._pose_session = None
        self._invalid_onnx_cache = {}

        logger.info("ğŸ‰ åˆå§‹åŒ–Dragon Xè€äººè·Œå€’é é˜²æª¢æ¸¬ç³»çµ±...")
        if not self.offline:
            self._find_dragon_x_devices()
        else:
            logger.info("ğŸŒ Offline æ¨¡å¼: è·³é QAI Hub è£ç½®æœå°‹èˆ‡æ¨¡å‹è¼‰å…¥ (å¯ç”¨æ–¼èªæ³•/æµç¨‹æ¸¬è©¦)")

        # edge-only: åªåœ¨éœ€è¦åŸå§‹ ONNX åŒ¯å‡ºæ™‚æ‰è¼‰å…¥æ¨¡å‹ (é¿å…é‡æ–° compile)
        if not self.offline and self.edge_only and not self.export_local_onnx:
            logger.info("ğŸ§Š (--edge-only) è·³éæ¨¡å‹é›²ç«¯ç·¨è­¯æäº¤ï¼Œåƒ…ä½¿ç”¨æœ¬åœ° compiled_*.onnx / åŸå§‹ ONNX")
        elif not self.offline:
            self._initialize_fall_detection_models()

        if not self.offline and self.export_local_onnx:
            try:
                self._export_original_pose_onnx()
            except Exception as e:
                logger.warning(f"âš ï¸ åŒ¯å‡ºåŸå§‹ ONNX å¤±æ•—: {e}")

        # è‡ªå‹•åŒ¯å‡º face/hand åŸå§‹ ONNX (ä¾›å¾ŒçºŒçµ±ä¸€æ¨è«–)
        if not self.offline and self.export_all_onnx:
            try:
                self._export_all_original_onnx()
            except Exception as e:
                logger.warning(f"âš ï¸ åŒ¯å‡ºå…¨éƒ¨æ¨¡å‹ ONNX å¤±æ•—: {e}")

        if not self.offline and self.full_pipeline:
            logger.info("ğŸ§ª å•Ÿå‹•å®Œæ•´å®˜æ–¹æµç¨‹ (Step 1~6 for each model)")
            self._run_full_official_steps_for_all_models()
            if self.python_link_requested:
                self._link_all_models_python()
            else:
                self._attempt_link_jobs_cli()

        if not self.offline and self.wait_compile_only and not self.full_pipeline:
            logger.info("â³ (--wait-compile) ç­‰å¾…ç¾æœ‰ç·¨è­¯/Profiling Jobs å®Œæˆ")
            self.wait_for_all_jobs()

        if not self.offline and self.download_compiled:
            self._download_all_target_models()
            if self.summarize_edge:
                self._summarize_edge_models()

        if self.realtime:
            self.run_realtime_inference()
    # Benchmark å¯èƒ½åœ¨å¤–éƒ¨ main è§£æåƒæ•¸å¾Œå†è¨­å®šå±¬æ€§å†å‘¼å«
    
    def _find_dragon_x_devices(self):
        """å°‹æ‰¾ä¸¦é¸æ“‡Dragon Xè¨­å‚™"""
        if not self.api_token:
            raise ValueError("âŒ è«‹åœ¨.envæ–‡ä»¶ä¸­è¨­ç½®QAI_HUB_API_TOKEN")
        
        try:
            devices = hub.get_devices()
            logger.info(f"ğŸ” æœå°‹QAI Hubè¨­å‚™...")
            logger.info(f"   ç¸½è¨­å‚™æ•¸é‡: {len(devices)}")
            
            # åˆ†é¡è¨­å‚™
            dragon_x_devices = []
            snapdragon_devices = []
            other_devices = []
            
            for device in devices:
                device_name = device.name.lower()
                if 'x elite' in device_name or 'snapdragon x' in device_name or 'dragon x' in device_name:
                    dragon_x_devices.append(device)
                elif 'snapdragon' in device_name:
                    snapdragon_devices.append(device)
                else:
                    other_devices.append(device)
            
            # é¡¯ç¤ºè¨­å‚™åˆ†é¡
            logger.info(f"ğŸ“Š è¨­å‚™åˆ†é¡çµæœ:")
            logger.info(f"   ğŸ‰ Dragon X / Snapdragon X Elite: {len(dragon_x_devices)}")
            logger.info(f"   ğŸ”¥ å…¶ä»–Snapdragonè¨­å‚™: {len(snapdragon_devices)}")
            logger.info(f"   ğŸ“± å…¶ä»–è¨­å‚™: {len(other_devices)}")
            
            # é¸æ“‡æœ€ä½³è¨­å‚™
            if dragon_x_devices:
                self.target_device = dragon_x_devices[0]
                logger.info(f"ğŸ‰ æˆåŠŸé¸å®šDragon Xè¨­å‚™!")
                logger.info(f"   ğŸ‰ è¨­å‚™åç¨±: {self.target_device.name}")
                logger.info(f"   âœ¨ é»‘å®¢æ¾ä¸»æ‰“å¹³å°å·²å°±ç·’!")
                
                # é¡¯ç¤ºæ‰€æœ‰Dragon Xè¨­å‚™é¸é …
                if len(dragon_x_devices) > 1:
                    logger.info(f"   ğŸ“‹ å…¶ä»–å¯ç”¨Dragon Xè¨­å‚™:")
                    for i, device in enumerate(dragon_x_devices[1:], 1):
                        logger.info(f"      {i}. {device.name}")
                        
            elif snapdragon_devices:
                self.target_device = snapdragon_devices[0]
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°Dragon Xï¼Œä½¿ç”¨Snapdragonè¨­å‚™:")
                logger.info(f"   ğŸ”¥ è¨­å‚™åç¨±: {self.target_device.name}")
                
            else:
                self.target_device = devices[0] if devices else None
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°Snapdragonè¨­å‚™ï¼Œä½¿ç”¨é è¨­è¨­å‚™:")
                logger.info(f"   ğŸ“± è¨­å‚™åç¨±: {self.target_device.name if self.target_device else 'None'}")
            
            return self.target_device
            
        except Exception as e:
            logger.error(f"âŒ è¨­å‚™æœå°‹å¤±æ•—: {e}")
            raise
    
    def _initialize_fall_detection_models(self):
        """åˆå§‹åŒ–è·Œå€’æª¢æ¸¬æ‰€éœ€çš„æ¨¡å‹"""
        logger.info("ğŸ§  è¼‰å…¥è€äººè·Œå€’é é˜²æª¢æ¸¬æ¨¡å‹...")
        
        try:
            # å§¿æ…‹æª¢æ¸¬æ˜¯è·Œå€’æª¢æ¸¬çš„æ ¸å¿ƒ
            self._load_pose_detection_for_fall_prevention()
            
            # äººè‡‰æª¢æ¸¬ç”¨æ–¼ç¢ºèªè€äººèº«ä»½
            self._load_face_detection_for_elderly_identification()
            
            # æ‰‹éƒ¨æª¢æ¸¬ç”¨æ–¼æª¢æ¸¬æ±‚æ•‘æ‰‹å‹¢
            self._load_hand_detection_for_emergency_gestures()
            
            logger.info("âœ… è€äººè·Œå€’é é˜²æª¢æ¸¬æ¨¡å‹è¼‰å…¥å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            raise
    
    def _load_pose_detection_for_fall_prevention(self):
        """è¼‰å…¥å§¿æ…‹æª¢æ¸¬æ¨¡å‹ï¼ˆè·Œå€’é é˜²æ ¸å¿ƒï¼‰"""
        try:
            from qai_hub_models.models.mediapipe_pose import Model as PoseModel
            
            logger.info("ğŸš¶â€â™‚ï¸ è¼‰å…¥å§¿æ…‹æª¢æ¸¬æ¨¡å‹ (è·Œå€’é é˜²æ ¸å¿ƒ)...")
            pose_model = PoseModel.from_pretrained()
            pose_detector = pose_model.pose_detector
            self.qai_hub_models['pose_fall_detection'] = pose_detector

            if self.edge_only:
                logger.info("â­ï¸ edge-only: ä¸æäº¤å§¿æ…‹ç·¨è­¯ Job")
            # æäº¤åˆ°Dragon Xè¨­å‚™ç·¨è­¯ (é™¤é edge-only)
            elif self.target_device:
                logger.info("ğŸ‰ æäº¤å§¿æ…‹æª¢æ¸¬æ¨¡å‹åˆ°Dragon Xç·¨è­¯...")
                try:
                    torchscript_model = pose_detector.convert_to_torchscript()
                    uploaded_model = hub.upload_model(torchscript_model)
                    compile_kwargs = dict(
                        model=uploaded_model,
                        input_specs={"image": ((1, 3, 256, 256), "float32")},
                        device=self.target_device,
                    )
                    if not self.no_qnn_dlc:
                        compile_kwargs['options'] = "--target_runtime qnn_dlc"
                    compile_job = hub.submit_compile_job(**compile_kwargs)
                    logger.info(f"âœ… å§¿æ…‹æª¢æ¸¬Dragon Xç·¨è­¯Job: {compile_job.job_id}")
                    logger.info(f"ğŸ”— Dashboard: https://app.aihub.qualcomm.com/jobs/{compile_job.job_id}")
                    self.compiled_models['pose_fall_detection_job'] = compile_job
                except Exception as e:
                    logger.error(f"âŒ å§¿æ…‹æª¢æ¸¬Dragon Xç·¨è­¯å¤±æ•—: {e}")
            
            logger.info("âœ… å§¿æ…‹æª¢æ¸¬æ¨¡å‹ (è·Œå€’é é˜²) è¼‰å…¥å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ å§¿æ…‹æª¢æ¸¬æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
    
    def _load_face_detection_for_elderly_identification(self):
        """è¼‰å…¥äººè‡‰æª¢æ¸¬æ¨¡å‹ï¼ˆè€äººèº«ä»½ç¢ºèªï¼‰"""
        try:
            from qai_hub_models.models.mediapipe_face import Model as FaceModel
            
            logger.info("ğŸ‘¤ è¼‰å…¥äººè‡‰æª¢æ¸¬æ¨¡å‹ (è€äººèº«ä»½ç¢ºèª)...")
            face_model = FaceModel.from_pretrained()
            face_detector = face_model.face_detector
            self.qai_hub_models['face_elderly_id'] = face_detector
            if self.edge_only:
                logger.info("â­ï¸ edge-only: ä¸æäº¤äººè‡‰ç·¨è­¯ Job")
            elif self.target_device:
                logger.info("ğŸ‰ æäº¤äººè‡‰æª¢æ¸¬æ¨¡å‹åˆ°Dragon Xç·¨è­¯...")
                try:
                    torchscript_model = face_detector.convert_to_torchscript()
                    uploaded_model = hub.upload_model(torchscript_model)
                    compile_kwargs = dict(
                        model=uploaded_model,
                        input_specs={"image": ((1, 3, 256, 256), "float32")},
                        device=self.target_device,
                    )
                    if not self.no_qnn_dlc:
                        compile_kwargs['options'] = "--target_runtime qnn_dlc"
                    compile_job = hub.submit_compile_job(**compile_kwargs)
                    logger.info(f"âœ… äººè‡‰æª¢æ¸¬Dragon Xç·¨è­¯Job: {compile_job.job_id}")
                    logger.info(f"ğŸ”— Dashboard: https://app.aihub.qualcomm.com/jobs/{compile_job.job_id}")
                    self.compiled_models['face_elderly_id_job'] = compile_job
                except Exception as e:
                    logger.error(f"âŒ äººè‡‰æª¢æ¸¬Dragon Xç·¨è­¯å¤±æ•—: {e}")
            
            logger.info("âœ… äººè‡‰æª¢æ¸¬æ¨¡å‹ (è€äººèº«ä»½ç¢ºèª) è¼‰å…¥å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ äººè‡‰æª¢æ¸¬æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
    
    def _load_hand_detection_for_emergency_gestures(self):
        """è¼‰å…¥æ‰‹éƒ¨æª¢æ¸¬æ¨¡å‹ï¼ˆç·Šæ€¥æ±‚æ•‘æ‰‹å‹¢ï¼‰"""
        try:
            from qai_hub_models.models.mediapipe_hand import Model as HandModel
            
            logger.info("âœ‹ è¼‰å…¥æ‰‹éƒ¨æª¢æ¸¬æ¨¡å‹ (ç·Šæ€¥æ±‚æ•‘æ‰‹å‹¢)...")
            hand_model = HandModel.from_pretrained()
            hand_detector = hand_model.hand_detector
            self.qai_hub_models['hand_emergency_gesture'] = hand_detector
            if self.edge_only:
                logger.info("â­ï¸ edge-only: ä¸æäº¤æ‰‹éƒ¨ç·¨è­¯ Job")
            elif self.target_device:
                logger.info("ğŸ‰ æäº¤æ‰‹éƒ¨æª¢æ¸¬æ¨¡å‹åˆ°Dragon Xç·¨è­¯...")
                try:
                    torchscript_model = hand_detector.convert_to_torchscript()
                    uploaded_model = hub.upload_model(torchscript_model)
                    compile_kwargs = dict(
                        model=uploaded_model,
                        input_specs={"image": ((1, 3, 224, 224), "float32")},
                        device=self.target_device,
                    )
                    if not self.no_qnn_dlc:
                        compile_kwargs['options'] = "--target_runtime qnn_dlc"
                    compile_job = hub.submit_compile_job(**compile_kwargs)
                    logger.info(f"âœ… æ‰‹éƒ¨æª¢æ¸¬Dragon Xç·¨è­¯Job: {compile_job.job_id}")
                    logger.info(f"ğŸ”— Dashboard: https://app.aihub.qualcomm.com/jobs/{compile_job.job_id}")
                    self.compiled_models['hand_emergency_gesture_job'] = compile_job
                except Exception as e:
                    logger.error(f"âŒ æ‰‹éƒ¨æª¢æ¸¬Dragon Xç·¨è­¯å¤±æ•—: {e}")
            
            logger.info("âœ… æ‰‹éƒ¨æª¢æ¸¬æ¨¡å‹ (ç·Šæ€¥æ±‚æ•‘æ‰‹å‹¢) è¼‰å…¥å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ‰‹éƒ¨æª¢æ¸¬æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
    
    def analyze_fall_risk(self, pose_keypoints: List[Dict]) -> Dict[str, Any]:
        """åˆ†æè·Œå€’é¢¨éšª"""
        # æ¨¡æ“¬æ¨¡å¼ (ç›´æ¥è¼¸å‡ºé«˜é¢¨éšªæˆ–éš¨æ©Ÿé¢¨éšªç”¨æ–¼Demo)
        if self.simulate_fall:
            return {
                "fall_risk": "high",
                "risk_score": 0.85,
                "confidence": 0.95,
                "message": "âš ï¸ æ¨¡æ“¬: é«˜è·Œå€’é¢¨éšª",
                "indicators": ["æ¨¡æ“¬è·Œå€’æƒ…å¢ƒ"],
                "recommendation": self._get_safety_recommendation("high")
            }
        if not pose_keypoints:
            return {"fall_risk": "unknown", "confidence": 0.0, "reasons": []}
        
        fall_risk_indicators = []
        risk_score = 0.0
        
        try:
            # æå–é—œéµé—œç¯€é»
            keypoints = pose_keypoints[0] if pose_keypoints else {}
            
            # æª¢æ¸¬èº«é«”å‚¾æ–œåº¦
            if len(keypoints.get('keypoints', [])) >= 17:
                kpts = keypoints['keypoints']
                
                # è‚©è†€æ°´å¹³åº¦æª¢æŸ¥
                left_shoulder = kpts[5] if len(kpts) > 5 else None
                right_shoulder = kpts[6] if len(kpts) > 6 else None
                
                if left_shoulder and right_shoulder:
                    shoulder_angle = abs(left_shoulder['y'] - right_shoulder['y'])
                    if shoulder_angle > 0.3:  # é–¾å€¼å¯èª¿æ•´
                        fall_risk_indicators.append("èº«é«”æ˜é¡¯å‚¾æ–œ")
                        risk_score += 0.4
                
                # é‡å¿ƒç©©å®šæ€§æª¢æŸ¥
                left_hip = kpts[11] if len(kpts) > 11 else None
                right_hip = kpts[12] if len(kpts) > 12 else None
                left_ankle = kpts[15] if len(kpts) > 15 else None
                right_ankle = kpts[16] if len(kpts) > 16 else None
                
                if all([left_hip, right_hip, left_ankle, right_ankle]):
                    # æª¢æŸ¥è…³è¸ä½ç½®ç›¸å°æ–¼é«–éƒ¨
                    hip_center_x = (left_hip['x'] + right_hip['x']) / 2
                    ankle_center_x = (left_ankle['x'] + right_ankle['x']) / 2
                    
                    balance_offset = abs(hip_center_x - ankle_center_x)
                    if balance_offset > 0.4:  # é‡å¿ƒåç§»éå¤§
                        fall_risk_indicators.append("é‡å¿ƒä¸ç©©å®š")
                        risk_score += 0.3
                
                # è†è“‹å½æ›²åº¦æª¢æŸ¥
                left_knee = kpts[13] if len(kpts) > 13 else None
                right_knee = kpts[14] if len(kpts) > 14 else None
                
                if left_knee and right_knee and left_hip and right_hip:
                    # æª¢æŸ¥è†è“‹æ˜¯å¦éåº¦å½æ›²ï¼ˆå¯èƒ½è¡¨ç¤ºè·Œå€’ï¼‰
                    left_knee_angle = abs(left_knee['y'] - left_hip['y'])
                    right_knee_angle = abs(right_knee['y'] - right_hip['y'])
                    
                    if left_knee_angle < 0.1 or right_knee_angle < 0.1:
                        fall_risk_indicators.append("è†è“‹ç•°å¸¸å½æ›²")
                        risk_score += 0.3
        
        except Exception as e:
            logger.error(f"âŒ è·Œå€’é¢¨éšªåˆ†æå¤±æ•—: {e}")
            return {"fall_risk": "analysis_error", "confidence": 0.0, "error": str(e)}
        
        # åˆ¤å®šé¢¨éšªç­‰ç´š
        if risk_score >= 0.7:
            risk_level = "high"
            risk_message = "âš ï¸ é«˜è·Œå€’é¢¨éšª"
        elif risk_score >= 0.4:
            risk_level = "medium"
            risk_message = "ğŸ”¶ ä¸­ç­‰è·Œå€’é¢¨éšª"
        elif risk_score >= 0.1:
            risk_level = "low"
            risk_message = "ğŸ”· ä½è·Œå€’é¢¨éšª"
        else:
            risk_level = "normal"
            risk_message = "âœ… æ­£å¸¸ç‹€æ…‹"
        
        return {
            "fall_risk": risk_level,
            "risk_score": risk_score,
            "confidence": min(risk_score * 1.5, 1.0),
            "message": risk_message,
            "indicators": fall_risk_indicators,
            "recommendation": self._get_safety_recommendation(risk_level)
        }
    
    def _get_safety_recommendation(self, risk_level: str) -> str:
        """æ ¹æ“šé¢¨éšªç­‰ç´šæä¾›å®‰å…¨å»ºè­°"""
        recommendations = {
            "high": "ç«‹å³æª¢æŸ¥ç’°å¢ƒå®‰å…¨ï¼Œå»ºè­°å°‹æ±‚å”åŠ©æˆ–åä¸‹ä¼‘æ¯",
            "medium": "æ³¨æ„å‘¨åœç’°å¢ƒï¼Œæ”¾æ…¢å‹•ä½œï¼Œç¢ºä¿æœ‰æ”¯æ’ç‰©åœ¨é™„è¿‘",
            "low": "ä¿æŒè¬¹æ…ï¼Œæ³¨æ„è…³ä¸‹ç‹€æ³",
            "normal": "ç¹¼çºŒä¿æŒè‰¯å¥½å§¿æ…‹"
        }
        return recommendations.get(risk_level, "ä¿æŒå®‰å…¨æ„è­˜")
    
    def comprehensive_fall_prevention_detection(self, image: np.ndarray) -> Dict[str, Any]:
        """ç¶œåˆè·Œå€’é é˜²æª¢æ¸¬"""
        results = {
            "timestamp": time.time(),
            "dragon_x_device": self.target_device.name if self.target_device else None,
            "fall_prevention_analysis": {},
            "detections": {},
            "qai_hub_jobs": {},
            "edge_models": self._gather_edge_model_summary()
        }

        # ç¢ºä¿ edge sessions å»ºç«‹ä¸€æ¬¡ (å« original ONNX)
        if not self._edge_sessions_initialized:
            try:
                self._ensure_edge_sessions()
            finally:
                self._edge_sessions_initialized = True
        
        # å§¿æ…‹æª¢æ¸¬ï¼ˆæ ¸å¿ƒï¼‰- æ¸›å°‘æ—¥èªŒé‡è¤‡
        if 'pose_fall_detection' in self.qai_hub_models:
            if self.demo_pose:
                # ç”¢ç”Ÿç¤ºç¯„å§¿æ…‹è³‡æ–™ (é€±æœŸæ€§æ”¹è®Šé¢¨éšªè§¸ç™¼æŒ‡æ¨™)
                kpts = []
                for i in range(17):
                    kpts.append({"x": float(0.5 + 0.15*np.sin(time.time()+i)),
                                 "y": float(0.5 + 0.15*np.cos(time.time()+i)),
                                 "confidence": 0.9})
                real_pose = {"keypoints": [{"keypoints": kpts}], "provider": ["demo"], "output_names": ["demo_output"]}
            else:
                real_pose = self._run_pose_inference_local(image)
            if real_pose is None:
                # fallback æ¨¡æ“¬
                mock_pose_results = {
                    "keypoints": [{
                        "keypoints": [
                            {"x": 0.5, "y": 0.3, "confidence": 0.8},
                            {"x": 0.45, "y": 0.5, "confidence": 0.9},
                            {"x": 0.55, "y": 0.5, "confidence": 0.9},
                        ]
                    }]
                }
                fall_analysis = self.analyze_fall_risk(mock_pose_results["keypoints"])
                results["fall_prevention_analysis"] = fall_analysis
                results["detections"]["pose"] = mock_pose_results
            else:
                fall_analysis = self.analyze_fall_risk(real_pose["keypoints"])
                results["fall_prevention_analysis"] = fall_analysis
                results["detections"]["pose"] = real_pose

        # Face / Hand ç°¡å–® Edge æ¨è«– (åªæä¾› shape/preview)
        face_edge = self._edge_infer_generic('face_elderly_id', image)
        if face_edge:
            results['detections']['face'] = face_edge
        hand_edge = self._edge_infer_generic('hand_emergency_gesture', image)
        if hand_edge:
            results['detections']['hand'] = hand_edge
        
        # è¨˜éŒ„Dragon Xç·¨è­¯Jobè³‡è¨Š
        for job_name, job in self.compiled_models.items():
            model_type = job_name.replace('_job', '')
            results["qai_hub_jobs"][model_type] = {
                "job_id": job.job_id,
                "dashboard_url": f"https://app.aihub.qualcomm.com/jobs/{job.job_id}",
                "target_device": self.target_device.name
            }
        
        return results
    
    def get_dragon_x_status_report(self) -> Dict[str, Any]:
        """ç²å–Dragon Xç³»çµ±ç‹€æ…‹å ±å‘Š"""
        report = {
            "system_name": "Dragon Xè€äººè·Œå€’é é˜²æª¢æ¸¬ç³»çµ±",
            "timestamp": time.time(),
            "dragon_x_device": {
                "name": self.target_device.name if self.target_device else None,
                "status": "ready" if self.target_device else "not_found"
            },
            "models_status": {},
            "qai_hub_jobs": {},
            "profile_jobs": {},
            "link_jobs": {},
            "hackathon_readiness": True
        }
        
        # æª¢æŸ¥æ¨¡å‹ç‹€æ…‹
        for model_name in self.qai_hub_models:
            report["models_status"][model_name] = "loaded"
        
        # æª¢æŸ¥ç·¨è­¯Jobç‹€æ…‹
        for job_name, job in self.compiled_models.items():
            try:
                # å˜—è©¦å¿«é€Ÿæª¢æŸ¥ç‹€æ…‹
                job.wait(timeout=1)
                status = "completed"
            except:
                status = "compiling"
            
            report["qai_hub_jobs"][job_name] = {
                "job_id": job.job_id,
                "status": status,
                "dashboard_url": f"https://app.aihub.qualcomm.com/jobs/{job.job_id}"
            }

        # Profile jobs
        for name, job in self.profile_jobs.items():
            try:
                job.wait(timeout=1)
                status = "completed"
            except:
                status = "running"
            report["profile_jobs"][name] = {
                "job_id": job.job_id,
                "status": status,
                "dashboard_url": f"https://app.aihub.qualcomm.com/jobs/{job.job_id}"
            }

        # Link jobs (CLI submissions only have ID string)
        for name, info in self.link_jobs.items():
            report["link_jobs"][name] = info
        
        return report

    # ================= å¯¦éš›åŸ·è¡Œæœ¬åœ°æ¨è«– (å§¿æ…‹) =================
    def _run_pose_inference_local(self, image: np.ndarray) -> Optional[Dict[str, Any]]:
        """å˜—è©¦ä½¿ç”¨å·²ä¸‹è¼‰çš„ compiled_pose_fall_detection.onnx åŸ·è¡Œæœ¬åœ°æ¨è«–ã€‚

        ç›®æ¨™: å„ªå…ˆä½¿ç”¨ QNN / QNNExecutionProvider (è‹¥ç’°å¢ƒæ”¯æ´) ä»¥è§¸ç™¼ NPUã€‚
        å›å‚³æ ¼å¼: {"keypoints": [{"keypoints": [{x,y,confidence}, ...]}]}
        å¤±æ•—å‰‡å›å‚³ Noneã€‚
        """
        onnx_path = 'compiled_pose_fall_detection.onnx'
        
        # æª¢æŸ¥æ˜¯å¦æ›¾æ¨™è¨˜ç‚ºç„¡æ•ˆï¼Œè‹¥æ˜¯å‰‡ç›´æ¥è·³é (é¿å…ç‹‚åˆ·)
        if onnx_path in self._invalid_onnx_cache:
            # å˜—è©¦ä½¿ç”¨åŸå§‹åŒ¯å‡º ONNX ä½œç‚º fallback
            orig_path = 'pose_fall_detection_original.onnx'
            if os.path.exists(orig_path):
                onnx_path = orig_path
            else:
                return None
        
        if not os.path.exists(onnx_path):
            # å˜—è©¦æ¥å— CLI ä¸‹è¼‰çš„ .onnx.dlc æª”æ¡ˆä¸¦è¤‡è£½ç‚º .onnx ä¾› ORT ä½¿ç”¨
            alt_path = 'compiled_pose_fall_detection.onnx.dlc'
            if os.path.exists(alt_path):
                try:
                    # æœ‰äº›æƒ…æ³ DLC å…¶å¯¦ä»æ˜¯å¯è§£æçš„ ONNXï¼›è‹¥ä¸æ˜¯ï¼Œä½¿ç”¨è€…éœ€å¦è¡Œè½‰æ›
                    shutil.copyfile(alt_path, onnx_path)
                    logger.info("ğŸ” å·²å°‡ .onnx.dlc è¤‡è£½ç‚º compiled_pose_fall_detection.onnx ä¾›æœ¬åœ°æ¨è«–å˜—è©¦")
                except Exception as e:
                    logger.warning(f"âš ï¸ è¤‡è£½ DLC -> ONNX å¤±æ•—: {e}")
            
            if not os.path.exists(onnx_path):
                # æ”¹å˜—è©¦ä½¿ç”¨åŸå§‹åŒ¯å‡º ONNX (è‹¥å­˜åœ¨)
                orig = 'pose_fall_detection_original.onnx'
                if os.path.exists(orig):
                    logger.info("ğŸ”„ ä½¿ç”¨åŸå§‹åŒ¯å‡ºå§¿æ…‹ ONNX (pose_fall_detection_original.onnx) é€²è¡Œæœ¬åœ°æ¨è«–")
                    onnx_path = orig
                else:
                    logger.warning("âš ï¸ æ‰¾ä¸åˆ°å·²ä¸‹è¼‰çš„å§¿æ…‹ ONNX (compiled æˆ– original)ï¼Œä½¿ç”¨æ¨¡æ“¬è³‡æ–™")
                    return None

        try:
            if self._pose_session is None:
                providers, preferred, qnn_active = self._get_preferred_providers()
                highlight = 'âœ…' if qnn_active else 'âš ï¸'
                logger.info(f"ğŸ§© ONNX Providers å¯ç”¨: {providers} -> ä½¿ç”¨: {preferred} {highlight}{' (å«QNN)' if qnn_active else ' (æœªå•Ÿç”¨QNN)'}")
                if self.force_qnn and not qnn_active:
                    logger.error("âŒ (--force-qnn) è¦æ±‚ QNN ä½†æœªæ‰¾åˆ° QNNExecutionProviderï¼Œè«‹å®‰è£ Qualcomm ONNX Runtime/QNN SDKã€‚")
                    logger.error("   æŒ‡å¼•: 1) å®‰è£/è¨­å®š QNN SDK 2) ç¢ºèª onnxruntime QNN EP å·²åŒ…å« 3) è¨­å®šç’°å¢ƒè®Šæ•¸ LD_LIBRARY_PATH æˆ– PATH")
                    return None
                # å…ˆå¿«é€Ÿé©—è­‰ ONNX (è‹¥ onnx å¥—ä»¶å­˜åœ¨)
                if onnx is not None:
                    try:
                        onnx.load(onnx_path)
                    except Exception as ve:
                        self._invalid_onnx_cache[onnx_path] = str(ve)
                        logger.warning(f"âš ï¸ compiled æª”æ¡ˆä¸æ˜¯åˆæ³• ONNX: {ve}. å˜—è©¦åŸå§‹åŒ¯å‡º ONNX")
                        # éš”é›¢å•é¡Œæª”æ¡ˆ
                        try:
                            quarantine_name = onnx_path + '.invalid'
                            if not os.path.exists(quarantine_name):
                                os.rename(onnx_path, quarantine_name)
                                logger.info(f"ğŸ§ª å·²éš”é›¢ç„¡æ•ˆæª”æ¡ˆ: {onnx_path} -> {quarantine_name}")
                        except Exception as re_err:
                            logger.debug(f"rename invalid failed: {re_err}")
                        fallback_orig = 'pose_fall_detection_original.onnx'
                        if os.path.exists(fallback_orig):
                            try:
                                self._pose_session = ort.InferenceSession(fallback_orig, providers=preferred)
                                logger.info("âœ… ä½¿ç”¨åŸå§‹åŒ¯å‡ºå§¿æ…‹ ONNX æˆåŠŸ (pose_fall_detection_original.onnx)")
                            except Exception as e2:
                                logger.warning(f"âš ï¸ åŸå§‹ ONNX ä¹Ÿç„¡æ³•è¼‰å…¥: {e2}")
                                self._pose_session = False
                        else:
                            self._pose_session = False
                        return None
                # è‹¥æœªæå‰è¿”å›å‰‡å»ºç«‹ session
                if self._pose_session is None:
                    self._pose_session = ort.InferenceSession(onnx_path, providers=preferred)
            sess = self._pose_session
            if sess is False:
                return None

            # å‰è™•ç†
            img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            img_resized = cv2.resize(img, (256, 256), interpolation=cv2.INTER_LINEAR)
            tensor = img_resized.astype('float32') / 255.0
            tensor = np.transpose(tensor, (2, 0, 1))[None, ...]
            input_name = sess.get_inputs()[0].name
            outputs = sess.run(None, {input_name: tensor})
            output_meta = sess.get_outputs()

            keypoints_list = []
            if outputs:
                arr_np = np.array(outputs[0])
                kpts = []
                try:
                    if arr_np.ndim == 3:
                        if arr_np.shape[2] == 3:  # (1, K, 3)
                            for i in range(min(arr_np.shape[1], 25)):
                                x, y, c = arr_np[0, i]
                                kpts.append({"x": float(x), "y": float(y), "confidence": float(c)})
                        elif arr_np.shape[1] == 3:  # (1, 3, K)
                            for i in range(min(arr_np.shape[2], 25)):
                                x = arr_np[0, 0, i]
                                y = arr_np[0, 1, i]
                                c = arr_np[0, 2, i] if arr_np.shape[1] > 2 else 0.9
                                kpts.append({"x": float(x), "y": float(y), "confidence": float(c)})
                    elif arr_np.ndim == 2 and arr_np.shape[0] == 1:  # (1, N)
                        flat = arr_np[0]
                        for i in range(0, min(len(flat), 75), 3):
                            if i + 2 < len(flat):
                                kpts.append({"x": float(flat[i]), "y": float(flat[i+1]), "confidence": float(flat[i+2])})
                    else:
                        logger.warning(f"âš ï¸ ç„¡æ³•è§£æå§¿æ…‹è¼¸å‡º shape={arr_np.shape}ï¼Œä½¿ç”¨æ¨¡æ“¬ fallback")
                except Exception as e:
                    logger.warning(f"âš ï¸ è§£æå§¿æ…‹è¼¸å‡ºå¤±æ•—:{e}ï¼Œä½¿ç”¨æ¨¡æ“¬ fallback")
                    return None
                if kpts:
                    keypoints_list.append({"keypoints": kpts})
            if not keypoints_list:
                return None
            return {"keypoints": keypoints_list, "provider": sess.get_providers(), "output_names": [o.name for o in output_meta]}
        except Exception as e:
            self._pose_session = False
            self._invalid_onnx_cache[onnx_path] = str(e)
            logger.warning(f"âš ï¸ æœ¬åœ°å§¿æ…‹æ¨è«–å¤±æ•— (åªæç¤ºä¸€æ¬¡ï¼Œå¾ŒçºŒå°‡éœé»˜): {e}")
            return None

    # ===== Edge éƒ¨ç½²è¼”åŠ© =====
    def _download_all_target_models(self):
        """å˜—è©¦å°æ¯å€‹ compile job å–å¾— target model ä¸¦ä¸‹è¼‰ compiled_{label}.onnx (è‹¥å°šæœªå­˜åœ¨)ã€‚"""
        for job_key, cjob in self.compiled_models.items():
            label = job_key.replace('_job', '')
            filename = f"compiled_{label}.onnx"
            if os.path.exists(filename):
                continue
            try:
                logger.info(f"ğŸ’¾ å˜—è©¦ä¸‹è¼‰ target model: {label}")
                # ç¢ºä¿ç·¨è­¯å®Œæˆ
                self._wait_for_single_job(cjob, f"compile:{label}", timeout=900, poll=15)
                tm = cjob.get_target_model()
                if hasattr(tm, 'download'):
                    # é¿å…é›™ .onnx.onnx.zip, å…ˆä»¥ä¸å¸¶ .onnx ä½œç‚ºåŸºåº•åç¨±
                    base_name = f"compiled_{label}"
                    tmp_download_name = base_name + "_raw_download"
                    try:
                        tm.download(tmp_download_name)
                    except Exception:
                        # å›é€€èˆŠè¡Œç‚º
                        tm.download(filename)
                    # å¯èƒ½å¯¦éš›ä¸‹è¼‰æˆ .onnx.dlc
                    self._normalize_and_extract_download(label)
                else:
                    logger.warning(f"âš ï¸ target_model ç„¡ download æ–¹æ³•: {label}")
            except Exception as e:
                logger.warning(f"âš ï¸ ä¸‹è¼‰ {label} å¤±æ•—: {e}")
        # ä¸‹è¼‰å®Œæˆå¾Œè¼¸å‡ºç¸½çµ (è‹¥ flag)
        if self.summarize_edge:
            self._summarize_edge_models()

    # ===== Edge Session å»ºç«‹ =====
    def _ensure_edge_sessions(self):
        """å»ºç«‹æˆ–å¿«å– pose / face / hand çš„ ONNX Runtime session (è‹¥æœ‰ compiled æ¨¡å‹æª”)."""
        models = [
            ('pose_fall_detection', (256, 256)),
            ('face_elderly_id', (256, 256)),
            ('hand_emergency_gesture', (224, 224)),
        ]
        providers_available, preferred, qnn_flag = self._get_preferred_providers()
        if self.force_qnn and not qnn_flag:
            logger.error("âŒ (--force-qnn) è¦æ±‚ QNN ä½†æœªæ‰¾åˆ° QNNExecutionProviderï¼Œè·³é Edge session å»ºç«‹ã€‚")
            return
        for label, shape in models:
            onnx_name = f"compiled_{label}.onnx"
            if label in self.onnx_sessions:
                continue
            if not os.path.exists(onnx_name):
                alt = onnx_name + '.dlc'
                if os.path.exists(alt):
                    try:
                        shutil.copyfile(alt, onnx_name)
                        logger.info(f"ğŸ” DLC -> ONNX è¤‡è£½: {alt} -> {onnx_name}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ è¤‡è£½ {alt} å¤±æ•—: {e}")
                if not os.path.exists(onnx_name):
                    # å°ˆé–€å° pose å˜—è©¦åŸå§‹åŒ¯å‡º ONNX
                    if label == 'pose_fall_detection' and os.path.exists('pose_fall_detection_original.onnx'):
                        onnx_name = 'pose_fall_detection_original.onnx'
                    else:
                        continue
            try:
                sess = ort.InferenceSession(onnx_name, providers=preferred)
                self.onnx_sessions[label] = (sess, shape)
                logger.info(f"ğŸ§© è½½å…¥ {label} ONNX Session (providers={sess.get_providers()}) {'âœ…å«QNN' if qnn_flag else 'âš ï¸ç„¡QNN'}")
            except Exception as e:
                logger.warning(f"âš ï¸ å»ºç«‹ {label} session å¤±æ•—: {e}")

    def _edge_infer_generic(self, label: str, frame: np.ndarray):
        entry = self.onnx_sessions.get(label)
        if not entry:
            return None
        sess, (tw, th) = entry
        try:
            img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            img_resized = cv2.resize(img, (tw, th), interpolation=cv2.INTER_LINEAR)
            tensor = img_resized.astype('float32') / 255.0
            tensor = np.transpose(tensor, (2,0,1))[None, ...]
            input_name = sess.get_inputs()[0].name
            outputs = sess.run(None, {input_name: tensor})
            # è¼•é‡æ‘˜è¦ï¼šåªè¼¸å‡ºç¬¬ä¸€å€‹å¼µé‡ shape èˆ‡å‰å¹¾å€‹å€¼
            if outputs:
                arr = np.array(outputs[0])
                preview = arr.flatten()[:6].tolist()
                return {"shape": list(arr.shape), "preview": [float(x) for x in preview]}
        except Exception as e:
            logger.debug(f"edge inference {label} error: {e}")
        return None

    def run_realtime_inference(self):
        """å•Ÿå‹•æ”å½±æ©Ÿå³æ™‚æ¨è«– (åƒ…ä½¿ç”¨å§¿æ…‹æ¨¡å‹åšé¢¨éšªåˆ†æ)ã€‚"""
        # å…ˆå˜—è©¦è¼‰å…¥å…¨éƒ¨ edge sessions
        self._ensure_edge_sessions()
        pose_ok = (
            'pose_fall_detection' in self.onnx_sessions or
            os.path.exists('compiled_pose_fall_detection.onnx') or
            os.path.exists('compiled_pose_fall_detection.onnx.dlc') or
            self._pose_session is not None
        )
        if not pose_ok:
            logger.warning("âš ï¸ ç„¡å§¿æ…‹ compiled ONNX(.dlc)ï¼Œè«‹å…ˆä½¿ç”¨ --download-compiled æˆ– --full-pipeline")
            return
        logger.info("ğŸ¥ å•Ÿå‹•å³æ™‚æ¨è«– (æŒ‰ q çµæŸ) - æœƒå˜—è©¦ä½¿ç”¨ pose/face/hand Edge æ¨¡å‹")
        cap = cv2.VideoCapture(self.camera_index)
        if not cap.isOpened():
            logger.error("âŒ ç„¡æ³•é–‹å•Ÿæ”å½±æ©Ÿ")
            return
        frame_id = 0
        fps = 0.0
        t_last = time.time()
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    logger.warning("âš ï¸ è®€å–å½±æ ¼å¤±æ•—")
                    break
                result = self.comprehensive_fall_prevention_detection(frame)
                # é¡å¤– edge æ¨è«– (face / hand)
                face_info = self._edge_infer_generic('face_elderly_id', frame)
                hand_info = self._edge_infer_generic('hand_emergency_gesture', frame)
                frame_id += 1
                if frame_id % 15 == 0:
                    now = time.time(); fps = 15.0 / (now - t_last); t_last = now
                overlay = frame.copy()
                fa = result.get('fall_prevention_analysis', {})
                status = fa.get('message', 'N/A')
                cv2.putText(overlay, f"FPS:{fps:.1f}", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,255,255),2)
                cv2.putText(overlay, status, (10,60), cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,255,0),2)
                if face_info:
                    cv2.putText(overlay, f"Face:{face_info['shape']}", (10,90), cv2.FONT_HERSHEY_SIMPLEX, 0.55,(255,200,0),1)
                if hand_info:
                    cv2.putText(overlay, f"Hand:{hand_info['shape']}", (10,110), cv2.FONT_HERSHEY_SIMPLEX, 0.55,(0,200,255),1)
                cv2.imshow('DragonX Edge Realtime', overlay)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    logger.info("ğŸ‘‹ ä½¿ç”¨è€…çµæŸå³æ™‚æ¨è«–")
                    break
                if self.max_frames and frame_id >= self.max_frames:
                    logger.info("ğŸ›‘ é”æœ€å¤§å½±æ ¼æ•¸ï¼ŒçµæŸå³æ™‚æ¨è«–")
                    break
        finally:
            cap.release(); cv2.destroyAllWindows()

    # ===================== æ–°å¢ï¼šå®Œæ•´Pipelineæ”¯æ´ =====================
    def _submit_profile_jobs_for_all(self):
        """ç‚ºæ‰€æœ‰å·²æäº¤çš„ç·¨è­¯æ¨¡å‹æäº¤ profiling jobï¼ˆè¿‘ä¼¼ inference æ€§èƒ½æ¸¬è©¦ï¼‰"""
        if not self.target_device:
            logger.warning("âš ï¸ ç„¡ç›®æ¨™è¨­å‚™ï¼Œè·³é profiling æäº¤")
            return
        for key, compile_job in self.compiled_models.items():
            model_label = key.replace('_job', '')
            if model_label in self.profile_jobs:
                continue
            try:
                # ç­‰å¾…å–®ä¸€ compile job å®Œæˆå¾Œå†é€ profiling (é¿å… 'model not compiled' éŒ¯èª¤)
                logger.info(f"â³ ç­‰å¾…ç·¨è­¯å®Œæˆä»¥ä¾¿ Profiling: {model_label} ({compile_job.job_id}) ...")
                self._wait_for_single_job(compile_job, f"compile:{model_label}")
                logger.info(f"âœ… ç·¨è­¯å·²å®Œæˆï¼Œæäº¤ Profiling: {model_label}")
                # å˜—è©¦å¾åŸå§‹æ¨¡å‹å­—å…¸æ‰¾åˆ°å°æ‡‰ component
                component_key = None
                if 'pose' in model_label:
                    component_key = 'pose_fall_detection'
                elif 'face' in model_label:
                    component_key = 'face_elderly_id'
                elif 'hand' in model_label:
                    component_key = 'hand_emergency_gesture'
                component = self.qai_hub_models.get(component_key)
                # æº–å‚™æ¨£æœ¬è¼¸å…¥ï¼ˆåƒ…ç•¶ API æ”¯æ´ç›¸é—œåƒæ•¸æ™‚æ‰ä½¿ç”¨ï¼‰
                sample_inputs_256 = {"image": np.random.rand(1,3,256,256).astype('float32')}
                sample_inputs_224 = {"image": np.random.rand(1,3,224,224).astype('float32')}
                sample_inputs = sample_inputs_224 if component_key == 'hand_emergency_gesture' else sample_inputs_256

                profile_job = None
                # 1. å˜—è©¦æœ€ç°¡ API å½¢å¼ï¼ˆæ–°ç‰ˆ SDK å¯èƒ½åªæ¥å—å¿…è¦åƒæ•¸ï¼‰
                try:
                    profile_job = hub.submit_profile_job(model=compile_job.model, device=self.target_device)
                except TypeError as te1:
                    # 2. å˜—è©¦åƒæ•¸åç¨± 'inputs'
                    try:
                        profile_job = hub.submit_profile_job(model=compile_job.model, device=self.target_device, inputs=sample_inputs)
                    except TypeError as te2:
                        # 3. å˜—è©¦èˆŠç‰ˆå¯èƒ½çš„ positional èª¿ç”¨
                        try:
                            profile_job = hub.submit_profile_job(compile_job.model, self.target_device)
                        except Exception as te3:
                            raise RuntimeError(f"submit_profile_job å¤šé‡å‘¼å«å½¢å¼å‡å¤±æ•—: {te1}; {te2}; {te3}")
                except Exception as e_any:
                    raise RuntimeError(f"submit_profile_job å‘¼å«å¤±æ•—: {e_any}")

                if profile_job is None:
                    raise RuntimeError("submit_profile_job è¿”å› Noneï¼Œå¯èƒ½ API å·²è®Šæ›´")
                self.profile_jobs[model_label + '_profile'] = profile_job
                logger.info(f"ğŸ“ˆ æäº¤Profiling: {model_label} -> {profile_job.job_id}")
                logger.info(f"ğŸ”— Dashboard: https://app.aihub.qualcomm.com/jobs/{profile_job.job_id}")
            except Exception as e:
                logger.error(f"âŒ Profiling æäº¤å¤±æ•— {model_label}: {e}")

    # === æ–°å¢ï¼šå®˜æ–¹ Step1~6 æ•´åˆåŸ·è¡Œ ===
    def _run_full_official_steps_for_all_models(self):
        """ä¾ç…§å®˜æ–¹æ•™å­¸æ­¥é©Ÿå°æ¯å€‹æ¨¡å‹åŸ·è¡Œ:
        Step1 æº–å‚™/Trace(å·²æ–¼è¼‰å…¥æ™‚å®Œæˆ TorchScript è½‰æ›)
        Step2 Compile (å·²æäº¤)
        Step3 Profile (ç­‰å¾… compile å®Œæˆå¾Œï¼Œä»¥ target_model åŸ·è¡Œ)
        Step4 Inference (åŒæ¨£ä½¿ç”¨ target_model)
        Step5 Post-process (åŸºæœ¬è¼¸å‡ºå½¢ç‹€/çµ±è¨ˆ)
        Step6 Download target model (ONNX/TorchScript)
        """
        if not self.target_device:
            logger.warning("âš ï¸ ç„¡ç›®æ¨™è¨­å‚™ï¼Œè·³éå®˜æ–¹æ­¥é©Ÿ")
            return
        for key, compile_job in list(self.compiled_models.items()):
            model_label = key.replace('_job', '')
            logger.info(f"================ {model_label} PIPELINE ================")
            logger.info(f"ğŸŸ¦ Step 2: ç­‰å¾… Compile å®Œæˆ -> {compile_job.job_id}")
            self._wait_for_single_job(compile_job, f"compile:{model_label}")
            # Step3: Profile éœ€ target model
            try:
                logger.info("ğŸŸ© å–å¾— target_model (get_target_model)")
                target_model = compile_job.get_target_model()
                self.target_models[model_label] = target_model
            except Exception as e:
                logger.error(f"âŒ ç„¡æ³•å–å¾— target_model ({model_label}): {e}")
                continue
            # æäº¤ Profile
            if model_label + '_profile' not in self.profile_jobs:
                try:
                    logger.info("ğŸŸ¨ Step 3: æäº¤ Profile Job")
                    profile_job = hub.submit_profile_job(model=target_model, device=self.target_device)
                    self.profile_jobs[model_label + '_profile'] = profile_job
                    self._wait_for_single_job(profile_job, f"profile:{model_label}")
                except Exception as e:
                    logger.warning(f"âš ï¸ Profile å¤±æ•— ({model_label}): {e}")
            # Inference
            if model_label not in self.inference_jobs:
                try:
                    logger.info("ğŸŸ¥ Step 4: æäº¤ Inference Job")
                    # å»ºç«‹ç°¡å–®éš¨æ©Ÿè¼¸å…¥ (ä¾åŸå§‹ input spec å°ºå¯¸)
                    shape = (1, 3, 256, 256)
                    if 'hand' in model_label:
                        shape = (1, 3, 224, 224)
                    dummy = np.random.rand(*shape).astype('float32')
                    inf_job = hub.submit_inference_job(model=target_model, device=self.target_device, inputs={'image': [dummy]})
                    self.inference_jobs[model_label + '_inference'] = inf_job
                    self._wait_for_single_job(inf_job, f"inference:{model_label}")
                    # Step5: Post-process (ä¸‹è¼‰è¼¸å‡ºè³‡æ–™)
                    try:
                        outputs = inf_job.download_output_data()
                        self.inference_outputs[model_label] = {k: (np.array(v).shape if isinstance(v, list) else 'unknown') for k, v in outputs.items()}
                        logger.info(f"ğŸ§ª Step 5: è¼¸å‡ºæ‘˜è¦: {self.inference_outputs[model_label]}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ ä¸‹è¼‰æ¨è«–è¼¸å‡ºå¤±æ•— ({model_label}): {e}")
                except Exception as e:
                    logger.error(f"âŒ Inference Job æäº¤å¤±æ•— ({model_label}): {e}")
            # Step6: ä¸‹è¼‰æ¨¡å‹
            if model_label not in self.target_models:
                continue
            try:
                download_name = f"compiled_{model_label}.onnx"
                logger.info(f"ğŸ’¾ Step 6: ä¸‹è¼‰ target model -> {download_name}")
                # target_model å¯èƒ½æä¾› download æ–¹æ³•
                target_model = self.target_models[model_label]
                if hasattr(target_model, 'download'):
                    target_model.download(download_name)
                    logger.info(f"âœ… å·²ä¸‹è¼‰ {download_name}")
                else:
                    logger.warning(f"âš ï¸ target_model ç„¡ download æ–¹æ³•ï¼Œè·³éä¸‹è¼‰ ({model_label})")
            except Exception as e:
                logger.warning(f"âš ï¸ ä¸‹è¼‰æ¨¡å‹å¤±æ•— ({model_label}): {e}")
            logger.info(f"================ {model_label} DONE ==================")

        # è‹¥ä½¿ç”¨è€…è¦æ±‚ Python link (å¤šæ¨¡å‹æ‰“åŒ…) å¯åœ¨å®Œæˆå¾ŒåŸ·è¡Œ
        if getattr(self, 'python_link_requested', False):
            self._link_all_models_python()

    # ====== Link Job & ONNX åŒ¯å‡ºè¼”åŠ© ======
    def _submit_link_job_resilient(self, models: List[Any], name: str):
        """éŸŒæ€§å‘¼å« submit_link_jobï¼Œå˜—è©¦å¤šç¨®åƒæ•¸çµ„åˆä»¥å…¼å®¹ä¸åŒ SDK ç‰ˆæœ¬ã€‚"""
        attempts = [
            ("device", {"device": self.target_device, "name": name}),
            ("target_device", {"target_device": self.target_device, "name": name}),
            ("no_device", {"name": name}),
        ]
        errors = []
        for label, kwargs in attempts:
            try:
                job = hub.submit_link_job(models, **kwargs)
                logger.info(f"âœ… submit_link_job æˆåŠŸ ({label}) job_id={job.job_id}")
                return job
            except TypeError as te:
                errors.append(f"{label}:{te}")
            except Exception as e:
                errors.append(f"{label}:{e}")
        raise RuntimeError("æ‰€æœ‰ submit_link_job å‘¼å«å¤±æ•—: " + ' | '.join(errors))

    def _export_original_pose_onnx(self):
        """å°‡åŸå§‹ pose æ¨¡å‹åŒ¯å‡ºç‚º ONNX (é QNN DLC) ä»¥ä¾›æœ¬åœ° ORT ä½¿ç”¨ã€‚"""
        if 'pose_fall_detection' not in self.qai_hub_models:
            raise ValueError("pose_fall_detection æ¨¡å‹å°šæœªè¼‰å…¥")
        out_path = 'pose_fall_detection_original.onnx'
        if os.path.exists(out_path):
            return
        model = self.qai_hub_models['pose_fall_detection']
        try:
            import torch
            dummy = torch.randn(1,3,256,256)
            base = getattr(model, 'model', None) or model
            torch.onnx.export(base, dummy, out_path, input_names=['image'], output_names=['output'], opset_version=17, do_constant_folding=True)
            logger.info(f"ğŸ’¾ å·²åŒ¯å‡ºåŸå§‹å§¿æ…‹ ONNX -> {out_path}")
        except Exception as e:
            logger.warning(f"âš ï¸ åŒ¯å‡ºå§¿æ…‹ ONNX å¤±æ•—: {e}")

    def _export_all_original_onnx(self):
        """åŒ¯å‡º pose / face / hand åŸå§‹ ONNX ä¾›çµ±ä¸€æœ¬åœ°æ¨è«–æˆ–é©—è­‰ã€‚

        - pose: 256x256
        - face: å‡è¨­è¼¸å…¥ 3x256x256 (è‹¥æ¨¡å‹éœ€è¦å…¶ä»–å°ºå¯¸å¯å†èª¿æ•´)
        - hand: å‡è¨­è¼¸å…¥ 3x256x256
        è‹¥æ¨¡å‹ç„¡æ³•åŒ¯å‡ºæˆ–å°šæœªè¼‰å…¥å‰‡è·³éä¸¦è¨˜éŒ„è­¦å‘Šã€‚
        """
        try:
            self._export_original_pose_onnx()
        except Exception as e:
            logger.warning(f"âš ï¸ åŒ¯å‡º pose å¤±æ•— (ç•¥é): {e}")
        # Face
        if 'face_elderly_id' in self.qai_hub_models and not os.path.exists('face_elderly_id_original.onnx'):
            try:
                import torch
                dummy = torch.randn(1,3,256,256)
                base = getattr(self.qai_hub_models['face_elderly_id'], 'model', None) or self.qai_hub_models['face_elderly_id']
                torch.onnx.export(base, dummy, 'face_elderly_id_original.onnx', input_names=['image'], output_names=['output'], opset_version=17, do_constant_folding=True)
                logger.info("ğŸ’¾ å·²åŒ¯å‡º face_elderly_id_original.onnx")
            except Exception as e:
                logger.warning(f"âš ï¸ åŒ¯å‡º face åŸå§‹ ONNX å¤±æ•—: {e}")
        # Hand
        if 'hand_emergency_gesture' in self.qai_hub_models and not os.path.exists('hand_emergency_gesture_original.onnx'):
            try:
                import torch
                dummy = torch.randn(1,3,256,256)
                base = getattr(self.qai_hub_models['hand_emergency_gesture'], 'model', None) or self.qai_hub_models['hand_emergency_gesture']
                torch.onnx.export(base, dummy, 'hand_emergency_gesture_original.onnx', input_names=['image'], output_names=['output'], opset_version=17, do_constant_folding=True)
                logger.info("ğŸ’¾ å·²åŒ¯å‡º hand_emergency_gesture_original.onnx")
            except Exception as e:
                logger.warning(f"âš ï¸ åŒ¯å‡º hand åŸå§‹ ONNX å¤±æ•—: {e}")

    def _link_all_models_python(self):
        """ä½¿ç”¨å®˜æ–¹ API hub.submit_link_job å°‡å¤šå€‹å·²ç·¨è­¯çš„ target_models é€²è¡Œ linkã€‚

        æ³¨æ„: å®˜æ–¹ç¯„ä¾‹æ˜¯åŒä¸€æ¨¡å‹ä¸åŒè¼¸å…¥å°ºå¯¸ä»¥å…±äº«æ¬Šé‡; é€™è£¡æ˜¯ä¸åŒä»»å‹™æ¨¡å‹ (pose/face/hand),
        ä»å¯å˜—è©¦ç”¢å‡ºä¸€å€‹ context binary, ä½†æ¬Šé‡å…±äº«æ”¶ç›Šæœ‰é™ã€‚
        æ¢ä»¶: éœ€ç‚º Qualcomm AI Engine Direct (qnn_dlc) è¼¸å‡º; å·²åœ¨ compile æ™‚åŠ ä¸Š --target_runtime qnn_dlcã€‚
        """
        if not self.target_device:
            logger.warning("âš ï¸ ç„¡ç›®æ¨™è¨­å‚™, ç„¡æ³•åŸ·è¡Œ Python link")
            return
        # ç¢ºä¿ target_models éƒ½å·²å–å¾—
        for job_key, compile_job in self.compiled_models.items():
            label = job_key.replace('_job', '')
            if label not in self.target_models:
                try:
                    self._wait_for_single_job(compile_job, f"compile:{label}")
                    self.target_models[label] = compile_job.get_target_model()
                except Exception as e:
                    logger.warning(f"âš ï¸ ç„¡æ³•å–å¾— target_model ({label}): {e}ï¼Œè·³éè©²æ¨¡å‹çš„ link")
        models_to_link = [m for m in self.target_models.values() if m is not None]
        if len(models_to_link) < 2:
            logger.warning("âš ï¸ å¯ç”¨ target_models å°‘æ–¼2, è·³é link")
            return
        try:
            logger.info(f"ğŸ”— (Python API) submit_link_job: {len(models_to_link)} å€‹æ¨¡å‹ -> å–®ä¸€ context")
            link_job = self._submit_link_job_resilient(models_to_link, name="DragonX MultiModel Context")
            self.link_jobs['dragonx_python_link'] = {
                'job_id': link_job.job_id,
                'status': 'submitted',
                'dashboard_url': f'https://app.aihub.qualcomm.com/jobs/{link_job.job_id}'
            }
            # ç­‰å¾…å®Œæˆ (é™åˆ¶æ™‚é–“é¿å…é˜»å¡éä¹…)
            self._wait_for_single_job(link_job, 'link:dragonx_python', timeout=1800, poll=15)
            try:
                linked_model = link_job.get_target_model()
                if hasattr(linked_model, 'download'):
                    linked_model.download('dragonx_linked_context.bin')
                    logger.info("ğŸ’¾ å·²ä¸‹è¼‰ linked context -> dragonx_linked_context.bin")
            except Exception as e:
                logger.warning(f"âš ï¸ å–å¾—/ä¸‹è¼‰ linked model å¤±æ•—: {e}")
        except Exception as e:
            logger.error(f"âŒ Python link_job å¤±æ•—: {e}")

    def _attempt_link_jobs_cli(self):
        """é€é CLI å˜—è©¦æäº¤ link jobï¼ˆè‹¥ SDK ç„¡ Python APIï¼‰ã€‚"""
        cli = shutil.which('qai-hub')
        if not cli:
            logger.warning("âš ï¸ æœªæ‰¾åˆ° qai-hub CLIï¼Œè·³é link job")
            return
        if not self.target_device:
            logger.warning("âš ï¸ ç„¡ç›®æ¨™è¨­å‚™ï¼Œè·³é link job")
            return
        device_name = self.target_device.name
        device_os = getattr(self.target_device, 'os_version', None) or getattr(self.target_device, 'os', None)

        # 1. å–å¾— help è¼¸å‡ºä»¥å‹•æ…‹åµæ¸¬å¯ç”¨æ——æ¨™
        help_flags: List[str] = []
        try:
            help_proc = subprocess.run([cli, 'submit-link-job', '-h'], capture_output=True, text=True, timeout=30)
            help_text = (help_proc.stdout + '\n' + help_proc.stderr)
            for line in help_text.splitlines():
                line = line.strip()
                if line.startswith('--'):
                    # æ“·å–æ——æ¨™åç¨± (ç©ºç™½æˆ–=å‰)
                    flag = line.split()[0]
                    # ç§»é™¤æè¿°ä¸­é€—è™Ÿåˆ†éš”çš„å…¶ä»– alias
                    for part in flag.split(','):
                        if part.startswith('--'):
                            help_flags.append(part.strip())
            logger.info(f"ğŸ” Link CLI å¯ç”¨æ——æ¨™: {help_flags}")
            if self.debug_link:
                with open('qai_hub_submit_link_job_help.txt', 'w') as f:
                    f.write(help_text)
                logger.info("ğŸ’¾ å·²å„²å­˜ submit-link-job help åˆ° qai_hub_submit_link_job_help.txt")
        except Exception as e:
            logger.warning(f"âš ï¸ ç„¡æ³•å–å¾— submit-link-job help: {e} (æ¡ç”¨ä¿å®ˆçŒœæ¸¬)")

        # å¯èƒ½çš„æ¨¡å‹æ——æ¨™ (ä¾å„ªå…ˆé †åº)
        candidate_model_flags = [f for f in ['--model', '--model-id', '--model_id'] if f in help_flags]
        # å¯èƒ½çš„ compile job æ——æ¨™
        candidate_compile_flags = [f for f in ['--compile-job-id', '--compile_job_id', '--job-id', '--job_id'] if f in help_flags]
        # è£ç½®æ——æ¨™
        candidate_device_flags = [f for f in ['--device', '--target-device', '--target_device'] if f in help_flags]
        # OS æ——æ¨™
        candidate_device_os_flags = [f for f in ['--device-os', '--device_os', '--os-version'] if f in help_flags]

        for key, compile_job in self.compiled_models.items():
            model_label = key.replace('_job', '')
            if model_label in self.link_jobs:
                continue

            model_id = getattr(getattr(compile_job, 'model', None), 'model_id', None)
            compile_job_id = getattr(compile_job, 'job_id', None)

            # å»ºç«‹åˆå§‹å‘½ä»¤ (ä¿å®ˆ: åªåŠ æˆ‘å€‘ç¢ºå®šå­˜åœ¨çš„æ——æ¨™)
            base_cmd = [cli, 'submit-link-job']

            # å„ªå…ˆä½¿ç”¨ compile job id (è‹¥ CLI æ”¯æ´)
            if compile_job_id and candidate_compile_flags:
                base_cmd += [candidate_compile_flags[0], compile_job_id]
            elif model_id and candidate_model_flags:
                base_cmd += [candidate_model_flags[0], model_id]
            elif model_id:
                # å˜—è©¦ positional model id (ç„¡æ——æ¨™)
                base_cmd.append(model_id)

            # Device
            if candidate_device_flags:
                base_cmd += [candidate_device_flags[0], device_name]
            else:
                # å˜—è©¦æ¨æ¸¬ --device (å³ä¾¿ help æœªåˆ—å‡º, æœ€å¸¸è¦‹)
                base_cmd += ['--device', device_name]

            # Device OS (åƒ…åœ¨æ——æ¨™å­˜åœ¨æ‰åŠ )
            if device_os and candidate_device_os_flags:
                base_cmd += [candidate_device_os_flags[0], str(device_os)]

            # ä¸€äº› CLI æ²’æœ‰ --output json, æ•…åƒ…åœ¨ help æœ‰åˆ—å‡ºæ™‚æ‰åŠ å…¥
            if '--output' in help_flags or '--format' in help_flags:
                if '--output' in help_flags:
                    base_cmd += ['--output', 'json']
                else:
                    base_cmd += ['--format', 'json']

            if self.debug_link:
                base_cmd.append('--verbose') if '--verbose' in help_flags else None
            logger.info(f"ğŸ”— å˜—è©¦æäº¤ Link Job (åˆå§‹): {' '.join(base_cmd)}")

            # è¿­ä»£å˜—è©¦, è‹¥å‡ºç¾ unrecognized arguments, å‹•æ…‹ç§»é™¤
            attempt_cmd = list(base_cmd)
            raw_capture = ''
            success = False
            attempt_logs: List[str] = []
            for attempt in range(6):
                try:
                    proc = subprocess.run(attempt_cmd, capture_output=True, text=True, timeout=180)
                    stdout = proc.stdout.strip()
                    stderr = proc.stderr.strip()
                    raw_capture = (stdout + '\n' + stderr)
                    if self.debug_link:
                        attempt_logs.append(f"Attempt {attempt+1} CMD: {' '.join(attempt_cmd)}\n--- STDOUT ---\n{stdout}\n--- STDERR ---\n{stderr}\n")

                    # åµæ¸¬æœªæ”¯æ´æ——æ¨™ä¸¦ç§»é™¤
                    m = re.search(r'unrecognized arguments?: (.+)', raw_capture)
                    if m:
                        unknown_parts = m.group(1).split()
                        # å˜—è©¦ç§»é™¤å‡ºç¾æ–¼å‘½ä»¤åˆ—çš„æ——æ¨™ (èˆ‡å…¶å¾Œå€¼)
                        removed_any = False
                        for up in unknown_parts:
                            token = up.strip(',')
                            if token in attempt_cmd:
                                idx = attempt_cmd.index(token)
                                # åŒæ™‚ç§»é™¤å¾Œä¸€å€‹å€¼ (è‹¥å­˜åœ¨ä¸”éä»¥--é–‹é ­)
                                removal = [attempt_cmd[idx]]
                                if idx + 1 < len(attempt_cmd) and not attempt_cmd[idx+1].startswith('--'):
                                    removal.append(attempt_cmd[idx+1])
                                for r in removal:
                                    attempt_cmd.remove(r)
                                removed_any = True
                        if removed_any:
                            logger.warning(f"âš ï¸ ç§»é™¤æœªæ”¯æ´æ——æ¨™å¾Œé‡è©¦: {' '.join(attempt_cmd)}")
                            continue  # é‡è·‘ä¸‹ä¸€è¼ª

                    # è§£æ job id
                    job_id = None
                    # Regex 1: æ‹¬è™Ÿå½¢å¼ (jxxxxxxx)
                    m2 = re.search(r'\(j[a-z0-9]{6,}\)', raw_capture, re.IGNORECASE)
                    if m2:
                        job_id = m2.group(0).strip('()')
                    if not job_id:
                        # ç›´æ¥ token æƒæ
                        for token in raw_capture.split():
                            t = token.strip('(),.\r\n')
                            if re.fullmatch(r'j[a-z0-9]{6,}', t.lower()):
                                job_id = t
                                break
                    if job_id:
                        self.link_jobs[model_label + '_link'] = {
                            'job_id': job_id,
                            'status': 'submitted',
                            'dashboard_url': f'https://app.aihub.qualcomm.com/jobs/{job_id}'
                        }
                        logger.info(f"âœ… Link Job æäº¤æˆåŠŸ: {job_id}")
                        success = True
                        break
                    else:
                        # è‹¥æ²’æœ‰ unrecognized è€Œä¹Ÿæ²’ job id, å¯èƒ½éœ€è¦æ› model / compile id æ——æ¨™ç­–ç•¥
                        if attempt == 0 and model_id and compile_job_id and candidate_model_flags and candidate_compile_flags:
                            # äº¤æ›¿ä½¿ç”¨å¦ä¸€ç¨®é¡æ——æ¨™
                            if candidate_model_flags[0] in attempt_cmd:
                                # æ›æˆ compile æ——æ¨™
                                for f in candidate_model_flags:
                                    if f in attempt_cmd:
                                        idx = attempt_cmd.index(f)
                                        # åˆªé™¤æ——æ¨™èˆ‡å…¶å€¼
                                        del attempt_cmd[idx:idx+2]
                                attempt_cmd += [candidate_compile_flags[0], compile_job_id]
                            else:
                                for f in candidate_compile_flags:
                                    if f in attempt_cmd:
                                        idx = attempt_cmd.index(f)
                                        del attempt_cmd[idx:idx+2]
                                attempt_cmd += [candidate_model_flags[0], model_id]
                            logger.warning(f"âš ï¸ åˆ‡æ›æ——æ¨™ç­–ç•¥é‡è©¦: {' '.join(attempt_cmd)}")
                            continue
                        logger.warning(f"âš ï¸ æœªè§£æåˆ° Link Job ID (å˜—è©¦æ¬¡æ•¸ {attempt+1})")
                except Exception as e:
                    logger.warning(f"âš ï¸ Link Job åŸ·è¡ŒéŒ¯èª¤ (é‡è©¦ {attempt+1}): {e}")
                    time.sleep(1)
            if not success:
                self.link_jobs[model_label + '_link'] = {
                    'job_id': None,
                    'status': 'parse_failed',
                    'raw_output': raw_capture[:800] if raw_capture else 'no_output'
                }
                logger.warning(f"âš ï¸ ç„¡æ³•è§£æ Link Job ID ({model_label}) - å·²è¨˜éŒ„ raw_output")
            if self.debug_link:
                log_path = f'link_attempt_{model_label}.log'
                try:
                    with open(log_path, 'w') as f:
                        f.write('\n'.join(attempt_logs) or raw_capture or 'no output captured')
                    logger.info(f"ğŸ’¾ å·²å„²å­˜ link é™¤éŒ¯ç´€éŒ„: {log_path}")
                except Exception as e:
                    logger.warning(f"âš ï¸ ç„¡æ³•å¯«å…¥é™¤éŒ¯æª” {log_path}: {e}")

    def _wait_for_single_job(self, job_obj, label: str, timeout: int = 1800, poll: int = 10):
        """è¼ªè©¢ç­‰å¾…å–®ä¸€ job å®Œæˆã€‚timeout ç§’å¾Œæ”¾æ£„ (æ¨™è¨˜ç‚º still_running)ã€‚"""
        start = time.time()
        while True:
            try:
                job_obj.wait(timeout=1)
                return True
            except Exception:
                pass
            elapsed = time.time() - start
            if elapsed >= timeout:
                logger.warning(f"âš ï¸ ç­‰å¾…è¶…æ™‚ ({timeout}s) job ä»æœªå®Œæˆ: {label}")
                return False
            if int(elapsed) % (poll) == 0:
                logger.info(f"â³ {label} é€²è¡Œä¸­... å·²ç­‰å¾… {int(elapsed)}s")
            time.sleep(1)

    def wait_for_all_jobs(self):
        """ç­‰å¾…æ‰€æœ‰ compile / profile job å®Œæˆï¼ˆlink ç‚º CLI æš«ä¸è¼ªè©¢ï¼‰ã€‚"""
        logger.info("â³ ç­‰å¾…æ‰€æœ‰ QAI Hub Jobs å®Œæˆ (compile + profile)...")
        unfinished = True
        last_status_emit = 0
        while unfinished:
            unfinished = False
            status_snapshot = {}
            # Compile jobs
            for name, job in self.compiled_models.items():
                try:
                    job.wait(timeout=1)
                    status_snapshot[name] = 'completed'
                except Exception:
                    status_snapshot[name] = 'running'
                    unfinished = True
            # Profile jobs
            for name, job in self.profile_jobs.items():
                try:
                    job.wait(timeout=1)
                    status_snapshot[name] = 'completed'
                except Exception:
                    status_snapshot[name] = 'running'
                    unfinished = True
            now = time.time()
            if now - last_status_emit > self.poll_interval:
                last_status_emit = now
                compiling = [k for k,v in status_snapshot.items() if v != 'completed']
                logger.info(f"ğŸ“Š Job ç‹€æ…‹: å®Œæˆ {len(status_snapshot)-len(compiling)}/{len(status_snapshot)}; é€²è¡Œä¸­: {', '.join(compiling) if compiling else 'ç„¡'}")
            if unfinished:
                time.sleep(self.poll_interval)
        logger.info("âœ… æ‰€æœ‰ compile / profile jobs å·²å®Œæˆ")

    def export_pipeline_status(self, path: str = 'dragon_x_pipeline_status.json'):
        report = self.get_dragon_x_status_report()
        with open(path, 'w') as f:
            json.dump(report, f, indent=2, default=str)
        logger.info(f"ğŸ“ Pipeline ç‹€æ…‹å·²è¼¸å‡º: {path}")

    # ================== æ–°å¢: ä¸‹è¼‰æª”æ¡ˆæ­£è¦åŒ–èˆ‡æ‘˜è¦å·¥å…· ==================
    def _normalize_and_extract_download(self, label: str):
        """è™•ç†å¯èƒ½çš„ä¸‹è¼‰å£“ç¸®æª”èˆ‡é›™é‡å‰¯æª”å, ç”¢å‡º compiled_{label}.onnx / .onnx.dlcã€‚

        è¦å‰‡:
        1. æœå°‹å¯èƒ½çš„ zip: compiled_{label}*, *_raw_download*
        2. è‹¥ zip å…§å« .onnx æˆ– .dlc, è§£å£“ä¸¦æ”¾åˆ°å·¥ä½œç›®éŒ„
        3. è‹¥åªå¾— .dlc, å»ºç«‹ compiled_{label}.onnx.dlc ä¸¦å˜—è©¦è¤‡è£½ç‚º compiled_{label}.onnx (ä¾› ORT å˜—è©¦)
        4. æ¸…ç†æš«å­˜æª”
        """
        base_prefix = f"compiled_{label}"
        target_onnx = f"{base_prefix}.onnx"
        # å…ˆæª¢æŸ¥ç¾æˆ .onnx
        if os.path.exists(target_onnx):
            return
        # æœå°‹ zip candidates
        candidates = [f for f in os.listdir('.') if f.startswith(base_prefix) and f.endswith('.zip')]
        for zip_name in candidates:
            try:
                with zipfile.ZipFile(zip_name, 'r') as zf:
                    members = zf.namelist()
                    extract_dir = f"_extract_{base_prefix}"
                    if os.path.exists(extract_dir):
                        shutil.rmtree(extract_dir, ignore_errors=True)
                    zf.extractall(extract_dir)
                    picked = None
                    for m in members:
                        low = m.lower()
                        if low.endswith('.onnx') or low.endswith('.dlc'):
                            picked = m
                            break
                    if not picked:
                        logger.warning(f"âš ï¸ {zip_name} æœªæ‰¾åˆ° .onnx/.dlc")
                        continue
                    src_path = os.path.join(extract_dir, picked)
                    # æ±ºå®šç›®çš„æª”å
                    if picked.lower().endswith('.dlc'):
                        dlc_out = f"compiled_{label}.dlc"
                        shutil.copyfile(src_path, dlc_out)
                        logger.info(f"ğŸ“¦ å·²è§£å£“ DLC -> {dlc_out}")
                    else:
                        shutil.copyfile(src_path, target_onnx)
                        logger.info(f"ğŸ“¦ å·²è§£å£“ ONNX -> {target_onnx}")
            except zipfile.BadZipFile:
                logger.warning(f"âš ï¸ å£“ç¸®æª”æå£: {zip_name}")
            except Exception as e:
                logger.warning(f"âš ï¸ è§£å£“ {zip_name} å¤±æ•—: {e}")
        # æ¸…ç†æš«å­˜ extract ç›®éŒ„
        for d in os.listdir('.'):
            if d.startswith(f"_extract_{base_prefix}") and os.path.isdir(d):
                shutil.rmtree(d, ignore_errors=True)

    def _validate_onnx_file(self, path: str) -> bool:
        if not os.path.exists(path):
            return False
        if onnx is None:
            return True  # ç„¡æ³•é©—è­‰, è¦–ç‚ºå­˜åœ¨
        try:
            onnx.load(path)
            return True
        except Exception:
            return False

    def _gather_edge_model_summary(self) -> Dict[str, Any]:
        summary: Dict[str, Any] = {}
        for f in os.listdir('.'):
            if f.startswith('compiled_') and (f.endswith('.onnx') or f.endswith('.dlc')):
                info = {
                    'size': os.path.getsize(f),
                    'valid_onnx': f.endswith('.onnx') and self._validate_onnx_file(f),
                    'type': 'dlc' if f.endswith('.dlc') else 'onnx'
                }
                # ç°¡å–® header æª¢æŸ¥ (é¿å…èª¤åˆ¤) - DLC å¸¸éåˆæ³• ONNX magic
                if f.endswith('.onnx') and not info['valid_onnx']:
                    try:
                        with open(f, 'rb') as rf:
                            magic = rf.read(4)
                        info['header'] = magic.hex()
                    except Exception:
                        pass
                summary[f] = info
        return summary

    def _summarize_edge_models(self):
        summary = self._gather_edge_model_summary()
        if not summary:
            logger.info("â„¹ï¸ å°šç„¡ Edge æ¨¡å‹æª”æ¡ˆ (compiled_*.onnx)")
            return
        logger.info("ğŸ§¾ Edge æ¨¡å‹æ‘˜è¦:")
        for name, info in summary.items():
            vflag = 'âœ…' if info['valid_onnx'] else ('ğŸ“¦' if info['type']=='dlc' else 'âš ï¸')
            extra = ' (åˆæ³•ONNX)' if info['valid_onnx'] else (' (DLCæª”æ¡ˆ)' if info['type']=='dlc' else '')
            logger.info(f"   {name} ({info['size']} bytes) {vflag}{extra}")
        # å¦‚æœæ²’æœ‰ä»»ä½• valid ONNX ä½†æœ‰ dlc, æç¤ºä½¿ç”¨è€… (é¿å…é‡è¤‡ typo)
        if all((not i['valid_onnx']) for i in summary.values()):
            logger.warning("âš ï¸ æœªåµæ¸¬åˆ°å¯é©—è­‰ ONNX; ç›®å‰å¯èƒ½åƒ…æœ‰ DLC. æœ¬åœ° ORT+QNN EP å¤šåŠç›´æ¥ä½¿ç”¨åŸå§‹ ONNX è€Œé DLC, å»ºè­°åŒæ™‚ä¿ç•™ pose_fall_detection_original.onnxã€‚")

    def _get_preferred_providers(self):
        providers = ort.get_available_providers()
        # é è¨­å„ªå…ˆé †åº
        order = ['QNNExecutionProvider', 'QNN', 'CUDAExecutionProvider', 'DmlExecutionProvider', 'CPUExecutionProvider']
        preferred = []
        for p in order:
            if p in providers and p not in preferred:
                preferred.append(p)
        # å¢å¼·: è‹¥ä½¿ç”¨è€…æœªè¦æ±‚ QNN, ä»ä¿æŒé †åº; è‹¥è¦æ±‚ QNN ä½† QNN ä¸å­˜åœ¨, ä»å¯ fallback (é™¤é force_qnn)
        if not preferred:
            preferred = providers
        qnn_active = any(p.startswith('QNN') for p in preferred if p in providers)
        if self.use_qnn and not qnn_active and 'QNNExecutionProvider' in providers:
            # æ’å…¥ QNNExecutionProvider åˆ°æœ€å‰
            preferred = ['QNNExecutionProvider'] + [p for p in preferred if p != 'QNNExecutionProvider']
            qnn_active = True
        return providers, preferred, qnn_active

def main():
    """ä¸»å‡½æ•¸ï¼šDragon Xè€äººè·Œå€’é é˜²æª¢æ¸¬ç³»çµ±æ¸¬è©¦ / Pipeline / Edge"""
    parser = argparse.ArgumentParser(description='Dragon X è·Œå€’é é˜²ç³»çµ±')
    parser.add_argument('--full-pipeline', action='store_true', help='åŸ·è¡Œ Compileâ†’Profileâ†’(Link) å®Œæ•´æµç¨‹ä¸¦è¼¸å‡ºç‹€æ…‹')
    parser.add_argument('--wait', action='store_true', help='ç­‰å¾…æ‰€æœ‰é›²ç«¯ Jobs å®Œæˆ')
    parser.add_argument('--poll-interval', type=int, default=15, help='Job è¼ªè©¢ç§’æ•¸ (default:15)')
    parser.add_argument('--export-status', action='store_true', help='é¡å¤–è¼¸å‡º pipeline ç‹€æ…‹ JSON')
    parser.add_argument('--debug-link', action='store_true', help='è¼¸å‡º link job é™¤éŒ¯è³‡è¨Šä¸¦ä¿å­˜ log æª”')
    parser.add_argument('--link-python', action='store_true', help='ä½¿ç”¨ Python API submit_link_job å°å·²ç·¨è­¯æ¨¡å‹é€²è¡Œ link')
    parser.add_argument('--image', type=str, help='æä¾›æœ¬åœ°å½±åƒè·¯å¾‘ä»¥é€²è¡Œå¯¦éš›æœ¬åœ°æ¨è«– (å§¿æ…‹)')
    parser.add_argument('--export-local-onnx', action='store_true', help='å•Ÿå‹•å¾Œå°‡åŸå§‹å§¿æ…‹æ¨¡å‹åŒ¯å‡ºç‚º ONNX ä¾›æœ¬åœ°æ¨è«–')
    # Edge flags
    parser.add_argument('--wait-compile', action='store_true', help='åƒ…ç­‰å¾…æ—¢æœ‰ compile/profile jobs å®Œæˆ (ä¸è‡ªå‹•åŸ·è¡Œ full pipeline)')
    parser.add_argument('--download-compiled', action='store_true', help='ä¸‹è¼‰ compiled_{model}.onnx ä¾› edge æ¨è«–')
    parser.add_argument('--realtime', action='store_true', help='å»ºç«‹æœ¬åœ° ONNX å³æ™‚æ”å½±æ©Ÿæ¨è«–')
    parser.add_argument('--camera-index', type=int, default=0, help='æ”å½±æ©Ÿç´¢å¼• (realtime)')
    parser.add_argument('--max-frames', type=int, default=None, help='å³æ™‚æ¨è«–æœ€å¤§å½±æ ¼ (æ¸¬è©¦ç”¨)')
    parser.add_argument('--edge-only', action='store_true', help='åƒ…ä½¿ç”¨å·²å­˜åœ¨çš„ compiled_*.onnx / åŸå§‹ONNXï¼Œä¸é‡æ–°æäº¤é›²ç«¯ç·¨è­¯')
    parser.add_argument('--no-qnn-dlc', action='store_true', help='ç·¨è­¯æ™‚ä¸åŠ å…¥ --target_runtime qnn_dlc (ç”¢å‡ºç´” ONNX target model)')
    parser.add_argument('--offline', action='store_true', help='é›¢ç·šæ¨¡å¼ï¼šè·³é QAI Hub è£ç½®æœå°‹èˆ‡æ¨¡å‹é›²ç«¯æ“ä½œï¼Œåƒ…æ¸¬è©¦æœ¬åœ°æµç¨‹')
    parser.add_argument('--version', action='store_true', help='é¡¯ç¤ºç³»çµ±ç‰ˆæœ¬å¾Œé›¢é–‹')
    # QNN / NPU ç›¸é—œ
    parser.add_argument('--use-qnn', action='store_true', help='è‹¥å¯ç”¨å‰‡å„ªå…ˆä½¿ç”¨ QNNExecutionProvider/NPU')
    parser.add_argument('--force-qnn', action='store_true', help='å¼·åˆ¶è¦æ±‚ QNNExecutionProviderï¼Œå¦å‰‡å ±éŒ¯ (ç”¨æ–¼æª¢æŸ¥ç’°å¢ƒ)')
    # Demo / é¢¨éšªæ¨¡æ“¬
    parser.add_argument('--simulate-fall', action='store_true', help='æ¨¡æ“¬é«˜è·Œå€’é¢¨éšª (ä¸ä¾å¯¦éš›æ¨¡å‹è¼¸å‡º)')
    parser.add_argument('--demo-pose', action='store_true', help='ä½¿ç”¨å‹•æ…‹ç”Ÿæˆçš„ demo pose è³‡æ–™ (ç„¡é ˆå¯¦éš›æ¨¡å‹)')
    # Edge æ¨¡å‹æ‘˜è¦
    parser.add_argument('--summarize-edge', action='store_true', help='ä¸‹è¼‰å¾Œåˆ—å‡ºç·¨è­¯æ¨¡å‹æª”æ¡ˆæ‘˜è¦')
    args = parser.parse_args()

    print("ğŸ‰ Dragon Xè€äººè·Œå€’é é˜²æª¢æ¸¬ç³»çµ±")
    print("=" * 60)
    print("ğŸ¯ å°ˆç‚ºé»‘å®¢æ¾æ‰“é€ çš„Snapdragon X Eliteå¹³å°è§£æ±ºæ–¹æ¡ˆ")
    print()
    if args.version:
        print(f"Dragon X System Version: {__DRAGON_X_SYSTEM_VERSION__}")
        return
    
    try:
        dragon_system = DragonXFallDetectionSystem(
            full_pipeline=args.full_pipeline, wait=args.wait, poll_interval=args.poll_interval,
            debug_link=args.debug_link, link_python=args.link_python, export_local_onnx=args.export_local_onnx,
            wait_compile_only=args.wait_compile, download_compiled=args.download_compiled,
            realtime=args.realtime, camera_index=args.camera_index, max_frames=args.max_frames,
            edge_only=args.edge_only, no_qnn_dlc=args.no_qnn_dlc, offline=args.offline,
            use_qnn=args.use_qnn, force_qnn=args.force_qnn,
            simulate_fall=args.simulate_fall, demo_pose=args.demo_pose,
            summarize_edge=args.summarize_edge
        )
        status_report = dragon_system.get_dragon_x_status_report()
        print("ğŸ“Š Dragon Xç³»çµ±ç‹€æ…‹:")
        print(f"   ğŸ‰ ç›®æ¨™è¨­å‚™: {status_report['dragon_x_device']['name']}")
        print(f"   ğŸ“± è¨­å‚™ç‹€æ…‹: {status_report['dragon_x_device']['status']}")
        print(f"   ğŸ§  å·²è¼‰å…¥æ¨¡å‹: {len(status_report['models_status'])}")
        print(f"   âš¡ Compile Jobs: {len(status_report['qai_hub_jobs'])}")
        print(f"   ğŸ“ˆ Profile Jobs: {len(status_report['profile_jobs'])}")
        print(f"   ğŸ”— Link Jobs: {len(status_report['link_jobs'])}")
        print(f"   ğŸ’¾ å·²ä¸‹è¼‰ Edge æ¨¡å‹: {[f for f in os.listdir('.') if f.startswith('compiled_') and f.endswith('.onnx')]}")
        print()

        print("ğŸ”— Compile Jobs:")
        for job_name, job_info in status_report['qai_hub_jobs'].items():
            print(f"   {job_name}: {job_info['job_id']} ({job_info['status']})")
            print(f"      Dashboard: {job_info['dashboard_url']}")
        if status_report['profile_jobs']:
            print("\nğŸ“ˆ Profile Jobs:")
            for name, info in status_report['profile_jobs'].items():
                print(f"   {name}: {info['job_id']} ({info['status']})")
                print(f"      Dashboard: {info['dashboard_url']}")
        if status_report['link_jobs']:
            print("\nğŸ”— Link Jobs:")
            for name, info in status_report['link_jobs'].items():
                print(f"   {name}: {info.get('job_id') or 'N/A'} ({info.get('status')})")
                if 'dashboard_url' in info:
                    print(f"      Dashboard: {info['dashboard_url']}")

        print("\nğŸ§ª æ¸¬è©¦è·Œå€’é é˜²æª¢æ¸¬ (æœ¬åœ°/Edge)...")
        if (args.download_compiled or args.use_qnn or args.edge_only) and not args.realtime:
            print("ğŸ’¡ å°šæœªå•Ÿå‹•æ”å½±æ©Ÿå³æ™‚æ¨è«–ã€‚è‹¥è¦é–‹å•Ÿé¡é ­è«‹åŠ  --realtime (å¯æ­é… --max-frames 120)ã€‚")
            print("   ç¯„ä¾‹: python dragon_x_fall_detection_system.py --edge-only --realtime --use-qnn --max-frames 200")
        if args.image and os.path.exists(args.image):
            img = cv2.imread(args.image)
            if img is None:
                print(f"âš ï¸ ç„¡æ³•è®€å–å½±åƒ {args.image}ï¼Œæ”¹ç”¨éš¨æ©Ÿåœ–åƒ")
                img = np.random.randint(0,255,(480,640,3),dtype=np.uint8)
        else:
            if args.image:
                print(f"âš ï¸ æŒ‡å®šå½±åƒä¸å­˜åœ¨: {args.image}ï¼Œæ”¹ç”¨éš¨æ©Ÿåœ–åƒ")
            img = np.random.randint(0,255,(480,640,3),dtype=np.uint8)
        detection_results = dragon_system.comprehensive_fall_prevention_detection(img)

        print("âœ… è·Œå€’é é˜²åˆ†æçµæœ:")
        fall_analysis = detection_results.get('fall_prevention_analysis', {})
        print(f"   {fall_analysis.get('message', 'æœªçŸ¥ç‹€æ…‹')}")
        print(f"   é¢¨éšªè©•åˆ†: {fall_analysis.get('risk_score', 0):.2f}")
        print(f"   å»ºè­°: {fall_analysis.get('recommendation', 'ç„¡å»ºè­°')}")
        if fall_analysis.get('indicators'):
            print(f"   é¢¨éšªæŒ‡æ¨™: {', '.join(fall_analysis['indicators'])}")

        # ä¿å­˜å ±å‘Š
        with open('dragon_x_fall_detection_report.json', 'w') as f:
            json.dump({
                "status_report": status_report,
                "detection_results": detection_results
            }, f, indent=2, default=str)
        print("\nğŸ“ Dragon Xå ±å‘Šå·²ä¿å­˜: dragon_x_fall_detection_report.json")

        if args.export_status:
            dragon_system.export_pipeline_status()

        print("ğŸ‰ å®Œæˆ!")
        if args.full_pipeline:
            print("ğŸ å®Œæ•´Pipelineå·²åŸ·è¡Œ (Compileâ†’Profileâ†’Link[å˜—è©¦])")
        else:
            print("â„¹ï¸ ä½¿ç”¨ --full-pipeline å¯åŸ·è¡Œå®Œæ•´æµç¨‹")
        if args.wait_compile:
            print("â³ å·²ç­‰å¾… compile/profile jobs å®Œæˆ")
        if args.download_compiled:
            print("ğŸ’¾ å·²å˜—è©¦ä¸‹è¼‰ compiled_{model}.onnx")
        if args.realtime:
            print("ğŸ¥ å·²å•Ÿå‹•/çµæŸå³æ™‚æ¨è«–")
        print("ğŸ’¡ ä½¿ç”¨ --wait å¯ç­‰å¾…é›²ç«¯Jobså®Œæˆ, --export-status è¼¸å‡ºJSONç‹€æ…‹")

    except Exception as e:
        print(f"âŒ Dragon Xç³»çµ±åˆå§‹åŒ–å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
