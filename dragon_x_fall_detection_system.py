#!/usr/bin/env python3
"""
ğŸ‰ Dragon Xå°ˆç”¨è€äººè·Œå€’é é˜²æª¢æ¸¬ç³»çµ±
å°ˆç‚ºé»‘å®¢æ¾å„ªåŒ–ï¼Œä½¿ç”¨Snapdragon X Eliteå¹³å°
"""

import os
import sys
import subprocess
import shutil
import qai_hub as hub
import numpy as np
import cv2
import onnxruntime as ort
import logging
try:
    from dotenv import load_dotenv  # type: ignore
except ImportError:  # make optional
    def load_dotenv(*args, **kwargs):
        print("âš ï¸ æœªå®‰è£ python-dotenvï¼Œè·³é .env è¼‰å…¥ (å¯åŸ·è¡Œ: pip install python-dotenv)")
        return False
from typing import Dict, Any, List, Optional
import time
import json
import argparse
import re

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DragonXFallDetectionSystem:
    """Dragon Xå°ˆç”¨è€äººè·Œå€’é é˜²æª¢æ¸¬ç³»çµ±"""

    def __init__(self, full_pipeline: bool = False, wait: bool = False, poll_interval: int = 15, debug_link: bool = False, link_python: bool = False):
        """åˆå§‹åŒ–Dragon Xæª¢æ¸¬ç³»çµ±

        Args:
            full_pipeline: æ˜¯å¦åŸ·è¡Œ Compileâ†’Profileâ†’Inference (å®˜æ–¹ç¤ºä¾‹æ­¥é©Ÿ)
            wait: æ˜¯å¦ç­‰å¾…æ‰€æœ‰ Job å®Œæˆ
            poll_interval: è¼ªè©¢ç§’æ•¸
            debug_link: æ˜¯å¦è¼¸å‡º link job é™¤éŒ¯è³‡è¨Š
            link_python: æ˜¯å¦ä½¿ç”¨ Python API submit_link_job é€²è¡Œå¤šæ¨¡å‹ link (å¦å‰‡åƒ…å˜—è©¦ CLI)
        """
        # åŸºæœ¬å±¬æ€§
        self.api_token = os.getenv('QAI_HUB_API_TOKEN')
        self.target_device = None
        # æ¨¡å‹èˆ‡å·¥ä½œè¿½è¹¤
        self.qai_hub_models: Dict[str, Any] = {}
        self.compiled_models: Dict[str, Any] = {}
        self.onnx_sessions: Dict[str, Any] = {}
        self.profile_jobs: Dict[str, Any] = {}
        self.link_jobs: Dict[str, Any] = {}
        self.target_models: Dict[str, Any] = {}
        self.inference_jobs: Dict[str, Any] = {}
        self.inference_outputs: Dict[str, Any] = {}
        # åŸ·è¡Œåƒæ•¸
        self.full_pipeline = full_pipeline
        self.wait_for_jobs = wait
        self.poll_interval = poll_interval
        self.debug_link = debug_link  # æ˜¯å¦è¼¸å‡º link job é™¤éŒ¯è³‡è¨Š
        self.python_link_requested = link_python

        logger.info("ğŸ‰ åˆå§‹åŒ–Dragon Xè€äººè·Œå€’é é˜²æª¢æ¸¬ç³»çµ±...")
        self._find_dragon_x_devices()
        self._initialize_fall_detection_models()

        if self.full_pipeline:
            logger.info("ğŸ§ª å•Ÿå‹•å®Œæ•´å®˜æ–¹æµç¨‹ (Step 1~6 for each model)")
            self._run_full_official_steps_for_all_models()
            # å¦‚æœä½¿ç”¨ Python link å…ˆåŸ·è¡Œ (å®˜æ–¹ API)ï¼›å¦å‰‡å˜—è©¦ CLIï¼›è‹¥å…©è€…éƒ½æƒ³è¦å¯è‡ªè¡Œå†å‘¼å«
            if self.python_link_requested:
                self._link_all_models_python()
            else:
                self._attempt_link_jobs_cli()
    
    def _find_dragon_x_devices(self):
        """å°‹æ‰¾ä¸¦é¸æ“‡Dragon Xè¨­å‚™"""
        if not self.api_token:
            raise ValueError("âŒ è«‹åœ¨.envæ–‡ä»¶ä¸­è¨­ç½®QAI_HUB_API_TOKEN")
        
        try:
            devices = hub.get_devices()
            logger.info(f"ğŸ” æœå°‹QAI Hubè¨­å‚™...")
            logger.info(f"   ç¸½è¨­å‚™æ•¸é‡: {len(devices)}")
            
            # åˆ†é¡è¨­å‚™
            dragon_x_devices = []
            snapdragon_devices = []
            other_devices = []
            
            for device in devices:
                device_name = device.name.lower()
                if 'x elite' in device_name or 'snapdragon x' in device_name or 'dragon x' in device_name:
                    dragon_x_devices.append(device)
                elif 'snapdragon' in device_name:
                    snapdragon_devices.append(device)
                else:
                    other_devices.append(device)
            
            # é¡¯ç¤ºè¨­å‚™åˆ†é¡
            logger.info(f"ğŸ“Š è¨­å‚™åˆ†é¡çµæœ:")
            logger.info(f"   ğŸ‰ Dragon X / Snapdragon X Elite: {len(dragon_x_devices)}")
            logger.info(f"   ğŸ”¥ å…¶ä»–Snapdragonè¨­å‚™: {len(snapdragon_devices)}")
            logger.info(f"   ğŸ“± å…¶ä»–è¨­å‚™: {len(other_devices)}")
            
            # é¸æ“‡æœ€ä½³è¨­å‚™
            if dragon_x_devices:
                self.target_device = dragon_x_devices[0]
                logger.info(f"ğŸ‰ æˆåŠŸé¸å®šDragon Xè¨­å‚™!")
                logger.info(f"   ğŸ‰ è¨­å‚™åç¨±: {self.target_device.name}")
                logger.info(f"   âœ¨ é»‘å®¢æ¾ä¸»æ‰“å¹³å°å·²å°±ç·’!")
                
                # é¡¯ç¤ºæ‰€æœ‰Dragon Xè¨­å‚™é¸é …
                if len(dragon_x_devices) > 1:
                    logger.info(f"   ğŸ“‹ å…¶ä»–å¯ç”¨Dragon Xè¨­å‚™:")
                    for i, device in enumerate(dragon_x_devices[1:], 1):
                        logger.info(f"      {i}. {device.name}")
                        
            elif snapdragon_devices:
                self.target_device = snapdragon_devices[0]
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°Dragon Xï¼Œä½¿ç”¨Snapdragonè¨­å‚™:")
                logger.info(f"   ğŸ”¥ è¨­å‚™åç¨±: {self.target_device.name}")
                
            else:
                self.target_device = devices[0] if devices else None
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°Snapdragonè¨­å‚™ï¼Œä½¿ç”¨é è¨­è¨­å‚™:")
                logger.info(f"   ğŸ“± è¨­å‚™åç¨±: {self.target_device.name if self.target_device else 'None'}")
            
            return self.target_device
            
        except Exception as e:
            logger.error(f"âŒ è¨­å‚™æœå°‹å¤±æ•—: {e}")
            raise
    
    def _initialize_fall_detection_models(self):
        """åˆå§‹åŒ–è·Œå€’æª¢æ¸¬æ‰€éœ€çš„æ¨¡å‹"""
        logger.info("ğŸ§  è¼‰å…¥è€äººè·Œå€’é é˜²æª¢æ¸¬æ¨¡å‹...")
        
        try:
            # å§¿æ…‹æª¢æ¸¬æ˜¯è·Œå€’æª¢æ¸¬çš„æ ¸å¿ƒ
            self._load_pose_detection_for_fall_prevention()
            
            # äººè‡‰æª¢æ¸¬ç”¨æ–¼ç¢ºèªè€äººèº«ä»½
            self._load_face_detection_for_elderly_identification()
            
            # æ‰‹éƒ¨æª¢æ¸¬ç”¨æ–¼æª¢æ¸¬æ±‚æ•‘æ‰‹å‹¢
            self._load_hand_detection_for_emergency_gestures()
            
            logger.info("âœ… è€äººè·Œå€’é é˜²æª¢æ¸¬æ¨¡å‹è¼‰å…¥å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            raise
    
    def _load_pose_detection_for_fall_prevention(self):
        """è¼‰å…¥å§¿æ…‹æª¢æ¸¬æ¨¡å‹ï¼ˆè·Œå€’é é˜²æ ¸å¿ƒï¼‰"""
        try:
            from qai_hub_models.models.mediapipe_pose import Model as PoseModel
            
            logger.info("ğŸš¶â€â™‚ï¸ è¼‰å…¥å§¿æ…‹æª¢æ¸¬æ¨¡å‹ (è·Œå€’é é˜²æ ¸å¿ƒ)...")
            pose_model = PoseModel.from_pretrained()
            pose_detector = pose_model.pose_detector
            self.qai_hub_models['pose_fall_detection'] = pose_detector
            
            # æäº¤åˆ°Dragon Xè¨­å‚™ç·¨è­¯
            if self.target_device:
                logger.info("ğŸ‰ æäº¤å§¿æ…‹æª¢æ¸¬æ¨¡å‹åˆ°Dragon Xç·¨è­¯...")
                
                try:
                    torchscript_model = pose_detector.convert_to_torchscript()
                    uploaded_model = hub.upload_model(torchscript_model)
                    
                    compile_job = hub.submit_compile_job(
                        model=uploaded_model,
                        input_specs={"image": ((1, 3, 256, 256), "float32")},
                        device=self.target_device,
                        # æŒ‡å®šç›®æ¨™ç”¢å‡ºç‚º Qualcomm AI Engine Direct DLC, ä»¥ä¾¿å¾ŒçºŒ link
                        options="--target_runtime qnn_dlc"
                    )
                    
                    logger.info(f"âœ… å§¿æ…‹æª¢æ¸¬Dragon Xç·¨è­¯Job: {compile_job.job_id}")
                    logger.info(f"ğŸ”— Dashboard: https://app.aihub.qualcomm.com/jobs/{compile_job.job_id}")
                    
                    self.compiled_models['pose_fall_detection_job'] = compile_job
                    
                except Exception as e:
                    logger.error(f"âŒ å§¿æ…‹æª¢æ¸¬Dragon Xç·¨è­¯å¤±æ•—: {e}")
            
            logger.info("âœ… å§¿æ…‹æª¢æ¸¬æ¨¡å‹ (è·Œå€’é é˜²) è¼‰å…¥å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ å§¿æ…‹æª¢æ¸¬æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
    
    def _load_face_detection_for_elderly_identification(self):
        """è¼‰å…¥äººè‡‰æª¢æ¸¬æ¨¡å‹ï¼ˆè€äººèº«ä»½ç¢ºèªï¼‰"""
        try:
            from qai_hub_models.models.mediapipe_face import Model as FaceModel
            
            logger.info("ğŸ‘¤ è¼‰å…¥äººè‡‰æª¢æ¸¬æ¨¡å‹ (è€äººèº«ä»½ç¢ºèª)...")
            face_model = FaceModel.from_pretrained()
            face_detector = face_model.face_detector
            self.qai_hub_models['face_elderly_id'] = face_detector
            
            # æäº¤åˆ°Dragon Xè¨­å‚™ç·¨è­¯
            if self.target_device:
                logger.info("ğŸ‰ æäº¤äººè‡‰æª¢æ¸¬æ¨¡å‹åˆ°Dragon Xç·¨è­¯...")
                
                try:
                    torchscript_model = face_detector.convert_to_torchscript()
                    uploaded_model = hub.upload_model(torchscript_model)
                    
                    compile_job = hub.submit_compile_job(
                        model=uploaded_model,
                        input_specs={"image": ((1, 3, 256, 256), "float32")},
                        device=self.target_device,
                        options="--target_runtime qnn_dlc"
                    )
                    
                    logger.info(f"âœ… äººè‡‰æª¢æ¸¬Dragon Xç·¨è­¯Job: {compile_job.job_id}")
                    logger.info(f"ğŸ”— Dashboard: https://app.aihub.qualcomm.com/jobs/{compile_job.job_id}")
                    
                    self.compiled_models['face_elderly_id_job'] = compile_job
                    
                except Exception as e:
                    logger.error(f"âŒ äººè‡‰æª¢æ¸¬Dragon Xç·¨è­¯å¤±æ•—: {e}")
            
            logger.info("âœ… äººè‡‰æª¢æ¸¬æ¨¡å‹ (è€äººèº«ä»½ç¢ºèª) è¼‰å…¥å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ äººè‡‰æª¢æ¸¬æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
    
    def _load_hand_detection_for_emergency_gestures(self):
        """è¼‰å…¥æ‰‹éƒ¨æª¢æ¸¬æ¨¡å‹ï¼ˆç·Šæ€¥æ±‚æ•‘æ‰‹å‹¢ï¼‰"""
        try:
            from qai_hub_models.models.mediapipe_hand import Model as HandModel
            
            logger.info("âœ‹ è¼‰å…¥æ‰‹éƒ¨æª¢æ¸¬æ¨¡å‹ (ç·Šæ€¥æ±‚æ•‘æ‰‹å‹¢)...")
            hand_model = HandModel.from_pretrained()
            hand_detector = hand_model.hand_detector
            self.qai_hub_models['hand_emergency_gesture'] = hand_detector
            
            # æäº¤åˆ°Dragon Xè¨­å‚™ç·¨è­¯
            if self.target_device:
                logger.info("ğŸ‰ æäº¤æ‰‹éƒ¨æª¢æ¸¬æ¨¡å‹åˆ°Dragon Xç·¨è­¯...")
                
                try:
                    torchscript_model = hand_detector.convert_to_torchscript()
                    uploaded_model = hub.upload_model(torchscript_model)
                    
                    compile_job = hub.submit_compile_job(
                        model=uploaded_model,
                        input_specs={"image": ((1, 3, 224, 224), "float32")},
                        device=self.target_device,
                        options="--target_runtime qnn_dlc"
                    )
                    
                    logger.info(f"âœ… æ‰‹éƒ¨æª¢æ¸¬Dragon Xç·¨è­¯Job: {compile_job.job_id}")
                    logger.info(f"ğŸ”— Dashboard: https://app.aihub.qualcomm.com/jobs/{compile_job.job_id}")
                    
                    self.compiled_models['hand_emergency_gesture_job'] = compile_job
                    
                except Exception as e:
                    logger.error(f"âŒ æ‰‹éƒ¨æª¢æ¸¬Dragon Xç·¨è­¯å¤±æ•—: {e}")
            
            logger.info("âœ… æ‰‹éƒ¨æª¢æ¸¬æ¨¡å‹ (ç·Šæ€¥æ±‚æ•‘æ‰‹å‹¢) è¼‰å…¥å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ‰‹éƒ¨æª¢æ¸¬æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
    
    def analyze_fall_risk(self, pose_keypoints: List[Dict]) -> Dict[str, Any]:
        """åˆ†æè·Œå€’é¢¨éšª"""
        if not pose_keypoints:
            return {"fall_risk": "unknown", "confidence": 0.0, "reasons": []}
        
        fall_risk_indicators = []
        risk_score = 0.0
        
        try:
            # æå–é—œéµé—œç¯€é»
            keypoints = pose_keypoints[0] if pose_keypoints else {}
            
            # æª¢æ¸¬èº«é«”å‚¾æ–œåº¦
            if len(keypoints.get('keypoints', [])) >= 17:
                kpts = keypoints['keypoints']
                
                # è‚©è†€æ°´å¹³åº¦æª¢æŸ¥
                left_shoulder = kpts[5] if len(kpts) > 5 else None
                right_shoulder = kpts[6] if len(kpts) > 6 else None
                
                if left_shoulder and right_shoulder:
                    shoulder_angle = abs(left_shoulder['y'] - right_shoulder['y'])
                    if shoulder_angle > 0.3:  # é–¾å€¼å¯èª¿æ•´
                        fall_risk_indicators.append("èº«é«”æ˜é¡¯å‚¾æ–œ")
                        risk_score += 0.4
                
                # é‡å¿ƒç©©å®šæ€§æª¢æŸ¥
                left_hip = kpts[11] if len(kpts) > 11 else None
                right_hip = kpts[12] if len(kpts) > 12 else None
                left_ankle = kpts[15] if len(kpts) > 15 else None
                right_ankle = kpts[16] if len(kpts) > 16 else None
                
                if all([left_hip, right_hip, left_ankle, right_ankle]):
                    # æª¢æŸ¥è…³è¸ä½ç½®ç›¸å°æ–¼é«–éƒ¨
                    hip_center_x = (left_hip['x'] + right_hip['x']) / 2
                    ankle_center_x = (left_ankle['x'] + right_ankle['x']) / 2
                    
                    balance_offset = abs(hip_center_x - ankle_center_x)
                    if balance_offset > 0.4:  # é‡å¿ƒåç§»éå¤§
                        fall_risk_indicators.append("é‡å¿ƒä¸ç©©å®š")
                        risk_score += 0.3
                
                # è†è“‹å½æ›²åº¦æª¢æŸ¥
                left_knee = kpts[13] if len(kpts) > 13 else None
                right_knee = kpts[14] if len(kpts) > 14 else None
                
                if left_knee and right_knee and left_hip and right_hip:
                    # æª¢æŸ¥è†è“‹æ˜¯å¦éåº¦å½æ›²ï¼ˆå¯èƒ½è¡¨ç¤ºè·Œå€’ï¼‰
                    left_knee_angle = abs(left_knee['y'] - left_hip['y'])
                    right_knee_angle = abs(right_knee['y'] - right_hip['y'])
                    
                    if left_knee_angle < 0.1 or right_knee_angle < 0.1:
                        fall_risk_indicators.append("è†è“‹ç•°å¸¸å½æ›²")
                        risk_score += 0.3
        
        except Exception as e:
            logger.error(f"âŒ è·Œå€’é¢¨éšªåˆ†æå¤±æ•—: {e}")
            return {"fall_risk": "analysis_error", "confidence": 0.0, "error": str(e)}
        
        # åˆ¤å®šé¢¨éšªç­‰ç´š
        if risk_score >= 0.7:
            risk_level = "high"
            risk_message = "âš ï¸ é«˜è·Œå€’é¢¨éšª"
        elif risk_score >= 0.4:
            risk_level = "medium"
            risk_message = "ğŸ”¶ ä¸­ç­‰è·Œå€’é¢¨éšª"
        elif risk_score >= 0.1:
            risk_level = "low"
            risk_message = "ğŸ”· ä½è·Œå€’é¢¨éšª"
        else:
            risk_level = "normal"
            risk_message = "âœ… æ­£å¸¸ç‹€æ…‹"
        
        return {
            "fall_risk": risk_level,
            "risk_score": risk_score,
            "confidence": min(risk_score * 1.5, 1.0),
            "message": risk_message,
            "indicators": fall_risk_indicators,
            "recommendation": self._get_safety_recommendation(risk_level)
        }
    
    def _get_safety_recommendation(self, risk_level: str) -> str:
        """æ ¹æ“šé¢¨éšªç­‰ç´šæä¾›å®‰å…¨å»ºè­°"""
        recommendations = {
            "high": "ç«‹å³æª¢æŸ¥ç’°å¢ƒå®‰å…¨ï¼Œå»ºè­°å°‹æ±‚å”åŠ©æˆ–åä¸‹ä¼‘æ¯",
            "medium": "æ³¨æ„å‘¨åœç’°å¢ƒï¼Œæ”¾æ…¢å‹•ä½œï¼Œç¢ºä¿æœ‰æ”¯æ’ç‰©åœ¨é™„è¿‘",
            "low": "ä¿æŒè¬¹æ…ï¼Œæ³¨æ„è…³ä¸‹ç‹€æ³",
            "normal": "ç¹¼çºŒä¿æŒè‰¯å¥½å§¿æ…‹"
        }
        return recommendations.get(risk_level, "ä¿æŒå®‰å…¨æ„è­˜")
    
    def comprehensive_fall_prevention_detection(self, image: np.ndarray) -> Dict[str, Any]:
        """ç¶œåˆè·Œå€’é é˜²æª¢æ¸¬"""
        results = {
            "timestamp": time.time(),
            "dragon_x_device": self.target_device.name if self.target_device else None,
            "fall_prevention_analysis": {},
            "detections": {},
            "qai_hub_jobs": {}
        }
        
        # å§¿æ…‹æª¢æ¸¬ï¼ˆæ ¸å¿ƒï¼‰
        if 'pose_fall_detection' in self.qai_hub_models:
            logger.info("ğŸš¶â€â™‚ï¸ åŸ·è¡Œå§¿æ…‹æª¢æ¸¬ (è·Œå€’é é˜²æ ¸å¿ƒ)...")
            real_pose = self._run_pose_inference_local(image)
            if real_pose is None:
                # fallback æ¨¡æ“¬
                mock_pose_results = {
                    "keypoints": [{
                        "keypoints": [
                            {"x": 0.5, "y": 0.3, "confidence": 0.8},
                            {"x": 0.45, "y": 0.5, "confidence": 0.9},
                            {"x": 0.55, "y": 0.5, "confidence": 0.9},
                        ]
                    }]
                }
                fall_analysis = self.analyze_fall_risk(mock_pose_results["keypoints"])
                results["fall_prevention_analysis"] = fall_analysis
                results["detections"]["pose"] = mock_pose_results
            else:
                fall_analysis = self.analyze_fall_risk(real_pose["keypoints"])
                results["fall_prevention_analysis"] = fall_analysis
                results["detections"]["pose"] = real_pose
        
        # è¨˜éŒ„Dragon Xç·¨è­¯Jobè³‡è¨Š
        for job_name, job in self.compiled_models.items():
            model_type = job_name.replace('_job', '')
            results["qai_hub_jobs"][model_type] = {
                "job_id": job.job_id,
                "dashboard_url": f"https://app.aihub.qualcomm.com/jobs/{job.job_id}",
                "target_device": self.target_device.name
            }
        
        return results
    
    def get_dragon_x_status_report(self) -> Dict[str, Any]:
        """ç²å–Dragon Xç³»çµ±ç‹€æ…‹å ±å‘Š"""
        report = {
            "system_name": "Dragon Xè€äººè·Œå€’é é˜²æª¢æ¸¬ç³»çµ±",
            "timestamp": time.time(),
            "dragon_x_device": {
                "name": self.target_device.name if self.target_device else None,
                "status": "ready" if self.target_device else "not_found"
            },
            "models_status": {},
            "qai_hub_jobs": {},
            "profile_jobs": {},
            "link_jobs": {},
            "hackathon_readiness": True
        }
        
        # æª¢æŸ¥æ¨¡å‹ç‹€æ…‹
        for model_name in self.qai_hub_models:
            report["models_status"][model_name] = "loaded"
        
        # æª¢æŸ¥ç·¨è­¯Jobç‹€æ…‹
        for job_name, job in self.compiled_models.items():
            try:
                # å˜—è©¦å¿«é€Ÿæª¢æŸ¥ç‹€æ…‹
                job.wait(timeout=1)
                status = "completed"
            except:
                status = "compiling"
            
            report["qai_hub_jobs"][job_name] = {
                "job_id": job.job_id,
                "status": status,
                "dashboard_url": f"https://app.aihub.qualcomm.com/jobs/{job.job_id}"
            }

        # Profile jobs
        for name, job in self.profile_jobs.items():
            try:
                job.wait(timeout=1)
                status = "completed"
            except:
                status = "running"
            report["profile_jobs"][name] = {
                "job_id": job.job_id,
                "status": status,
                "dashboard_url": f"https://app.aihub.qualcomm.com/jobs/{job.job_id}"
            }

        # Link jobs (CLI submissions only have ID string)
        for name, info in self.link_jobs.items():
            report["link_jobs"][name] = info
        
        return report

    # ================= å¯¦éš›åŸ·è¡Œæœ¬åœ°æ¨è«– (å§¿æ…‹) =================
    def _run_pose_inference_local(self, image: np.ndarray) -> Optional[Dict[str, Any]]:
        """å˜—è©¦ä½¿ç”¨å·²ä¸‹è¼‰çš„ compiled_pose_fall_detection.onnx åŸ·è¡Œæœ¬åœ°æ¨è«–ã€‚

        ç›®æ¨™: å„ªå…ˆä½¿ç”¨ QNN / QNNExecutionProvider (è‹¥ç’°å¢ƒæ”¯æ´) ä»¥è§¸ç™¼ NPUã€‚
        å›å‚³æ ¼å¼: {"keypoints": [{"keypoints": [{x,y,confidence}, ...]}]}
        å¤±æ•—å‰‡å›å‚³ Noneã€‚
        """
        onnx_path = 'compiled_pose_fall_detection.onnx'
        if not os.path.exists(onnx_path):
            logger.warning("âš ï¸ æ‰¾ä¸åˆ°å·²ä¸‹è¼‰çš„å§¿æ…‹ ONNX (compiled_pose_fall_detection.onnx)ï¼Œä½¿ç”¨æ¨¡æ“¬è³‡æ–™")
            return None
        try:
            providers = ort.get_available_providers()
            preferred = []
            # å¸¸è¦‹å¯èƒ½åç¨±ï¼ˆä¾å¹³å°èª¿æ•´ï¼‰
            for cand in ['QNNExecutionProvider', 'QNN', 'CPUExecutionProvider']:
                if cand in providers and cand not in preferred:
                    preferred.append(cand)
            if not preferred:
                preferred = providers
            logger.info(f"ğŸ§© ONNX Runtime Providers å¯ç”¨: {providers} -> ä½¿ç”¨é †åº: {preferred}")
            sess = ort.InferenceSession(onnx_path, providers=preferred)

            # å‰è™•ç†: BGR->RGB, resize 256, normalize 0..1
            img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            img_resized = cv2.resize(img, (256, 256), interpolation=cv2.INTER_LINEAR)
            tensor = img_resized.astype('float32') / 255.0
            tensor = np.transpose(tensor, (2, 0, 1))  # CHW
            tensor = np.expand_dims(tensor, 0)  # NCHW

            input_name = sess.get_inputs()[0].name
            outputs = sess.run(None, {input_name: tensor})
            output_meta = sess.get_outputs()

            # å˜—è©¦å¾ç¬¬ä¸€å€‹è¼¸å‡ºæ¨æ¸¬ keypoints (å‡è¨­å½¢ç‹€ [1, K, 3] æˆ– [1, 3, K])
            keypoints_list = []
            if outputs:
                arr = outputs[0]
                arr_np = np.array(arr)
                kpts = []
                try:
                    if arr_np.ndim == 3:  # ä¾‹å¦‚ (1, K, C) or (1, C, K)
                        if arr_np.shape[2] == 3:  # (1, K, 3)
                            for i in range(min(arr_np.shape[1], 25)):
                                x, y, c = arr_np[0, i]
                                kpts.append({"x": float(x), "y": float(y), "confidence": float(c)})
                        elif arr_np.shape[1] == 3:  # (1, 3, K)
                            for i in range(min(arr_np.shape[2], 25)):
                                x = arr_np[0, 0, i]
                                y = arr_np[0, 1, i]
                                c = arr_np[0, 2, i] if arr_np.shape[1] > 2 else 0.9
                                kpts.append({"x": float(x), "y": float(y), "confidence": float(c)})
                    elif arr_np.ndim == 2 and arr_np.shape[0] == 1:  # (1, N) æ”¤å¹³
                        flat = arr_np[0]
                        for i in range(0, min(len(flat), 75), 3):
                            if i + 2 < len(flat):
                                kpts.append({"x": float(flat[i]), "y": float(flat[i+1]), "confidence": float(flat[i+2])})
                    else:
                        logger.warning(f"âš ï¸ ç„¡æ³•è§£æå§¿æ…‹è¼¸å‡º shape={arr_np.shape}ï¼Œä½¿ç”¨æ¨¡æ“¬ fallback")
                except Exception as e:
                    logger.warning(f"âš ï¸ è§£æå§¿æ…‹è¼¸å‡ºå¤±æ•—:{e}ï¼Œä½¿ç”¨æ¨¡æ“¬ fallback")
                    return None
                if kpts:
                    keypoints_list.append({"keypoints": kpts})
            if not keypoints_list:
                return None
            return {"keypoints": keypoints_list, "provider": sess.get_providers(), "output_names": [o.name for o in output_meta]}
        except Exception as e:
            logger.warning(f"âš ï¸ æœ¬åœ°å§¿æ…‹æ¨è«–å¤±æ•— (æ”¹ç”¨æ¨¡æ“¬): {e}")
            return None

    # ===================== æ–°å¢ï¼šå®Œæ•´Pipelineæ”¯æ´ =====================
    def _submit_profile_jobs_for_all(self):
        """ç‚ºæ‰€æœ‰å·²æäº¤çš„ç·¨è­¯æ¨¡å‹æäº¤ profiling jobï¼ˆè¿‘ä¼¼ inference æ€§èƒ½æ¸¬è©¦ï¼‰"""
        if not self.target_device:
            logger.warning("âš ï¸ ç„¡ç›®æ¨™è¨­å‚™ï¼Œè·³é profiling æäº¤")
            return
        for key, compile_job in self.compiled_models.items():
            model_label = key.replace('_job', '')
            if model_label in self.profile_jobs:
                continue
            try:
                # ç­‰å¾…å–®ä¸€ compile job å®Œæˆå¾Œå†é€ profiling (é¿å… 'model not compiled' éŒ¯èª¤)
                logger.info(f"â³ ç­‰å¾…ç·¨è­¯å®Œæˆä»¥ä¾¿ Profiling: {model_label} ({compile_job.job_id}) ...")
                self._wait_for_single_job(compile_job, f"compile:{model_label}")
                logger.info(f"âœ… ç·¨è­¯å·²å®Œæˆï¼Œæäº¤ Profiling: {model_label}")
                # å˜—è©¦å¾åŸå§‹æ¨¡å‹å­—å…¸æ‰¾åˆ°å°æ‡‰ component
                component_key = None
                if 'pose' in model_label:
                    component_key = 'pose_fall_detection'
                elif 'face' in model_label:
                    component_key = 'face_elderly_id'
                elif 'hand' in model_label:
                    component_key = 'hand_emergency_gesture'
                component = self.qai_hub_models.get(component_key)
                # æº–å‚™æ¨£æœ¬è¼¸å…¥ï¼ˆåƒ…ç•¶ API æ”¯æ´ç›¸é—œåƒæ•¸æ™‚æ‰ä½¿ç”¨ï¼‰
                sample_inputs_256 = {"image": np.random.rand(1,3,256,256).astype('float32')}
                sample_inputs_224 = {"image": np.random.rand(1,3,224,224).astype('float32')}
                sample_inputs = sample_inputs_224 if component_key == 'hand_emergency_gesture' else sample_inputs_256

                profile_job = None
                # 1. å˜—è©¦æœ€ç°¡ API å½¢å¼ï¼ˆæ–°ç‰ˆ SDK å¯èƒ½åªæ¥å—å¿…è¦åƒæ•¸ï¼‰
                try:
                    profile_job = hub.submit_profile_job(model=compile_job.model, device=self.target_device)
                except TypeError as te1:
                    # 2. å˜—è©¦åƒæ•¸åç¨± 'inputs'
                    try:
                        profile_job = hub.submit_profile_job(model=compile_job.model, device=self.target_device, inputs=sample_inputs)
                    except TypeError as te2:
                        # 3. å˜—è©¦èˆŠç‰ˆå¯èƒ½çš„ positional èª¿ç”¨
                        try:
                            profile_job = hub.submit_profile_job(compile_job.model, self.target_device)
                        except Exception as te3:
                            raise RuntimeError(f"submit_profile_job å¤šé‡å‘¼å«å½¢å¼å‡å¤±æ•—: {te1}; {te2}; {te3}")
                except Exception as e_any:
                    raise RuntimeError(f"submit_profile_job å‘¼å«å¤±æ•—: {e_any}")

                if profile_job is None:
                    raise RuntimeError("submit_profile_job è¿”å› Noneï¼Œå¯èƒ½ API å·²è®Šæ›´")
                self.profile_jobs[model_label + '_profile'] = profile_job
                logger.info(f"ğŸ“ˆ æäº¤Profiling: {model_label} -> {profile_job.job_id}")
                logger.info(f"ğŸ”— Dashboard: https://app.aihub.qualcomm.com/jobs/{profile_job.job_id}")
            except Exception as e:
                logger.error(f"âŒ Profiling æäº¤å¤±æ•— {model_label}: {e}")

    # === æ–°å¢ï¼šå®˜æ–¹ Step1~6 æ•´åˆåŸ·è¡Œ ===
    def _run_full_official_steps_for_all_models(self):
        """ä¾ç…§å®˜æ–¹æ•™å­¸æ­¥é©Ÿå°æ¯å€‹æ¨¡å‹åŸ·è¡Œ:
        Step1 æº–å‚™/Trace(å·²æ–¼è¼‰å…¥æ™‚å®Œæˆ TorchScript è½‰æ›)
        Step2 Compile (å·²æäº¤)
        Step3 Profile (ç­‰å¾… compile å®Œæˆå¾Œï¼Œä»¥ target_model åŸ·è¡Œ)
        Step4 Inference (åŒæ¨£ä½¿ç”¨ target_model)
        Step5 Post-process (åŸºæœ¬è¼¸å‡ºå½¢ç‹€/çµ±è¨ˆ)
        Step6 Download target model (ONNX/TorchScript)
        """
        if not self.target_device:
            logger.warning("âš ï¸ ç„¡ç›®æ¨™è¨­å‚™ï¼Œè·³éå®˜æ–¹æ­¥é©Ÿ")
            return
        for key, compile_job in list(self.compiled_models.items()):
            model_label = key.replace('_job', '')
            logger.info(f"================ {model_label} PIPELINE ================")
            logger.info(f"ğŸŸ¦ Step 2: ç­‰å¾… Compile å®Œæˆ -> {compile_job.job_id}")
            self._wait_for_single_job(compile_job, f"compile:{model_label}")
            # Step3: Profile éœ€ target model
            try:
                logger.info("ğŸŸ© å–å¾— target_model (get_target_model)")
                target_model = compile_job.get_target_model()
                self.target_models[model_label] = target_model
            except Exception as e:
                logger.error(f"âŒ ç„¡æ³•å–å¾— target_model ({model_label}): {e}")
                continue
            # æäº¤ Profile
            if model_label + '_profile' not in self.profile_jobs:
                try:
                    logger.info("ğŸŸ¨ Step 3: æäº¤ Profile Job")
                    profile_job = hub.submit_profile_job(model=target_model, device=self.target_device)
                    self.profile_jobs[model_label + '_profile'] = profile_job
                    self._wait_for_single_job(profile_job, f"profile:{model_label}")
                except Exception as e:
                    logger.warning(f"âš ï¸ Profile å¤±æ•— ({model_label}): {e}")
            # Inference
            if model_label not in self.inference_jobs:
                try:
                    logger.info("ğŸŸ¥ Step 4: æäº¤ Inference Job")
                    # å»ºç«‹ç°¡å–®éš¨æ©Ÿè¼¸å…¥ (ä¾åŸå§‹ input spec å°ºå¯¸)
                    shape = (1, 3, 256, 256)
                    if 'hand' in model_label:
                        shape = (1, 3, 224, 224)
                    dummy = np.random.rand(*shape).astype('float32')
                    inf_job = hub.submit_inference_job(model=target_model, device=self.target_device, inputs={'image': [dummy]})
                    self.inference_jobs[model_label + '_inference'] = inf_job
                    self._wait_for_single_job(inf_job, f"inference:{model_label}")
                    # Step5: Post-process (ä¸‹è¼‰è¼¸å‡ºè³‡æ–™)
                    try:
                        outputs = inf_job.download_output_data()
                        self.inference_outputs[model_label] = {k: (np.array(v).shape if isinstance(v, list) else 'unknown') for k, v in outputs.items()}
                        logger.info(f"ğŸ§ª Step 5: è¼¸å‡ºæ‘˜è¦: {self.inference_outputs[model_label]}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ ä¸‹è¼‰æ¨è«–è¼¸å‡ºå¤±æ•— ({model_label}): {e}")
                except Exception as e:
                    logger.error(f"âŒ Inference Job æäº¤å¤±æ•— ({model_label}): {e}")
            # Step6: ä¸‹è¼‰æ¨¡å‹
            if model_label not in self.target_models:
                continue
            try:
                download_name = f"compiled_{model_label}.onnx"
                logger.info(f"ğŸ’¾ Step 6: ä¸‹è¼‰ target model -> {download_name}")
                # target_model å¯èƒ½æä¾› download æ–¹æ³•
                target_model = self.target_models[model_label]
                if hasattr(target_model, 'download'):
                    target_model.download(download_name)
                    logger.info(f"âœ… å·²ä¸‹è¼‰ {download_name}")
                else:
                    logger.warning(f"âš ï¸ target_model ç„¡ download æ–¹æ³•ï¼Œè·³éä¸‹è¼‰ ({model_label})")
            except Exception as e:
                logger.warning(f"âš ï¸ ä¸‹è¼‰æ¨¡å‹å¤±æ•— ({model_label}): {e}")
            logger.info(f"================ {model_label} DONE ==================")

        # è‹¥ä½¿ç”¨è€…è¦æ±‚ Python link (å¤šæ¨¡å‹æ‰“åŒ…) å¯åœ¨å®Œæˆå¾ŒåŸ·è¡Œ
        if getattr(self, 'python_link_requested', False):
            self._link_all_models_python()

    def _link_all_models_python(self):
        """ä½¿ç”¨å®˜æ–¹ API hub.submit_link_job å°‡å¤šå€‹å·²ç·¨è­¯çš„ target_models é€²è¡Œ linkã€‚

        æ³¨æ„: å®˜æ–¹ç¯„ä¾‹æ˜¯åŒä¸€æ¨¡å‹ä¸åŒè¼¸å…¥å°ºå¯¸ä»¥å…±äº«æ¬Šé‡; é€™è£¡æ˜¯ä¸åŒä»»å‹™æ¨¡å‹ (pose/face/hand),
        ä»å¯å˜—è©¦ç”¢å‡ºä¸€å€‹ context binary, ä½†æ¬Šé‡å…±äº«æ”¶ç›Šæœ‰é™ã€‚
        æ¢ä»¶: éœ€ç‚º Qualcomm AI Engine Direct (qnn_dlc) è¼¸å‡º; å·²åœ¨ compile æ™‚åŠ ä¸Š --target_runtime qnn_dlcã€‚
        """
        if not self.target_device:
            logger.warning("âš ï¸ ç„¡ç›®æ¨™è¨­å‚™, ç„¡æ³•åŸ·è¡Œ Python link")
            return
        # ç¢ºä¿ target_models éƒ½å·²å–å¾—
        for job_key, compile_job in self.compiled_models.items():
            label = job_key.replace('_job', '')
            if label not in self.target_models:
                try:
                    self._wait_for_single_job(compile_job, f"compile:{label}")
                    self.target_models[label] = compile_job.get_target_model()
                except Exception as e:
                    logger.warning(f"âš ï¸ ç„¡æ³•å–å¾— target_model ({label}): {e}ï¼Œè·³éè©²æ¨¡å‹çš„ link")
        models_to_link = [m for m in self.target_models.values() if m is not None]
        if len(models_to_link) < 2:
            logger.warning("âš ï¸ å¯ç”¨ target_models å°‘æ–¼2, è·³é link")
            return
        try:
            logger.info(f"ğŸ”— (Python API) submit_link_job: {len(models_to_link)} å€‹æ¨¡å‹ -> å–®ä¸€ context")
            link_job = hub.submit_link_job(models_to_link, device=self.target_device, name="DragonX MultiModel Context")
            self.link_jobs['dragonx_python_link'] = {
                'job_id': link_job.job_id,
                'status': 'submitted',
                'dashboard_url': f'https://app.aihub.qualcomm.com/jobs/{link_job.job_id}'
            }
            # ç­‰å¾…å®Œæˆ (é™åˆ¶æ™‚é–“é¿å…é˜»å¡éä¹…)
            self._wait_for_single_job(link_job, 'link:dragonx_python', timeout=1800, poll=15)
            try:
                linked_model = link_job.get_target_model()
                if hasattr(linked_model, 'download'):
                    linked_model.download('dragonx_linked_context.bin')
                    logger.info("ğŸ’¾ å·²ä¸‹è¼‰ linked context -> dragonx_linked_context.bin")
            except Exception as e:
                logger.warning(f"âš ï¸ å–å¾—/ä¸‹è¼‰ linked model å¤±æ•—: {e}")
        except Exception as e:
            logger.error(f"âŒ Python link_job å¤±æ•—: {e}")

    def _attempt_link_jobs_cli(self):
        """é€é CLI å˜—è©¦æäº¤ link jobï¼ˆè‹¥ SDK ç„¡ Python APIï¼‰ã€‚"""
        cli = shutil.which('qai-hub')
        if not cli:
            logger.warning("âš ï¸ æœªæ‰¾åˆ° qai-hub CLIï¼Œè·³é link job")
            return
        if not self.target_device:
            logger.warning("âš ï¸ ç„¡ç›®æ¨™è¨­å‚™ï¼Œè·³é link job")
            return
        device_name = self.target_device.name
        device_os = getattr(self.target_device, 'os_version', None) or getattr(self.target_device, 'os', None)

        # 1. å–å¾— help è¼¸å‡ºä»¥å‹•æ…‹åµæ¸¬å¯ç”¨æ——æ¨™
        help_flags: List[str] = []
        try:
            help_proc = subprocess.run([cli, 'submit-link-job', '-h'], capture_output=True, text=True, timeout=30)
            help_text = (help_proc.stdout + '\n' + help_proc.stderr)
            for line in help_text.splitlines():
                line = line.strip()
                if line.startswith('--'):
                    # æ“·å–æ——æ¨™åç¨± (ç©ºç™½æˆ–=å‰)
                    flag = line.split()[0]
                    # ç§»é™¤æè¿°ä¸­é€—è™Ÿåˆ†éš”çš„å…¶ä»– alias
                    for part in flag.split(','):
                        if part.startswith('--'):
                            help_flags.append(part.strip())
            logger.info(f"ğŸ” Link CLI å¯ç”¨æ——æ¨™: {help_flags}")
            if self.debug_link:
                with open('qai_hub_submit_link_job_help.txt', 'w') as f:
                    f.write(help_text)
                logger.info("ğŸ’¾ å·²å„²å­˜ submit-link-job help åˆ° qai_hub_submit_link_job_help.txt")
        except Exception as e:
            logger.warning(f"âš ï¸ ç„¡æ³•å–å¾— submit-link-job help: {e} (æ¡ç”¨ä¿å®ˆçŒœæ¸¬)")

        # å¯èƒ½çš„æ¨¡å‹æ——æ¨™ (ä¾å„ªå…ˆé †åº)
        candidate_model_flags = [f for f in ['--model', '--model-id', '--model_id'] if f in help_flags]
        # å¯èƒ½çš„ compile job æ——æ¨™
        candidate_compile_flags = [f for f in ['--compile-job-id', '--compile_job_id', '--job-id', '--job_id'] if f in help_flags]
        # è£ç½®æ——æ¨™
        candidate_device_flags = [f for f in ['--device', '--target-device', '--target_device'] if f in help_flags]
        # OS æ——æ¨™
        candidate_device_os_flags = [f for f in ['--device-os', '--device_os', '--os-version'] if f in help_flags]

        for key, compile_job in self.compiled_models.items():
            model_label = key.replace('_job', '')
            if model_label in self.link_jobs:
                continue

            model_id = getattr(getattr(compile_job, 'model', None), 'model_id', None)
            compile_job_id = getattr(compile_job, 'job_id', None)

            # å»ºç«‹åˆå§‹å‘½ä»¤ (ä¿å®ˆ: åªåŠ æˆ‘å€‘ç¢ºå®šå­˜åœ¨çš„æ——æ¨™)
            base_cmd = [cli, 'submit-link-job']

            # å„ªå…ˆä½¿ç”¨ compile job id (è‹¥ CLI æ”¯æ´)
            if compile_job_id and candidate_compile_flags:
                base_cmd += [candidate_compile_flags[0], compile_job_id]
            elif model_id and candidate_model_flags:
                base_cmd += [candidate_model_flags[0], model_id]
            elif model_id:
                # å˜—è©¦ positional model id (ç„¡æ——æ¨™)
                base_cmd.append(model_id)

            # Device
            if candidate_device_flags:
                base_cmd += [candidate_device_flags[0], device_name]
            else:
                # å˜—è©¦æ¨æ¸¬ --device (å³ä¾¿ help æœªåˆ—å‡º, æœ€å¸¸è¦‹)
                base_cmd += ['--device', device_name]

            # Device OS (åƒ…åœ¨æ——æ¨™å­˜åœ¨æ‰åŠ )
            if device_os and candidate_device_os_flags:
                base_cmd += [candidate_device_os_flags[0], str(device_os)]

            # ä¸€äº› CLI æ²’æœ‰ --output json, æ•…åƒ…åœ¨ help æœ‰åˆ—å‡ºæ™‚æ‰åŠ å…¥
            if '--output' in help_flags or '--format' in help_flags:
                if '--output' in help_flags:
                    base_cmd += ['--output', 'json']
                else:
                    base_cmd += ['--format', 'json']

            if self.debug_link:
                base_cmd.append('--verbose') if '--verbose' in help_flags else None
            logger.info(f"ğŸ”— å˜—è©¦æäº¤ Link Job (åˆå§‹): {' '.join(base_cmd)}")

            # è¿­ä»£å˜—è©¦, è‹¥å‡ºç¾ unrecognized arguments, å‹•æ…‹ç§»é™¤
            attempt_cmd = list(base_cmd)
            raw_capture = ''
            success = False
            attempt_logs: List[str] = []
            for attempt in range(6):
                try:
                    proc = subprocess.run(attempt_cmd, capture_output=True, text=True, timeout=180)
                    stdout = proc.stdout.strip()
                    stderr = proc.stderr.strip()
                    raw_capture = (stdout + '\n' + stderr)
                    if self.debug_link:
                        attempt_logs.append(f"Attempt {attempt+1} CMD: {' '.join(attempt_cmd)}\n--- STDOUT ---\n{stdout}\n--- STDERR ---\n{stderr}\n")

                    # åµæ¸¬æœªæ”¯æ´æ——æ¨™ä¸¦ç§»é™¤
                    m = re.search(r'unrecognized arguments?: (.+)', raw_capture)
                    if m:
                        unknown_parts = m.group(1).split()
                        # å˜—è©¦ç§»é™¤å‡ºç¾æ–¼å‘½ä»¤åˆ—çš„æ——æ¨™ (èˆ‡å…¶å¾Œå€¼)
                        removed_any = False
                        for up in unknown_parts:
                            token = up.strip(',')
                            if token in attempt_cmd:
                                idx = attempt_cmd.index(token)
                                # åŒæ™‚ç§»é™¤å¾Œä¸€å€‹å€¼ (è‹¥å­˜åœ¨ä¸”éä»¥--é–‹é ­)
                                removal = [attempt_cmd[idx]]
                                if idx + 1 < len(attempt_cmd) and not attempt_cmd[idx+1].startswith('--'):
                                    removal.append(attempt_cmd[idx+1])
                                for r in removal:
                                    attempt_cmd.remove(r)
                                removed_any = True
                        if removed_any:
                            logger.warning(f"âš ï¸ ç§»é™¤æœªæ”¯æ´æ——æ¨™å¾Œé‡è©¦: {' '.join(attempt_cmd)}")
                            continue  # é‡è·‘ä¸‹ä¸€è¼ª

                    # è§£æ job id
                    job_id = None
                    # Regex 1: æ‹¬è™Ÿå½¢å¼ (jxxxxxxx)
                    m2 = re.search(r'\(j[a-z0-9]{6,}\)', raw_capture, re.IGNORECASE)
                    if m2:
                        job_id = m2.group(0).strip('()')
                    if not job_id:
                        # ç›´æ¥ token æƒæ
                        for token in raw_capture.split():
                            t = token.strip('(),.\r\n')
                            if re.fullmatch(r'j[a-z0-9]{6,}', t.lower()):
                                job_id = t
                                break
                    if job_id:
                        self.link_jobs[model_label + '_link'] = {
                            'job_id': job_id,
                            'status': 'submitted',
                            'dashboard_url': f'https://app.aihub.qualcomm.com/jobs/{job_id}'
                        }
                        logger.info(f"âœ… Link Job æäº¤æˆåŠŸ: {job_id}")
                        success = True
                        break
                    else:
                        # è‹¥æ²’æœ‰ unrecognized è€Œä¹Ÿæ²’ job id, å¯èƒ½éœ€è¦æ› model / compile id æ——æ¨™ç­–ç•¥
                        if attempt == 0 and model_id and compile_job_id and candidate_model_flags and candidate_compile_flags:
                            # äº¤æ›¿ä½¿ç”¨å¦ä¸€ç¨®é¡æ——æ¨™
                            if candidate_model_flags[0] in attempt_cmd:
                                # æ›æˆ compile æ——æ¨™
                                for f in candidate_model_flags:
                                    if f in attempt_cmd:
                                        idx = attempt_cmd.index(f)
                                        # åˆªé™¤æ——æ¨™èˆ‡å…¶å€¼
                                        del attempt_cmd[idx:idx+2]
                                attempt_cmd += [candidate_compile_flags[0], compile_job_id]
                            else:
                                for f in candidate_compile_flags:
                                    if f in attempt_cmd:
                                        idx = attempt_cmd.index(f)
                                        del attempt_cmd[idx:idx+2]
                                attempt_cmd += [candidate_model_flags[0], model_id]
                            logger.warning(f"âš ï¸ åˆ‡æ›æ——æ¨™ç­–ç•¥é‡è©¦: {' '.join(attempt_cmd)}")
                            continue
                        logger.warning(f"âš ï¸ æœªè§£æåˆ° Link Job ID (å˜—è©¦æ¬¡æ•¸ {attempt+1})")
                except Exception as e:
                    logger.warning(f"âš ï¸ Link Job åŸ·è¡ŒéŒ¯èª¤ (é‡è©¦ {attempt+1}): {e}")
                    time.sleep(1)
            if not success:
                self.link_jobs[model_label + '_link'] = {
                    'job_id': None,
                    'status': 'parse_failed',
                    'raw_output': raw_capture[:800] if raw_capture else 'no_output'
                }
                logger.warning(f"âš ï¸ ç„¡æ³•è§£æ Link Job ID ({model_label}) - å·²è¨˜éŒ„ raw_output")
            if self.debug_link:
                log_path = f'link_attempt_{model_label}.log'
                try:
                    with open(log_path, 'w') as f:
                        f.write('\n'.join(attempt_logs) or raw_capture or 'no output captured')
                    logger.info(f"ğŸ’¾ å·²å„²å­˜ link é™¤éŒ¯ç´€éŒ„: {log_path}")
                except Exception as e:
                    logger.warning(f"âš ï¸ ç„¡æ³•å¯«å…¥é™¤éŒ¯æª” {log_path}: {e}")

    def _wait_for_single_job(self, job_obj, label: str, timeout: int = 1800, poll: int = 10):
        """è¼ªè©¢ç­‰å¾…å–®ä¸€ job å®Œæˆã€‚timeout ç§’å¾Œæ”¾æ£„ (æ¨™è¨˜ç‚º still_running)ã€‚"""
        start = time.time()
        while True:
            try:
                job_obj.wait(timeout=1)
                return True
            except Exception:
                pass
            elapsed = time.time() - start
            if elapsed >= timeout:
                logger.warning(f"âš ï¸ ç­‰å¾…è¶…æ™‚ ({timeout}s) job ä»æœªå®Œæˆ: {label}")
                return False
            if int(elapsed) % (poll) == 0:
                logger.info(f"â³ {label} é€²è¡Œä¸­... å·²ç­‰å¾… {int(elapsed)}s")
            time.sleep(1)

    def wait_for_all_jobs(self):
        """ç­‰å¾…æ‰€æœ‰ compile / profile job å®Œæˆï¼ˆlink ç‚º CLI æš«ä¸è¼ªè©¢ï¼‰ã€‚"""
        logger.info("â³ ç­‰å¾…æ‰€æœ‰ QAI Hub Jobs å®Œæˆ (compile + profile)...")
        unfinished = True
        last_status_emit = 0
        while unfinished:
            unfinished = False
            status_snapshot = {}
            # Compile jobs
            for name, job in self.compiled_models.items():
                try:
                    job.wait(timeout=1)
                    status_snapshot[name] = 'completed'
                except Exception:
                    status_snapshot[name] = 'running'
                    unfinished = True
            # Profile jobs
            for name, job in self.profile_jobs.items():
                try:
                    job.wait(timeout=1)
                    status_snapshot[name] = 'completed'
                except Exception:
                    status_snapshot[name] = 'running'
                    unfinished = True
            now = time.time()
            if now - last_status_emit > self.poll_interval:
                last_status_emit = now
                compiling = [k for k,v in status_snapshot.items() if v != 'completed']
                logger.info(f"ğŸ“Š Job ç‹€æ…‹: å®Œæˆ {len(status_snapshot)-len(compiling)}/{len(status_snapshot)}; é€²è¡Œä¸­: {', '.join(compiling) if compiling else 'ç„¡'}")
            if unfinished:
                time.sleep(self.poll_interval)
        logger.info("âœ… æ‰€æœ‰ compile / profile jobs å·²å®Œæˆ")

    def export_pipeline_status(self, path: str = 'dragon_x_pipeline_status.json'):
        report = self.get_dragon_x_status_report()
        with open(path, 'w') as f:
            json.dump(report, f, indent=2, default=str)
        logger.info(f"ğŸ“ Pipeline ç‹€æ…‹å·²è¼¸å‡º: {path}")

def main():
    """ä¸»å‡½æ•¸ï¼šDragon Xè€äººè·Œå€’é é˜²æª¢æ¸¬ç³»çµ±æ¸¬è©¦ / Pipeline"""
    parser = argparse.ArgumentParser(description='Dragon X è·Œå€’é é˜²ç³»çµ±')
    parser.add_argument('--full-pipeline', action='store_true', help='åŸ·è¡Œ Compileâ†’Profileâ†’(Link) å®Œæ•´æµç¨‹ä¸¦è¼¸å‡ºç‹€æ…‹')
    parser.add_argument('--wait', action='store_true', help='ç­‰å¾…æ‰€æœ‰é›²ç«¯ Jobs å®Œæˆ')
    parser.add_argument('--poll-interval', type=int, default=15, help='Job è¼ªè©¢ç§’æ•¸ (default:15)')
    parser.add_argument('--export-status', action='store_true', help='é¡å¤–è¼¸å‡º pipeline ç‹€æ…‹ JSON')
    parser.add_argument('--debug-link', action='store_true', help='è¼¸å‡º link job é™¤éŒ¯è³‡è¨Šä¸¦ä¿å­˜ log æª”')
    parser.add_argument('--link-python', action='store_true', help='ä½¿ç”¨ Python API submit_link_job å°å·²ç·¨è­¯æ¨¡å‹é€²è¡Œ link')
    parser.add_argument('--image', type=str, help='æä¾›æœ¬åœ°å½±åƒè·¯å¾‘ä»¥é€²è¡Œå¯¦éš›æœ¬åœ°æ¨è«– (å§¿æ…‹)')
    args = parser.parse_args()

    print("ğŸ‰ Dragon Xè€äººè·Œå€’é é˜²æª¢æ¸¬ç³»çµ±")
    print("=" * 60)
    print("ğŸ¯ å°ˆç‚ºé»‘å®¢æ¾æ‰“é€ çš„Snapdragon X Eliteå¹³å°è§£æ±ºæ–¹æ¡ˆ")
    print()
    
    try:
        dragon_system = DragonXFallDetectionSystem(full_pipeline=args.full_pipeline, wait=args.wait, poll_interval=args.poll_interval, debug_link=args.debug_link, link_python=args.link_python)

        status_report = dragon_system.get_dragon_x_status_report()
        print("ğŸ“Š Dragon Xç³»çµ±ç‹€æ…‹:")
        print(f"   ğŸ‰ ç›®æ¨™è¨­å‚™: {status_report['dragon_x_device']['name']}")
        print(f"   ğŸ“± è¨­å‚™ç‹€æ…‹: {status_report['dragon_x_device']['status']}")
        print(f"   ğŸ§  å·²è¼‰å…¥æ¨¡å‹: {len(status_report['models_status'])}")
        print(f"   âš¡ Compile Jobs: {len(status_report['qai_hub_jobs'])}")
        print(f"   ğŸ“ˆ Profile Jobs: {len(status_report['profile_jobs'])}")
        print(f"   ğŸ”— Link Jobs: {len(status_report['link_jobs'])}")
        print()

        print("ğŸ”— Compile Jobs:")
        for job_name, job_info in status_report['qai_hub_jobs'].items():
            print(f"   {job_name}: {job_info['job_id']} ({job_info['status']})")
            print(f"      Dashboard: {job_info['dashboard_url']}")
        if status_report['profile_jobs']:
            print("\nğŸ“ˆ Profile Jobs:")
            for name, info in status_report['profile_jobs'].items():
                print(f"   {name}: {info['job_id']} ({info['status']})")
                print(f"      Dashboard: {info['dashboard_url']}")
        if status_report['link_jobs']:
            print("\nğŸ”— Link Jobs:")
            for name, info in status_report['link_jobs'].items():
                print(f"   {name}: {info.get('job_id') or 'N/A'} ({info.get('status')})")
                if 'dashboard_url' in info:
                    print(f"      Dashboard: {info['dashboard_url']}")

        print("\nğŸ§ª æ¸¬è©¦è·Œå€’é é˜²æª¢æ¸¬ (æœ¬åœ°æ¨¡æ“¬)...")
        if args.image and os.path.exists(args.image):
            img = cv2.imread(args.image)
            if img is None:
                print(f"âš ï¸ ç„¡æ³•è®€å–å½±åƒ {args.image}ï¼Œæ”¹ç”¨éš¨æ©Ÿåœ–åƒ")
                img = np.random.randint(0,255,(480,640,3),dtype=np.uint8)
        else:
            if args.image:
                print(f"âš ï¸ æŒ‡å®šå½±åƒä¸å­˜åœ¨: {args.image}ï¼Œæ”¹ç”¨éš¨æ©Ÿåœ–åƒ")
            img = np.random.randint(0,255,(480,640,3),dtype=np.uint8)
        detection_results = dragon_system.comprehensive_fall_prevention_detection(img)

        print("âœ… è·Œå€’é é˜²åˆ†æçµæœ:")
        fall_analysis = detection_results.get('fall_prevention_analysis', {})
        print(f"   {fall_analysis.get('message', 'æœªçŸ¥ç‹€æ…‹')}")
        print(f"   é¢¨éšªè©•åˆ†: {fall_analysis.get('risk_score', 0):.2f}")
        print(f"   å»ºè­°: {fall_analysis.get('recommendation', 'ç„¡å»ºè­°')}")
        if fall_analysis.get('indicators'):
            print(f"   é¢¨éšªæŒ‡æ¨™: {', '.join(fall_analysis['indicators'])}")

        # ä¿å­˜å ±å‘Š
        with open('dragon_x_fall_detection_report.json', 'w') as f:
            json.dump({
                "status_report": status_report,
                "detection_results": detection_results
            }, f, indent=2, default=str)
        print("\nğŸ“ Dragon Xå ±å‘Šå·²ä¿å­˜: dragon_x_fall_detection_report.json")

        if args.export_status:
            dragon_system.export_pipeline_status()

        print("ğŸ‰ å®Œæˆ!")
        if args.full_pipeline:
            print("ğŸ å®Œæ•´Pipelineå·²åŸ·è¡Œ (Compileâ†’Profileâ†’Link[å˜—è©¦])")
        else:
            print("â„¹ï¸ ä½¿ç”¨ --full-pipeline å¯åŸ·è¡Œå®Œæ•´æµç¨‹")
        print("ğŸ’¡ ä½¿ç”¨ --wait å¯ç­‰å¾…é›²ç«¯Jobså®Œæˆ, --export-status è¼¸å‡ºJSONç‹€æ…‹")

    except Exception as e:
        print(f"âŒ Dragon Xç³»çµ±åˆå§‹åŒ–å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
