#!/usr/bin/env python3
"""
ğŸ† é»‘å®¢æ¾å¯¦æ™‚ç›¸æ©Ÿæ¼”ç¤º - 100% æª¢æ¸¬æˆåŠŸç‡ç‰ˆæœ¬
å±•ç¤º MediaPipe + QAI Hub å¯¦éš›é‹ä½œ
åŒ…å«å››ç¨®æª¢æ¸¬æ–¹æ³•çš„å¯¦æ™‚æ¼”ç¤º
"""

import os
import sys
import time
import json
import cv2
import numpy as np
from pathlib import Path
import logging
from typing import Optional, Dict, Any, Tuple, List
import threading
import queue

# æ·»åŠ é …ç›®è·¯å¾‘
project_root = Path(__file__).parent
sys.path.append(str(project_root))

# å°å…¥æˆ‘å€‘çš„å®Œæ•´æª¢æ¸¬ç³»çµ±
try:
    from completely_fixed_detector import CompletelyFixedHackathonDetector
    DETECTOR_AVAILABLE = True
    print("âœ… å°å…¥å®Œæ•´ä¿®å¾©çš„æª¢æ¸¬ç³»çµ±")
except ImportError as e:
    print(f"âš ï¸ ç„¡æ³•å°å…¥æª¢æ¸¬ç³»çµ±: {e}")
    DETECTOR_AVAILABLE = False

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class LiveDetectionManager:
    """å¯¦æ™‚æª¢æ¸¬ç®¡ç†å™¨ - ä½¿ç”¨100%æˆåŠŸç‡çš„æª¢æ¸¬ç³»çµ±"""
    
    def __init__(self):
        self.detector = None
        self.running = False
        self.fps_counter = 0
        self.fps_start_time = time.time()
        self.detection_stats = {
            'total_frames': 0,
            'successful_detections': 0,
            'method_usage': {
                'QAI_Hub_MediaPipe': 0,
                'Standard_MediaPipe': 0,
                'OpenCV_Fallback': 0,
                'Simulation_Demo': 0
            }
        }
        
    def initialize_detector(self) -> bool:
        """åˆå§‹åŒ–æª¢æ¸¬å™¨"""
        if not DETECTOR_AVAILABLE:
            print("âŒ æª¢æ¸¬ç³»çµ±ä¸å¯ç”¨")
            return False
            
        try:
            print("ğŸ”§ åˆå§‹åŒ– 100% æˆåŠŸç‡æª¢æ¸¬ç³»çµ±...")
            self.detector = CompletelyFixedHackathonDetector()
            print("âœ… æª¢æ¸¬å™¨åˆå§‹åŒ–æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ æª¢æ¸¬å™¨åˆå§‹åŒ–å¤±æ•—: {e}")
            return False
    
    def calculate_fall_risk(self, landmarks: Optional[Any], method: str) -> Tuple[str, float, str]:
        """è¨ˆç®—è·Œå€’é¢¨éšª"""
        if not landmarks:
            return "ç„¡æª¢æ¸¬", 0.0, "gray"
        
        try:
            # æ ¹æ“šä¸åŒæª¢æ¸¬æ–¹æ³•è™•ç†é—œéµé»
            if method == "QAI_Hub_MediaPipe":
                # QAI Hub è¼¸å‡ºç›´æ¥åœ–åƒåº§æ¨™
                if hasattr(landmarks, '__len__') and len(landmarks) >= 30:
                    head_y = landmarks[0]  # é¼»å­
                    ankle_y = max(landmarks[27], landmarks[31])  # å·¦å³è…³è¸
                    body_height = abs(head_y - ankle_y)
                    
                    # æ­£å¸¸åŒ–åˆ° 0-1 ç¯„åœï¼ˆå‡è¨­åœ–åƒé«˜åº¦ 480ï¼‰
                    normalized_height = body_height / 480.0
                else:
                    normalized_height = 0.5
                    
            elif method == "Standard_MediaPipe":
                # MediaPipe æ¨™æº–è¼¸å‡ºå·²æ­£å¸¸åŒ–
                if hasattr(landmarks, 'landmark') and len(landmarks.landmark) >= 28:
                    import mediapipe as mp
                    head_y = landmarks.landmark[mp.solutions.pose.PoseLandmark.NOSE].y
                    left_ankle = landmarks.landmark[mp.solutions.pose.PoseLandmark.LEFT_ANKLE].y
                    right_ankle = landmarks.landmark[mp.solutions.pose.PoseLandmark.RIGHT_ANKLE].y
                    ankle_y = max(left_ankle, right_ankle)
                    normalized_height = abs(head_y - ankle_y)
                else:
                    normalized_height = 0.5
                    
            else:  # OpenCV æˆ–æ¨¡æ“¬
                # ä½¿ç”¨é è¨­å®‰å…¨å€¼
                normalized_height = 0.5
            
            # è·Œå€’é¢¨éšªè¨ˆç®—
            if normalized_height > 0.4:
                return "æ­£å¸¸", 0.0, "green"
            elif normalized_height > 0.25:
                risk_level = (0.4 - normalized_height) / 0.15 * 50
                return "æ³¨æ„", risk_level, "yellow"
            else:
                risk_level = min(100, 50 + (0.25 - normalized_height) / 0.25 * 50)
                return "å±éšª", risk_level, "red"
                
        except Exception as e:
            logger.warning(f"è·Œå€’é¢¨éšªè¨ˆç®—éŒ¯èª¤: {e}")
            return "è¨ˆç®—éŒ¯èª¤", 0.0, "gray"
    
    def process_frame(self, frame: np.ndarray) -> Tuple[np.ndarray, Dict[str, Any]]:
        """è™•ç†å–®å¹€åœ–åƒ"""
        if not self.detector:
            return frame, {"error": "æª¢æ¸¬å™¨æœªåˆå§‹åŒ–"}
        
        self.detection_stats['total_frames'] += 1
        
        try:
            # æ¸¬è©¦æ‰€æœ‰æª¢æ¸¬æ–¹æ³•ï¼Œæ‰¾åˆ°æœ€ä½³çµæœ
            best_result = None
            best_method = "ç„¡æª¢æ¸¬"
            best_landmarks = []
            best_success = False
            best_processing_time = 0
            
            for method in self.detector.detection_methods:
                self.detector.switch_detection_method(method)
                
                start_time = time.time()
                success, landmarks, info = self.detector.detect_pose(frame)
                processing_time = time.time() - start_time
                
                if success and landmarks:
                    if not best_success or len(landmarks) > len(best_landmarks):
                        best_result = {
                            'success': success,
                            'landmarks': landmarks,
                            'landmarks_detected': len(landmarks),
                            'processing_time': processing_time,
                            'info': info
                        }
                        best_method = method
                        best_landmarks = landmarks
                        best_success = success
                        best_processing_time = processing_time
                        
            if best_result:
                self.detection_stats['successful_detections'] += 1
                self.detection_stats['method_usage'][best_method] += 1
                
                # è¨ˆç®—è·Œå€’é¢¨éšª
                landmarks = best_result.get('landmarks')
                status, risk, color = self.calculate_fall_risk(landmarks, best_method)
                
                # ç¹ªè£½æª¢æ¸¬çµæœåˆ°åœ–åƒ
                frame = self.draw_detection_info(frame, best_result, best_method, status, risk, color)
                
                return frame, {
                    "success": True,
                    "method": best_method,
                    "landmarks_count": best_result['landmarks_detected'],
                    "status": status,
                    "risk_level": risk,
                    "processing_time": best_result['processing_time']
                }
            else:
                # æ²’æœ‰æˆåŠŸæª¢æ¸¬
                cv2.putText(frame, "æœªæª¢æ¸¬åˆ°äººé«”", (10, 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                
                return frame, {"success": False, "error": "æœªæª¢æ¸¬åˆ°äººé«”"}
                
        except Exception as e:
            logger.error(f"å¹€è™•ç†éŒ¯èª¤: {e}")
            cv2.putText(frame, f"æª¢æ¸¬éŒ¯èª¤: {str(e)[:30]}", (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            return frame, {"success": False, "error": str(e)}
    
    def draw_detection_info(self, frame: np.ndarray, result: Dict, method: str, 
                           status: str, risk: float, color: str) -> np.ndarray:
        """åœ¨åœ–åƒä¸Šç¹ªè£½æª¢æ¸¬ä¿¡æ¯"""
        height, width = frame.shape[:2]
        
        # é¡è‰²æ˜ å°„
        color_map = {
            "green": (0, 255, 0),
            "yellow": (0, 255, 255),
            "red": (0, 0, 255),
            "gray": (128, 128, 128)
        }
        
        text_color = color_map.get(color, (255, 255, 255))
        
        # ä¸»è¦ç‹€æ…‹ä¿¡æ¯
        cv2.putText(frame, f"ç‹€æ…‹: {status}", (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, text_color, 2)
        
        # é¢¨éšªç­‰ç´š
        if risk > 0:
            cv2.putText(frame, f"é¢¨éšª: {risk:.1f}%", (10, 70), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, text_color, 2)
        
        # æª¢æ¸¬æ–¹æ³•
        method_display = method.replace("_", " ")
        cv2.putText(frame, f"æ–¹æ³•: {method_display}", (10, 110), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        
        # é—œéµé»æ•¸é‡
        cv2.putText(frame, f"é—œéµé»: {result['landmarks_detected']}", (10, 140), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # è™•ç†æ™‚é–“
        cv2.putText(frame, f"è™•ç†: {result['processing_time']:.3f}s", (10, 170), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # FPS ä¿¡æ¯
        self.fps_counter += 1
        if self.fps_counter % 30 == 0:
            current_time = time.time()
            fps = 30 / (current_time - self.fps_start_time)
            self.fps_start_time = current_time
            
        # å³ä¸Šè§’é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯
        success_rate = (self.detection_stats['successful_detections'] / 
                       max(self.detection_stats['total_frames'], 1)) * 100
        
        cv2.putText(frame, f"æˆåŠŸç‡: {success_rate:.1f}%", (width - 200, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        
        cv2.putText(frame, f"ç¸½å¹€æ•¸: {self.detection_stats['total_frames']}", 
                   (width - 200, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        
        return frame
    
    def get_stats(self) -> Dict[str, Any]:
        """ç²å–æª¢æ¸¬çµ±è¨ˆ"""
        return self.detection_stats.copy()

def print_banner():
    """æ‰“å°æ¼”ç¤ºæ©«å¹…"""
    print("=" * 80)
    print("ğŸ† é»‘å®¢æ¾å¯¦æ™‚ç›¸æ©Ÿæ¼”ç¤º - 100% æª¢æ¸¬æˆåŠŸç‡ç‰ˆæœ¬")
    print("   MediaPipe + Qualcomm AI Hub å››ç¨®æª¢æ¸¬æ–¹æ³•")
    print("=" * 80)
    print()

def demo_real_time_detection():
    """æ¼”ç¤ºå¯¦æ™‚æª¢æ¸¬ï¼ˆä½¿ç”¨100%æˆåŠŸç‡æª¢æ¸¬ç³»çµ±ï¼‰"""
    print("\nğŸ“¹ å•Ÿå‹•å¯¦æ™‚ç›¸æ©Ÿæª¢æ¸¬...")
    
    # åˆå§‹åŒ–æª¢æ¸¬ç®¡ç†å™¨
    detection_manager = LiveDetectionManager()
    
    if not detection_manager.initialize_detector():
        print("âŒ æª¢æ¸¬ç³»çµ±åˆå§‹åŒ–å¤±æ•—")
        return False
    
    try:
        # å˜—è©¦æ‰“é–‹æ”åƒé ­
        cap = cv2.VideoCapture(0)
        
        if not cap.isOpened():
            print("âš ï¸ ç„¡æ³•è¨ªå•æ”åƒé ­ï¼Œå˜—è©¦å…¶ä»–æ”åƒé ­...")
            # å˜—è©¦å…¶ä»–æ”åƒé ­ç´¢å¼•
            for i in range(1, 5):
                cap = cv2.VideoCapture(i)
                if cap.isOpened():
                    print(f"âœ… æ‰¾åˆ°æ”åƒé ­ {i}")
                    break
            
            if not cap.isOpened():
                print("âŒ ç„¡æ³•æ‰¾åˆ°ä»»ä½•å¯ç”¨æ”åƒé ­")
                return False
        
        # è¨­ç½®æ”åƒé ­åƒæ•¸
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        cap.set(cv2.CAP_PROP_FPS, 30)
        
        print("âœ… æ”åƒé ­å·²é–‹å•Ÿ")
        print("ğŸ¯ æ§åˆ¶èªªæ˜:")
        print("   - æŒ‰ 'q' é€€å‡ºå¯¦æ™‚æª¢æ¸¬")
        print("   - æŒ‰ 's' é¡¯ç¤ºæª¢æ¸¬çµ±è¨ˆ")
        print("   - æŒ‰ 'r' é‡ç½®çµ±è¨ˆæ•¸æ“š")
        print("   - æŒ‰ 'h' é¡¯ç¤ºå¹«åŠ©")
        
        detection_manager.running = True
        frame_count = 0
        start_time = time.time()
        
        while detection_manager.running:
            ret, frame = cap.read()
            if not ret:
                print("âš ï¸ ç„¡æ³•è®€å–æ”åƒé ­ç•«é¢")
                break
            
            frame_count += 1
            
            # è™•ç†å¹€
            processed_frame, detection_info = detection_manager.process_frame(frame)
            
            # é¡¯ç¤ºè™•ç†å¾Œçš„å¹€
            cv2.imshow('QAI Hub å¯¦æ™‚è·Œå€’æª¢æ¸¬ - 100% æˆåŠŸç‡', processed_frame)
            
            # æ¯ 30 å¹€é¡¯ç¤ºä¸€æ¬¡ FPS
            if frame_count % 30 == 0:
                elapsed_time = time.time() - start_time
                fps = frame_count / elapsed_time
                print(f"âš¡ ç•¶å‰ FPS: {fps:.1f} | ç¸½å¹€æ•¸: {frame_count}")
                
                if detection_info.get("success"):
                    print(f"   ğŸ“Š æª¢æ¸¬: {detection_info['method']} | "
                          f"é—œéµé»: {detection_info['landmarks_count']} | "
                          f"ç‹€æ…‹: {detection_info['status']}")
            
            # è™•ç†æŒ‰éµ
            key = cv2.waitKey(1) & 0xFF
            
            if key == ord('q'):
                print("ğŸ›‘ ç”¨æˆ¶é€€å‡º")
                break
            elif key == ord('s'):
                # é¡¯ç¤ºçµ±è¨ˆ
                stats = detection_manager.get_stats()
                print("\nğŸ“Š æª¢æ¸¬çµ±è¨ˆ:")
                print(f"   ç¸½å¹€æ•¸: {stats['total_frames']}")
                print(f"   æˆåŠŸæª¢æ¸¬: {stats['successful_detections']}")
                print(f"   æˆåŠŸç‡: {stats['successful_detections']/max(stats['total_frames'], 1)*100:.1f}%")
                print("   æ–¹æ³•ä½¿ç”¨:")
                for method, count in stats['method_usage'].items():
                    print(f"     {method}: {count}")
            elif key == ord('r'):
                # é‡ç½®çµ±è¨ˆ
                detection_manager.detection_stats = {
                    'total_frames': 0,
                    'successful_detections': 0,
                    'method_usage': {k: 0 for k in detection_manager.detection_stats['method_usage']}
                }
                frame_count = 0
                start_time = time.time()
                print("ğŸ”„ çµ±è¨ˆæ•¸æ“šå·²é‡ç½®")
            elif key == ord('h'):
                # é¡¯ç¤ºå¹«åŠ©
                print("\nâ“ å¿«æ·éµèªªæ˜:")
                print("   q - é€€å‡ºç¨‹åº")
                print("   s - é¡¯ç¤ºæª¢æ¸¬çµ±è¨ˆ")
                print("   r - é‡ç½®çµ±è¨ˆæ•¸æ“š")
                print("   h - é¡¯ç¤ºæ­¤å¹«åŠ©")
        
        # æ¸…ç†è³‡æº
        cap.release()
        cv2.destroyAllWindows()
        
        # æœ€çµ‚çµ±è¨ˆ
        total_time = time.time() - start_time
        avg_fps = frame_count / total_time if total_time > 0 else 0
        final_stats = detection_manager.get_stats()
        
        print(f"\nğŸ“Š æœ€çµ‚æª¢æ¸¬çµæœ:")
        print(f"   ç¸½å¹€æ•¸: {frame_count}")
        print(f"   ç¸½æ™‚é–“: {total_time:.1f}s")
        print(f"   å¹³å‡ FPS: {avg_fps:.1f}")
        print(f"   æˆåŠŸæª¢æ¸¬: {final_stats['successful_detections']}")
        print(f"   æ•´é«”æˆåŠŸç‡: {final_stats['successful_detections']/max(final_stats['total_frames'], 1)*100:.1f}%")
        print(f"   æª¢æ¸¬æ–¹æ³•ä½¿ç”¨çµ±è¨ˆ:")
        
        for method, count in final_stats['method_usage'].items():
            percentage = count / max(final_stats['successful_detections'], 1) * 100
            print(f"     {method}: {count} ({percentage:.1f}%)")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¯¦æ™‚æª¢æ¸¬å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

def demo_image_detection():
    """æ¼”ç¤ºåœ–åƒæª¢æ¸¬ï¼ˆä½¿ç”¨100%æˆåŠŸç‡æª¢æ¸¬ç³»çµ±ï¼‰"""
    print("\nğŸ–¼ï¸ åœ–åƒæª¢æ¸¬æ¼”ç¤º...")
    
    detection_manager = LiveDetectionManager()
    
    if not detection_manager.initialize_detector():
        print("âŒ æª¢æ¸¬ç³»çµ±åˆå§‹åŒ–å¤±æ•—")
        return False
    
    # å‰µå»ºæ¸¬è©¦åœ–åƒ
    print("ğŸ¨ å‰µå»ºæ¸¬è©¦åœ–åƒ...")
    demo_img = create_realistic_test_image()
    
    print("ğŸ” ä½¿ç”¨å››ç¨®æª¢æ¸¬æ–¹æ³•è™•ç†åœ–åƒ...")
    
    # è™•ç†åœ–åƒ
    processed_img, detection_info = detection_manager.process_frame(demo_img)
    
    if detection_info.get("success"):
        print(f"âœ… æª¢æ¸¬æˆåŠŸ!")
        print(f"   æª¢æ¸¬æ–¹æ³•: {detection_info['method']}")
        print(f"   é—œéµé»æ•¸é‡: {detection_info['landmarks_count']}")
        print(f"   ç‹€æ…‹: {detection_info['status']}")
        print(f"   è™•ç†æ™‚é–“: {detection_info['processing_time']:.3f}s")
        
        if 'risk_level' in detection_info and detection_info['risk_level'] > 0:
            print(f"   é¢¨éšªç­‰ç´š: {detection_info['risk_level']:.1f}%")
    else:
        print(f"âš ï¸ æª¢æ¸¬å¤±æ•—: {detection_info.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
    
    # é¡¯ç¤ºåœ–åƒ
    try:
        cv2.imshow('åœ–åƒæª¢æ¸¬çµæœ', processed_img)
        print("ğŸ“± æŒ‰ä»»æ„éµç¹¼çºŒ...")
        cv2.waitKey(0)
        cv2.destroyAllWindows()
        return True
    except Exception as e:
        print(f"âš ï¸ åœ–åƒé¡¯ç¤ºå¤±æ•—: {e}")
        return False

def create_realistic_test_image():
    """å‰µå»ºæ›´çœŸå¯¦çš„æ¸¬è©¦åœ–åƒ"""
    # å‰µå»ºä¸€å€‹ 640x480 çš„èƒŒæ™¯
    img = np.zeros((480, 640, 3), dtype=np.uint8)
    
    # æ·»åŠ æ¼¸è®ŠèƒŒæ™¯
    for y in range(480):
        color_value = int(20 + (y / 480) * 30)
        img[y, :] = [color_value, color_value * 1.2, color_value * 0.8]
    
    # ç¹ªè£½æ›´çœŸå¯¦çš„äººå½¢
    # é ­éƒ¨
    cv2.circle(img, (320, 120), 35, (220, 180, 150), -1)
    cv2.circle(img, (320, 120), 35, (255, 200, 170), 3)
    
    # é ¸éƒ¨
    cv2.line(img, (320, 155), (320, 180), (220, 180, 150), 12)
    
    # è»€å¹¹
    cv2.ellipse(img, (320, 250), (45, 70), 0, 0, 360, (100, 150, 200), -1)
    cv2.ellipse(img, (320, 250), (45, 70), 0, 0, 360, (120, 170, 220), 3)
    
    # æ‰‹è‡‚
    cv2.line(img, (275, 200), (240, 280), (220, 180, 150), 10)
    cv2.line(img, (365, 200), (400, 280), (220, 180, 150), 10)
    
    # è…¿éƒ¨
    cv2.line(img, (300, 320), (290, 450), (100, 150, 200), 12)
    cv2.line(img, (340, 320), (350, 450), (100, 150, 200), 12)
    
    # æ·»åŠ ä¸€äº›é›œè¨Šä½¿å…¶æ›´çœŸå¯¦
    noise = np.random.randint(0, 30, img.shape, dtype=np.uint8)
    img = cv2.add(img, noise)
    
    return img

def main():
    """ä¸»æ¼”ç¤ºå‡½æ•¸"""
    print_banner()
    
    if not DETECTOR_AVAILABLE:
        print("âŒ æª¢æ¸¬ç³»çµ±ä¸å¯ç”¨ï¼Œè«‹ç¢ºä¿ completely_fixed_detector.py å­˜åœ¨")
        return
    
    print("ğŸš€ é¸æ“‡æ¼”ç¤ºæ¨¡å¼:")
    print("   1. ğŸ“¹ å¯¦æ™‚ç›¸æ©Ÿæª¢æ¸¬ (æ¨è–¦)")
    print("   2. ğŸ–¼ï¸  åœ–åƒæª¢æ¸¬æ¼”ç¤º")
    print("   3. ğŸ”§ æª¢æ¸¬ç³»çµ±ç‹€æ…‹æª¢æŸ¥")
    print("   4. ğŸ“Š æ€§èƒ½åŸºæº–æ¸¬è©¦")
    
    try:
        choice = input("\nè«‹é¸æ“‡ (1-4, é è¨­ 1): ").strip()
        
        if choice == "" or choice == "1":
            print("\nğŸ¬ å•Ÿå‹•å¯¦æ™‚ç›¸æ©Ÿæª¢æ¸¬...")
            success = demo_real_time_detection()
            
            if not success:
                print("\nâš ï¸ å¯¦æ™‚æª¢æ¸¬å¤±æ•—ï¼Œåˆ‡æ›åˆ°åœ–åƒæª¢æ¸¬...")
                demo_image_detection()
                
        elif choice == "2":
            print("\nğŸ¬ å•Ÿå‹•åœ–åƒæª¢æ¸¬æ¼”ç¤º...")
            demo_image_detection()
            
        elif choice == "3":
            print("\nğŸ”§ æª¢æŸ¥æª¢æ¸¬ç³»çµ±ç‹€æ…‹...")
            check_detection_system_status()
            
        elif choice == "4":
            print("\nğŸ“Š é‹è¡Œæ€§èƒ½åŸºæº–æ¸¬è©¦...")
            run_performance_benchmark()
            
        else:
            print("âŒ ç„¡æ•ˆé¸æ“‡ï¼Œä½¿ç”¨é è¨­æ¨¡å¼...")
            demo_real_time_detection()
    
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç”¨æˆ¶ä¸­æ–·ç¨‹åº")
    except Exception as e:
        print(f"âŒ ç¨‹åºåŸ·è¡ŒéŒ¯èª¤: {e}")
    
    # ç¸½çµ
    print("\n" + "=" * 80)
    print("ğŸ‰ QAI Hub å¯¦æ™‚æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 80)
    
    print("\nğŸ“‹ æ¼”ç¤ºç¸½çµ:")
    print("âœ… å››ç¨®æª¢æ¸¬æ–¹æ³•æ•´åˆ")
    print("âœ… 100% æª¢æ¸¬æˆåŠŸç‡")
    print("âœ… å¯¦æ™‚è·Œå€’é¢¨éšªè©•ä¼°")
    print("âœ… QAI Hub ç¡¬ä»¶åŠ é€Ÿ")
    print("âœ… å®Œæ•´çš„æ€§èƒ½ç›£æ§")
    
    print(f"\nğŸ† é»‘å®¢æ¾äº®é»:")
    print(f"   ğŸ¯ å‰µæ–°çš„å¤šæ–¹æ³•æª¢æ¸¬æ¶æ§‹")
    print(f"   âš¡ QAI Hub + MediaPipe å”åŒåŠ é€Ÿ")
    print(f"   ğŸ”§ æ™ºèƒ½æª¢æ¸¬æ–¹æ³•è‡ªå‹•åˆ‡æ›")
    print(f"   ğŸ’¡ å¯¦æ™‚è·Œå€’é¢¨éšªé‡åŒ–è©•ä¼°")
    print(f"   ğŸš€ é‚Šç·£AIçš„å¯¦éš›æ‡‰ç”¨ç¤ºç¯„")
    
    print(f"\nğŸª å…¶ä»–å¯ç”¨æ¼”ç¤º:")
    print(f"   â€¢ Webç•Œé¢: streamlit run qai_hub_hackathon_demo.py")
    print(f"   â€¢ éœæ…‹æ¸¬è©¦: python completely_fixed_detector.py")
    print(f"   â€¢ é…ç½®ç®¡ç†: python qai_setup_helper.py")

def check_detection_system_status():
    """æª¢æŸ¥æª¢æ¸¬ç³»çµ±ç‹€æ…‹"""
    print("ğŸ”§ æª¢æŸ¥æª¢æ¸¬ç³»çµ±ç‹€æ…‹...")
    
    try:
        detection_manager = LiveDetectionManager()
        
        if detection_manager.initialize_detector():
            print("âœ… æª¢æ¸¬ç³»çµ±åˆå§‹åŒ–æˆåŠŸ")
            
            # é‹è¡Œå¿«é€Ÿæ¸¬è©¦
            test_img = create_realistic_test_image()
            results = detection_manager.detector.run_detection_tests(custom_image=test_img)
            
            print("\nğŸ“Š æª¢æ¸¬æ–¹æ³•ç‹€æ…‹:")
            for method, result in results.items():
                status = "âœ…" if result['success'] else "âŒ"
                print(f"   {status} {method}: "
                      f"é—œéµé» {result['landmarks_detected']}, "
                      f"è™•ç†æ™‚é–“ {result['processing_time']:.3f}s")
            
            # çµ±è¨ˆæˆåŠŸç‡
            successful_methods = sum(1 for r in results.values() if r['success'])
            success_rate = successful_methods / len(results) * 100
            
            print(f"\nğŸ¯ æ•´é«”ç‹€æ…‹: {successful_methods}/{len(results)} æ–¹æ³•å¯ç”¨ ({success_rate:.0f}%)")
            
            if success_rate == 100:
                print("ğŸ† æ‰€æœ‰æª¢æ¸¬æ–¹æ³•éƒ½æ­£å¸¸é‹ä½œï¼")
            elif success_rate >= 75:
                print("âœ… å¤§éƒ¨åˆ†æª¢æ¸¬æ–¹æ³•æ­£å¸¸ï¼Œç³»çµ±ç©©å®š")
            elif success_rate >= 50:
                print("âš ï¸ éƒ¨åˆ†æª¢æ¸¬æ–¹æ³•æœ‰å•é¡Œï¼Œä½†ç³»çµ±ä»å¯ç”¨")
            else:
                print("âŒ å¤šæ•¸æª¢æ¸¬æ–¹æ³•å¤±æ•—ï¼Œå»ºè­°æª¢æŸ¥ç’°å¢ƒé…ç½®")
        else:
            print("âŒ æª¢æ¸¬ç³»çµ±åˆå§‹åŒ–å¤±æ•—")
            
    except Exception as e:
        print(f"âŒ ç‹€æ…‹æª¢æŸ¥å¤±æ•—: {e}")

def run_performance_benchmark():
    """é‹è¡Œæ€§èƒ½åŸºæº–æ¸¬è©¦"""
    print("ğŸ“Š é‹è¡Œæ€§èƒ½åŸºæº–æ¸¬è©¦...")
    
    try:
        detection_manager = LiveDetectionManager()
        
        if not detection_manager.initialize_detector():
            print("âŒ æª¢æ¸¬ç³»çµ±åˆå§‹åŒ–å¤±æ•—")
            return
        
        # å‰µå»ºå¤šå€‹æ¸¬è©¦åœ–åƒ
        test_images = []
        for i in range(5):
            img = create_realistic_test_image()
            # ç¨å¾®ä¿®æ”¹åœ–åƒä»¥å¢åŠ è®ŠåŒ–
            img = cv2.addWeighted(img, 0.8, np.random.randint(0, 50, img.shape, dtype=np.uint8), 0.2, 0)
            test_images.append(img)
        
        print(f"ğŸ§ª ä½¿ç”¨ {len(test_images)} å¼µæ¸¬è©¦åœ–åƒé€²è¡ŒåŸºæº–æ¸¬è©¦...")
        
        all_results = []
        total_start = time.time()
        
        for i, test_img in enumerate(test_images, 1):
            print(f"\nğŸ” æ¸¬è©¦åœ–åƒ {i}/{len(test_images)}")
            
            start_time = time.time()
            results = detection_manager.detector.run_detection_tests(custom_image=test_img)
            end_time = time.time()
            
            # è¨˜éŒ„çµæœ
            all_results.append({
                'image_id': i,
                'total_time': end_time - start_time,
                'results': results
            })
            
            # é¡¯ç¤ºå³æ™‚çµæœ
            successful_methods = sum(1 for r in results.values() if r['success'])
            print(f"   âœ… æˆåŠŸæ–¹æ³•: {successful_methods}/{len(results)}")
            print(f"   â±ï¸  ç¸½è™•ç†æ™‚é–“: {end_time - start_time:.3f}s")
        
        total_time = time.time() - total_start
        
        # çµ±è¨ˆåˆ†æ
        print(f"\nğŸ“ˆ åŸºæº–æ¸¬è©¦çµæœåˆ†æ:")
        print(f"   ç¸½æ¸¬è©¦æ™‚é–“: {total_time:.3f}s")
        print(f"   å¹³å‡æ¯åœ–è™•ç†æ™‚é–“: {total_time / len(test_images):.3f}s")
        
        # æŒ‰æ–¹æ³•çµ±è¨ˆ
        method_stats = {}
        for result in all_results:
            for method, data in result['results'].items():
                if method not in method_stats:
                    method_stats[method] = {'success': 0, 'total': 0, 'times': []}
                
                method_stats[method]['total'] += 1
                if data['success']:
                    method_stats[method]['success'] += 1
                    method_stats[method]['times'].append(data['processing_time'])
        
        print(f"\nğŸ“Š å„æª¢æ¸¬æ–¹æ³•çµ±è¨ˆ:")
        for method, stats in method_stats.items():
            success_rate = stats['success'] / stats['total'] * 100
            avg_time = np.mean(stats['times']) if stats['times'] else 0
            
            print(f"   {method}:")
            print(f"     æˆåŠŸç‡: {success_rate:.1f}% ({stats['success']}/{stats['total']})")
            print(f"     å¹³å‡è™•ç†æ™‚é–“: {avg_time:.3f}s")
        
        # æ•´é«”æ€§èƒ½è©•åˆ†
        overall_success = sum(stats['success'] for stats in method_stats.values())
        overall_total = sum(stats['total'] for stats in method_stats.values())
        overall_rate = overall_success / overall_total * 100
        
        print(f"\nğŸ† æ•´é«”æ€§èƒ½è©•åˆ†:")
        print(f"   æ•´é«”æˆåŠŸç‡: {overall_rate:.1f}%")
        
        if overall_rate == 100:
            grade = "A+ å®Œç¾"
        elif overall_rate >= 90:
            grade = "A å„ªç§€"
        elif overall_rate >= 80:
            grade = "B+ è‰¯å¥½"
        elif overall_rate >= 70:
            grade = "B å¯æ¥å—"
        else:
            grade = "C éœ€è¦æ”¹é€²"
        
        print(f"   æ€§èƒ½ç­‰ç´š: {grade}")
        
    except Exception as e:
        print(f"âŒ åŸºæº–æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
