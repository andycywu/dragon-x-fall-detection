#!/usr/bin/env python3
"""
ğŸŒ å¯¦ç”¨çš„QAI Hub + ONNX Runtimeé›†æˆç³»çµ±
çœŸæ­£é€£æ¥QAI Hubä¸¦å°å‡ºå„ªåŒ–å¾Œçš„ONNXæ¨¡å‹
"""

import os
import qai_hub as hub
import numpy as np
import cv2
import onnxruntime as ort
import logging
from pathlib import Path
from dotenv import load_dotenv
from typing import Dict, Any, Optional
import time
import json
import tempfile

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class QAIHubONNXIntegration:
    """QAI Hub + ONNX Runtimeé›†æˆç³»çµ±"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç³»çµ±"""
        self.api_token = os.getenv('QAI_HUB_API_TOKEN')
        if not self.api_token:
            raise ValueError("âŒ è«‹åœ¨.envæ–‡ä»¶ä¸­è¨­ç½®QAI_HUB_API_TOKEN")
        
        # ONNX Runtimeé…ç½®
        self.onnx_providers = self._get_onnx_providers()
        self.onnx_sessions = {}
        
        # QAI Hubæ¨¡å‹å’ŒJobs
        self.models = {}
        self.compile_jobs = {}
        
        logger.info("ğŸš€ åˆå§‹åŒ–QAI Hub + ONNXé›†æˆç³»çµ±...")
        self._verify_connection()
        
    def _verify_connection(self):
        """é©—è­‰QAI Hubé€£æ¥"""
        try:
            devices = hub.get_devices()
            logger.info(f"âœ… QAI Hubé€£æ¥æˆåŠŸï¼Œå¯ç”¨è¨­å‚™: {len(devices)}")
            
            # é¸æ“‡ç›®æ¨™è¨­å‚™
            self.target_device = devices[0] if devices else None
            if self.target_device:
                logger.info(f"ğŸ¯ ç›®æ¨™è¨­å‚™: {self.target_device.name}")
        except Exception as e:
            logger.error(f"âŒ QAI Hubé€£æ¥å¤±æ•—: {e}")
            raise
    
    def _get_onnx_providers(self):
        """ç²å–ONNX Runtimeæä¾›å•†"""
        providers = []
        available = ort.get_available_providers()
        
        if 'CUDAExecutionProvider' in available:
            providers.append('CUDAExecutionProvider')
            logger.info("âœ… å•Ÿç”¨CUDAåŠ é€Ÿ")
        elif 'DmlExecutionProvider' in available:
            providers.append('DmlExecutionProvider')
            logger.info("âœ… å•Ÿç”¨DirectMLåŠ é€Ÿ")
        
        providers.append('CPUExecutionProvider')
        return providers
    
    def load_mediapipe_models(self):
        """è¼‰å…¥MediaPipeæ¨¡å‹"""
        logger.info("ğŸ“¥ è¼‰å…¥MediaPipeæ¨¡å‹...")
        
        model_configs = {
            'face': {
                'import_path': 'qai_hub_models.models.mediapipe_face',
                'input_shape': (1, 3, 192, 192),
                'description': 'MediaPipe Face Detection'
            },
            'pose': {
                'import_path': 'qai_hub_models.models.mediapipe_pose',
                'input_shape': (1, 3, 256, 256),
                'description': 'MediaPipe Pose Estimation'
            },
            'hand': {
                'import_path': 'qai_hub_models.models.mediapipe_hand',
                'input_shape': (1, 3, 224, 224),
                'description': 'MediaPipe Hand Detection'
            }
        }
        
        for model_name, config in model_configs.items():
            try:
                logger.info(f"ğŸ“± è¼‰å…¥{config['description']}...")
                
                # å‹•æ…‹å°å…¥æ¨¡å‹
                module_path = config['import_path']
                module = __import__(module_path, fromlist=['Model'])
                ModelClass = getattr(module, 'Model')
                
                # å‰µå»ºæ¨¡å‹å¯¦ä¾‹
                model = ModelClass.from_pretrained()
                self.models[model_name] = {
                    'model': model,
                    'input_shape': config['input_shape'],
                    'description': config['description']
                }
                
                logger.info(f"âœ… {config['description']}è¼‰å…¥æˆåŠŸ")
                
            except Exception as e:
                logger.error(f"âŒ {config['description']}è¼‰å…¥å¤±æ•—: {e}")
    
    def submit_compile_jobs(self):
        """æäº¤ç·¨è­¯Jobsåˆ°QAI Hub"""
        if not self.target_device:
            logger.error("âŒ æ²’æœ‰å¯ç”¨çš„ç›®æ¨™è¨­å‚™")
            return
        
        logger.info("ğŸ”„ æäº¤æ¨¡å‹ç·¨è­¯Jobs...")
        
        for model_name, model_info in self.models.items():
            try:
                model = model_info['model']
                input_shape = model_info['input_shape']
                
                logger.info(f"ğŸ“¤ æäº¤{model_info['description']}ç·¨è­¯Job...")
                
                # æäº¤ç·¨è­¯Job
                compile_job = hub.submit_compile_job(
                    model=model,
                    input_specs={"image": (input_shape, "float32")},
                    device=self.target_device,
                )
                
                self.compile_jobs[model_name] = compile_job
                
                logger.info(f"âœ… {model_info['description']}ç·¨è­¯Jobæäº¤æˆåŠŸ")
                logger.info(f"   Job ID: {compile_job.job_id}")
                logger.info(f"   Dashboard: https://aihub.qualcomm.com/jobs/{compile_job.job_id}")
                
            except Exception as e:
                logger.error(f"âŒ {model_info['description']}ç·¨è­¯Jobæäº¤å¤±æ•—: {e}")
    
    def export_onnx_models(self, wait_for_compilation=False):
        """å°å‡ºONNXæ¨¡å‹"""
        logger.info("ğŸ“¤ å°å‡ºONNXæ¨¡å‹...")
        
        for model_name, model_info in self.models.items():
            try:
                model = model_info['model']
                input_shape = model_info['input_shape']
                
                logger.info(f"ğŸ”„ å°å‡º{model_info['description']}ç‚ºONNX...")
                
                # æº–å‚™ç¤ºä¾‹è¼¸å…¥
                sample_input = {"image": np.random.randn(*input_shape).astype(np.float32)}
                
                # å¦‚æœæœ‰ç·¨è­¯Jobä¸”ç­‰å¾…ç·¨è­¯å®Œæˆ
                if wait_for_compilation and model_name in self.compile_jobs:
                    try:
                        logger.info(f"â³ ç­‰å¾…{model_name}ç·¨è­¯å®Œæˆ...")
                        compile_job = self.compile_jobs[model_name]
                        compile_job.wait(timeout=180)  # 3åˆ†é˜è¶…æ™‚
                        
                        if compile_job.success:
                            logger.info(f"âœ… {model_name}ç·¨è­¯æˆåŠŸï¼Œä½¿ç”¨å„ªåŒ–å¾Œçš„æ¨¡å‹")
                            # ä½¿ç”¨ç·¨è­¯å¾Œçš„æ¨¡å‹å°å‡ºONNX
                            optimized_model = compile_job.get_target_model()
                            onnx_model = hub.get_onnx_model(optimized_model, sample_input)
                        else:
                            logger.warning(f"âš ï¸ {model_name}ç·¨è­¯å¤±æ•—ï¼Œä½¿ç”¨åŸå§‹æ¨¡å‹")
                            onnx_model = hub.get_onnx_model(model, sample_input)
                    except Exception as e:
                        logger.warning(f"âš ï¸ ç­‰å¾…ç·¨è­¯è¶…æ™‚: {e}ï¼Œä½¿ç”¨åŸå§‹æ¨¡å‹")
                        onnx_model = hub.get_onnx_model(model, sample_input)
                else:
                    # ç›´æ¥ä½¿ç”¨åŸå§‹æ¨¡å‹å°å‡º
                    onnx_model = hub.get_onnx_model(model, sample_input)
                
                # ä¿å­˜ONNXæ–‡ä»¶
                onnx_path = f"qai_hub_{model_name}_optimized.onnx"
                with open(onnx_path, 'wb') as f:
                    f.write(onnx_model.model)
                
                logger.info(f"âœ… {model_info['description']} ONNXå·²ä¿å­˜: {onnx_path}")
                
                # è¼‰å…¥ONNX Runtimeæœƒè©±
                self._load_onnx_session(model_name, onnx_path, model_info)
                
            except Exception as e:
                logger.error(f"âŒ {model_info['description']} ONNXå°å‡ºå¤±æ•—: {e}")
    
    def _load_onnx_session(self, model_name: str, onnx_path: str, model_info: Dict):
        """è¼‰å…¥ONNX Runtimeæœƒè©±"""
        try:
            logger.info(f"ğŸ”„ è¼‰å…¥{model_name} ONNX Runtimeæœƒè©±...")
            
            # é…ç½®æœƒè©±é¸é …
            sess_options = ort.SessionOptions()
            sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
            
            # å‰µå»ºæœƒè©±
            session = ort.InferenceSession(
                onnx_path,
                sess_options=sess_options,
                providers=self.onnx_providers
            )
            
            self.onnx_sessions[model_name] = {
                'session': session,
                'input_shape': model_info['input_shape'],
                'description': model_info['description']
            }
            
            logger.info(f"âœ… {model_name} ONNXæœƒè©±è¼‰å…¥æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"âŒ {model_name} ONNXæœƒè©±è¼‰å…¥å¤±æ•—: {e}")
    
    def detect(self, image: np.ndarray, model_name: str) -> Dict[str, Any]:
        """ä½¿ç”¨ONNX RuntimeåŸ·è¡Œæª¢æ¸¬"""
        if model_name not in self.onnx_sessions:
            return {"error": f"ONNXæœƒè©± {model_name} æœªè¼‰å…¥"}
        
        try:
            session_info = self.onnx_sessions[model_name]
            session = session_info['session']
            
            # é è™•ç†åœ–åƒ
            processed_image = self._preprocess_image(image, session_info['input_shape'])
            
            # åŸ·è¡Œæ¨ç†
            input_name = session.get_inputs()[0].name
            start_time = time.time()
            outputs = session.run(None, {input_name: processed_image})
            inference_time = (time.time() - start_time) * 1000
            
            # è™•ç†çµæœ
            results = self._process_outputs(outputs, model_name)
            results.update({
                'inference_time_ms': inference_time,
                'model_type': f"QAI_Hub_{model_name}_ONNX",
                'description': session_info['description']
            })
            
            logger.info(f"âš¡ {model_name}æª¢æ¸¬å®Œæˆ: {inference_time:.2f}ms")
            return results
            
        except Exception as e:
            logger.error(f"âŒ {model_name}æª¢æ¸¬å¤±æ•—: {e}")
            return {"error": str(e)}
    
    def _preprocess_image(self, image: np.ndarray, input_shape: tuple) -> np.ndarray:
        """é è™•ç†åœ–åƒ"""
        target_size = (input_shape[3], input_shape[2])  # (width, height)
        
        # èª¿æ•´å¤§å°
        resized = cv2.resize(image, target_size)
        
        # è½‰æ›é¡è‰²ç©ºé–“
        if len(resized.shape) == 3:
            resized = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
        
        # æ­£è¦åŒ–
        normalized = resized.astype(np.float32) / 255.0
        
        # èª¿æ•´ç¶­åº¦é †åºå’Œæ·»åŠ batchç¶­åº¦
        preprocessed = np.transpose(normalized, (2, 0, 1))
        preprocessed = np.expand_dims(preprocessed, axis=0)
        
        return preprocessed
    
    def _process_outputs(self, outputs: list, model_name: str) -> Dict[str, Any]:
        """è™•ç†æ¨¡å‹è¼¸å‡º"""
        results = {"success": True, "detections": []}
        
        try:
            if model_name == 'face' and len(outputs) >= 2:
                # äººè‡‰æª¢æ¸¬
                boxes = outputs[0]
                scores = outputs[1]
                
                threshold = 0.5
                for i, score in enumerate(scores[0]):
                    if score > threshold:
                        results["detections"].append({
                            "type": "face",
                            "confidence": float(score),
                            "box": boxes[0][i].tolist()
                        })
                        
                results["total_faces"] = len(results["detections"])
                
            elif model_name == 'pose' and len(outputs) >= 1:
                # å§¿æ…‹æª¢æ¸¬
                keypoints = outputs[0]
                if keypoints.shape[-1] >= 51:  # 17å€‹é—œéµé» * 3
                    pose_points = []
                    for i in range(0, 51, 3):
                        pose_points.append({
                            "x": float(keypoints[0][i]),
                            "y": float(keypoints[0][i+1]),
                            "confidence": float(keypoints[0][i+2])
                        })
                    
                    results["detections"] = [{
                        "type": "pose",
                        "keypoints": pose_points
                    }]
                    results["total_poses"] = 1
                    
            elif model_name == 'hand' and len(outputs) >= 1:
                # æ‰‹éƒ¨æª¢æ¸¬
                landmarks = outputs[0]
                results["detections"] = [{
                    "type": "hand",
                    "landmarks": landmarks[0].tolist()
                }]
                results["total_hands"] = 1
                
        except Exception as e:
            logger.error(f"âŒ è¼¸å‡ºè™•ç†å¤±æ•—: {e}")
            results["success"] = False
            results["error"] = str(e)
        
        return results
    
    def unified_detection(self, image: np.ndarray) -> Dict[str, Any]:
        """çµ±ä¸€æª¢æ¸¬æ¥å£"""
        results = {
            "timestamp": time.time(),
            "image_shape": image.shape,
            "detections": {},
            "performance": {},
            "total_detections": {}
        }
        
        # åŸ·è¡Œæ‰€æœ‰å¯ç”¨çš„æª¢æ¸¬
        for model_name in self.onnx_sessions.keys():
            detection_result = self.detect(image, model_name)
            results["detections"][model_name] = detection_result
            
            if "inference_time_ms" in detection_result:
                results["performance"][f"{model_name}_ms"] = detection_result["inference_time_ms"]
            
            # çµ±è¨ˆæª¢æ¸¬æ•¸é‡
            if "total_faces" in detection_result:
                results["total_detections"]["faces"] = detection_result["total_faces"]
            elif "total_poses" in detection_result:
                results["total_detections"]["poses"] = detection_result["total_poses"]
            elif "total_hands" in detection_result:
                results["total_detections"]["hands"] = detection_result["total_hands"]
        
        return results
    
    def get_job_statuses(self) -> Dict[str, Any]:
        """ç²å–æ‰€æœ‰Jobç‹€æ…‹"""
        statuses = {}
        for model_name, job in self.compile_jobs.items():
            try:
                statuses[model_name] = {
                    "job_id": job.job_id,
                    "status": job.status,
                    "dashboard": f"https://aihub.qualcomm.com/jobs/{job.job_id}"
                }
            except Exception as e:
                statuses[model_name] = {"error": str(e)}
        
        return statuses

def demo():
    """æ¼”ç¤ºQAI Hub + ONNXé›†æˆç³»çµ±"""
    print("ğŸŒ QAI Hub + ONNX Runtimeé›†æˆç³»çµ±æ¼”ç¤º")
    print("=" * 50)
    
    try:
        # åˆå§‹åŒ–ç³»çµ±
        system = QAIHubONNXIntegration()
        
        # è¼‰å…¥æ¨¡å‹
        system.load_mediapipe_models()
        
        # æäº¤ç·¨è­¯Jobs
        system.submit_compile_jobs()
        
        # å°å‡ºONNXæ¨¡å‹ï¼ˆä¸ç­‰å¾…ç·¨è­¯å®Œæˆï¼Œä½¿ç”¨åŸå§‹æ¨¡å‹ï¼‰
        system.export_onnx_models(wait_for_compilation=False)
        
        # æ¸¬è©¦æª¢æ¸¬
        print("\nğŸ§ª æ¸¬è©¦æª¢æ¸¬...")
        test_images = ['andy.jpg', 'official_test_image.jpg']
        
        for img_path in test_images:
            if os.path.exists(img_path):
                print(f"\nğŸ“· æ¸¬è©¦: {img_path}")
                image = cv2.imread(img_path)
                
                if image is not None:
                    results = system.unified_detection(image)
                    print(f"   æª¢æ¸¬çµæœ: {results['total_detections']}")
                    print(f"   æ€§èƒ½: {results['performance']}")
        
        # æª¢æŸ¥Jobç‹€æ…‹
        print("\nğŸ“Š QAI Hub Jobç‹€æ…‹:")
        statuses = system.get_job_statuses()
        for model_name, status in statuses.items():
            print(f"   {model_name}: {status}")
        
        # ä¿å­˜çµæœæ‘˜è¦
        summary = {
            "system": "QAI Hub + ONNX Runtime Integration",
            "timestamp": time.time(),
            "loaded_models": list(system.models.keys()),
            "onnx_sessions": list(system.onnx_sessions.keys()),
            "job_statuses": statuses,
            "providers": system.onnx_providers
        }
        
        with open('qai_hub_onnx_integration_results.json', 'w') as f:
            json.dump(summary, f, indent=2)
        
        print(f"\nâœ… æ¼”ç¤ºå®Œæˆï¼çµæœå·²ä¿å­˜åˆ° qai_hub_onnx_integration_results.json")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    demo()
