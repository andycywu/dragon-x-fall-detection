#!/usr/bin/env python3
"""
ğŸ‰ Dragon Xå°ˆç”¨è€äººè·Œå€’é é˜²æª¢æ¸¬ç³»çµ±
å°ˆç‚ºé»‘å®¢æ¾å„ªåŒ–ï¼Œä½¿ç”¨Snapdragon X Eliteå¹³å°
"""

import os
import qai_hub as hub
import numpy as np
import cv2
import onnxruntime as ort
import logging
from dotenv import load_dotenv
from typing import Dict, Any, List, Optional, Tuple
import time
import json
from pathlib import Path

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DragonXFallDetectionSystem:
    """Dragon Xå°ˆç”¨è€äººè·Œå€’é é˜²æª¢æ¸¬ç³»çµ±"""
    
    def __init__(self, download_compiled: bool = False, wait_compile: bool = False,
                 realtime: bool = False, camera_index: int = 0, max_frames: Optional[int] = None):
        """åˆå§‹åŒ–Dragon Xæª¢æ¸¬ç³»çµ±

        Args:
            download_compiled: åœ¨ç·¨è­¯ job å®Œæˆå¾Œè‡ªå‹•ä¸‹è¼‰ target model (edge éƒ¨ç½²ç”¨)
            wait_compile: æ–¼åˆå§‹åŒ–éšæ®µç­‰å¾… compile jobs å®Œæˆ (é¿å…å¾ŒçºŒä¸‹è¼‰å¤±æ•—)
            realtime: å•Ÿå‹•å¾Œç«‹å³é€²å…¥å³æ™‚æ¨è«–å¾ªç’°
            camera_index: æ”å½±æ©Ÿç´¢å¼• (å³æ™‚æ¨¡å¼ä½¿ç”¨)
            max_frames: æœ€å¤šè™•ç†å½±æ ¼æ•¸ (None è¡¨ç¤ºä¸é™ï¼›æ¸¬è©¦/é™¤éŒ¯å¯è¨­å®š)
        """
        self.api_token = os.getenv('QAI_HUB_API_TOKEN')
        self.target_device = None
        self.qai_hub_models = {}
        self.compiled_models = {}
        self.onnx_sessions = {}
        self.download_dir = Path('edge_models')
        self.download_dir.mkdir(exist_ok=True)
        self.download_compiled = download_compiled
        self.wait_compile = wait_compile
        self.realtime = realtime
        self.camera_index = camera_index
        self.max_frames = max_frames
        
        logger.info("ğŸ‰ åˆå§‹åŒ–Dragon Xè€äººè·Œå€’é é˜²æª¢æ¸¬ç³»çµ±...")
        self._find_dragon_x_devices()
        self._initialize_fall_detection_models()
        if self.wait_compile:
            self._wait_for_all_compile_jobs()
        if self.download_compiled:
            self._download_compiled_target_models()
            self._create_onnx_sessions_from_downloads()
        if self.realtime and self.onnx_sessions:
            logger.info("ğŸš€ é€²å…¥å³æ™‚æ¨è«–æ¨¡å¼ (ä½¿ç”¨å·²ä¸‹è¼‰ compiled ONNX)")
            self.run_realtime_inference()
    
    def _find_dragon_x_devices(self):
        """å°‹æ‰¾ä¸¦é¸æ“‡Dragon Xè¨­å‚™"""
        if not self.api_token:
            raise ValueError("âŒ è«‹åœ¨.envæ–‡ä»¶ä¸­è¨­ç½®QAI_HUB_API_TOKEN")
        
        try:
            devices = hub.get_devices()
            logger.info(f"ğŸ” æœå°‹QAI Hubè¨­å‚™...")
            logger.info(f"   ç¸½è¨­å‚™æ•¸é‡: {len(devices)}")
            
            # åˆ†é¡è¨­å‚™
            dragon_x_devices = []
            snapdragon_devices = []
            other_devices = []
            
            for device in devices:
                device_name = device.name.lower()
                if 'x elite' in device_name or 'snapdragon x' in device_name or 'dragon x' in device_name:
                    dragon_x_devices.append(device)
                elif 'snapdragon' in device_name:
                    snapdragon_devices.append(device)
                else:
                    other_devices.append(device)
            
            # é¡¯ç¤ºè¨­å‚™åˆ†é¡
            logger.info(f"ğŸ“Š è¨­å‚™åˆ†é¡çµæœ:")
            logger.info(f"   ğŸ‰ Dragon X / Snapdragon X Elite: {len(dragon_x_devices)}")
            logger.info(f"   ğŸ”¥ å…¶ä»–Snapdragonè¨­å‚™: {len(snapdragon_devices)}")
            logger.info(f"   ğŸ“± å…¶ä»–è¨­å‚™: {len(other_devices)}")
            
            # é¸æ“‡æœ€ä½³è¨­å‚™
            if dragon_x_devices:
                self.target_device = dragon_x_devices[0]
                logger.info(f"ğŸ‰ æˆåŠŸé¸å®šDragon Xè¨­å‚™!")
                logger.info(f"   ğŸ‰ è¨­å‚™åç¨±: {self.target_device.name}")
                logger.info(f"   âœ¨ é»‘å®¢æ¾ä¸»æ‰“å¹³å°å·²å°±ç·’!")
                
                # é¡¯ç¤ºæ‰€æœ‰Dragon Xè¨­å‚™é¸é …
                if len(dragon_x_devices) > 1:
                    logger.info(f"   ğŸ“‹ å…¶ä»–å¯ç”¨Dragon Xè¨­å‚™:")
                    for i, device in enumerate(dragon_x_devices[1:], 1):
                        logger.info(f"      {i}. {device.name}")
                        
            elif snapdragon_devices:
                self.target_device = snapdragon_devices[0]
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°Dragon Xï¼Œä½¿ç”¨Snapdragonè¨­å‚™:")
                logger.info(f"   ğŸ”¥ è¨­å‚™åç¨±: {self.target_device.name}")
                
            else:
                self.target_device = devices[0] if devices else None
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°Snapdragonè¨­å‚™ï¼Œä½¿ç”¨é è¨­è¨­å‚™:")
                logger.info(f"   ğŸ“± è¨­å‚™åç¨±: {self.target_device.name if self.target_device else 'None'}")
            
            return self.target_device
            
        except Exception as e:
            logger.error(f"âŒ è¨­å‚™æœå°‹å¤±æ•—: {e}")
            raise
    
    def _initialize_fall_detection_models(self):
        """åˆå§‹åŒ–è·Œå€’æª¢æ¸¬æ‰€éœ€çš„æ¨¡å‹"""
        logger.info("ğŸ§  è¼‰å…¥è€äººè·Œå€’é é˜²æª¢æ¸¬æ¨¡å‹...")
        
        try:
            # å§¿æ…‹æª¢æ¸¬æ˜¯è·Œå€’æª¢æ¸¬çš„æ ¸å¿ƒ
            self._load_pose_detection_for_fall_prevention()
            
            # äººè‡‰æª¢æ¸¬ç”¨æ–¼ç¢ºèªè€äººèº«ä»½
            self._load_face_detection_for_elderly_identification()
            
            # æ‰‹éƒ¨æª¢æ¸¬ç”¨æ–¼æª¢æ¸¬æ±‚æ•‘æ‰‹å‹¢
            self._load_hand_detection_for_emergency_gestures()
            
            logger.info("âœ… è€äººè·Œå€’é é˜²æª¢æ¸¬æ¨¡å‹è¼‰å…¥å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            raise
    
    def _load_pose_detection_for_fall_prevention(self):
        """è¼‰å…¥å§¿æ…‹æª¢æ¸¬æ¨¡å‹ï¼ˆè·Œå€’é é˜²æ ¸å¿ƒï¼‰"""
        try:
            from qai_hub_models.models.mediapipe_pose import Model as PoseModel
            
            logger.info("ğŸš¶â€â™‚ï¸ è¼‰å…¥å§¿æ…‹æª¢æ¸¬æ¨¡å‹ (è·Œå€’é é˜²æ ¸å¿ƒ)...")
            pose_model = PoseModel.from_pretrained()
            pose_detector = pose_model.pose_detector
            self.qai_hub_models['pose_fall_detection'] = pose_detector
            
            # æäº¤åˆ°Dragon Xè¨­å‚™ç·¨è­¯
            if self.target_device:
                logger.info("ğŸ‰ æäº¤å§¿æ…‹æª¢æ¸¬æ¨¡å‹åˆ°Dragon Xç·¨è­¯...")
                
                try:
                    torchscript_model = pose_detector.convert_to_torchscript()
                    uploaded_model = hub.upload_model(torchscript_model)
                    
                    compile_job = hub.submit_compile_job(
                        model=uploaded_model,
                        input_specs={"image": ((1, 3, 256, 256), "float32")},
                        device=self.target_device,
                    )
                    
                    logger.info(f"âœ… å§¿æ…‹æª¢æ¸¬Dragon Xç·¨è­¯Job: {compile_job.job_id}")
                    logger.info(f"ğŸ”— Dashboard: https://app.aihub.qualcomm.com/jobs/{compile_job.job_id}")
                    
                    self.compiled_models['pose_fall_detection_job'] = compile_job
                    
                except Exception as e:
                    logger.error(f"âŒ å§¿æ…‹æª¢æ¸¬Dragon Xç·¨è­¯å¤±æ•—: {e}")
            
            logger.info("âœ… å§¿æ…‹æª¢æ¸¬æ¨¡å‹ (è·Œå€’é é˜²) è¼‰å…¥å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ å§¿æ…‹æª¢æ¸¬æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
    
    def _load_face_detection_for_elderly_identification(self):
        """è¼‰å…¥äººè‡‰æª¢æ¸¬æ¨¡å‹ï¼ˆè€äººèº«ä»½ç¢ºèªï¼‰"""
        try:
            from qai_hub_models.models.mediapipe_face import Model as FaceModel
            
            logger.info("ğŸ‘¤ è¼‰å…¥äººè‡‰æª¢æ¸¬æ¨¡å‹ (è€äººèº«ä»½ç¢ºèª)...")
            face_model = FaceModel.from_pretrained()
            face_detector = face_model.face_detector
            self.qai_hub_models['face_elderly_id'] = face_detector
            
            # æäº¤åˆ°Dragon Xè¨­å‚™ç·¨è­¯
            if self.target_device:
                logger.info("ğŸ‰ æäº¤äººè‡‰æª¢æ¸¬æ¨¡å‹åˆ°Dragon Xç·¨è­¯...")
                
                try:
                    torchscript_model = face_detector.convert_to_torchscript()
                    uploaded_model = hub.upload_model(torchscript_model)
                    
                    compile_job = hub.submit_compile_job(
                        model=uploaded_model,
                        input_specs={"image": ((1, 3, 256, 256), "float32")},
                        device=self.target_device,
                    )
                    
                    logger.info(f"âœ… äººè‡‰æª¢æ¸¬Dragon Xç·¨è­¯Job: {compile_job.job_id}")
                    logger.info(f"ğŸ”— Dashboard: https://app.aihub.qualcomm.com/jobs/{compile_job.job_id}")
                    
                    self.compiled_models['face_elderly_id_job'] = compile_job
                    
                except Exception as e:
                    logger.error(f"âŒ äººè‡‰æª¢æ¸¬Dragon Xç·¨è­¯å¤±æ•—: {e}")
            
            logger.info("âœ… äººè‡‰æª¢æ¸¬æ¨¡å‹ (è€äººèº«ä»½ç¢ºèª) è¼‰å…¥å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ äººè‡‰æª¢æ¸¬æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
    
    def _load_hand_detection_for_emergency_gestures(self):
        """è¼‰å…¥æ‰‹éƒ¨æª¢æ¸¬æ¨¡å‹ï¼ˆç·Šæ€¥æ±‚æ•‘æ‰‹å‹¢ï¼‰"""
        try:
            from qai_hub_models.models.mediapipe_hand import Model as HandModel
            
            logger.info("âœ‹ è¼‰å…¥æ‰‹éƒ¨æª¢æ¸¬æ¨¡å‹ (ç·Šæ€¥æ±‚æ•‘æ‰‹å‹¢)...")
            hand_model = HandModel.from_pretrained()
            hand_detector = hand_model.hand_detector
            self.qai_hub_models['hand_emergency_gesture'] = hand_detector
            
            # æäº¤åˆ°Dragon Xè¨­å‚™ç·¨è­¯
            if self.target_device:
                logger.info("ğŸ‰ æäº¤æ‰‹éƒ¨æª¢æ¸¬æ¨¡å‹åˆ°Dragon Xç·¨è­¯...")
                
                try:
                    torchscript_model = hand_detector.convert_to_torchscript()
                    uploaded_model = hub.upload_model(torchscript_model)
                    
                    compile_job = hub.submit_compile_job(
                        model=uploaded_model,
                        input_specs={"image": ((1, 3, 224, 224), "float32")},
                        device=self.target_device,
                    )
                    
                    logger.info(f"âœ… æ‰‹éƒ¨æª¢æ¸¬Dragon Xç·¨è­¯Job: {compile_job.job_id}")
                    logger.info(f"ğŸ”— Dashboard: https://app.aihub.qualcomm.com/jobs/{compile_job.job_id}")
                    
                    self.compiled_models['hand_emergency_gesture_job'] = compile_job
                    
                except Exception as e:
                    logger.error(f"âŒ æ‰‹éƒ¨æª¢æ¸¬Dragon Xç·¨è­¯å¤±æ•—: {e}")
            
            logger.info("âœ… æ‰‹éƒ¨æª¢æ¸¬æ¨¡å‹ (ç·Šæ€¥æ±‚æ•‘æ‰‹å‹¢) è¼‰å…¥å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ‰‹éƒ¨æª¢æ¸¬æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
    
    def analyze_fall_risk(self, pose_keypoints: List[Dict]) -> Dict[str, Any]:
        """åˆ†æè·Œå€’é¢¨éšª"""
        if not pose_keypoints:
            return {"fall_risk": "unknown", "confidence": 0.0, "reasons": []}
        
        fall_risk_indicators = []
        risk_score = 0.0
        
        try:
            # æå–é—œéµé—œç¯€é»
            keypoints = pose_keypoints[0] if pose_keypoints else {}
            
            # æª¢æ¸¬èº«é«”å‚¾æ–œåº¦
            if len(keypoints.get('keypoints', [])) >= 17:
                kpts = keypoints['keypoints']
                
                # è‚©è†€æ°´å¹³åº¦æª¢æŸ¥
                left_shoulder = kpts[5] if len(kpts) > 5 else None
                right_shoulder = kpts[6] if len(kpts) > 6 else None
                
                if left_shoulder and right_shoulder:
                    shoulder_angle = abs(left_shoulder['y'] - right_shoulder['y'])
                    if shoulder_angle > 0.3:  # é–¾å€¼å¯èª¿æ•´
                        fall_risk_indicators.append("èº«é«”æ˜é¡¯å‚¾æ–œ")
                        risk_score += 0.4
                
                # é‡å¿ƒç©©å®šæ€§æª¢æŸ¥
                left_hip = kpts[11] if len(kpts) > 11 else None
                right_hip = kpts[12] if len(kpts) > 12 else None
                left_ankle = kpts[15] if len(kpts) > 15 else None
                right_ankle = kpts[16] if len(kpts) > 16 else None
                
                if all([left_hip, right_hip, left_ankle, right_ankle]):
                    # æª¢æŸ¥è…³è¸ä½ç½®ç›¸å°æ–¼é«–éƒ¨
                    hip_center_x = (left_hip['x'] + right_hip['x']) / 2
                    ankle_center_x = (left_ankle['x'] + right_ankle['x']) / 2
                    
                    balance_offset = abs(hip_center_x - ankle_center_x)
                    if balance_offset > 0.4:  # é‡å¿ƒåç§»éå¤§
                        fall_risk_indicators.append("é‡å¿ƒä¸ç©©å®š")
                        risk_score += 0.3
                
                # è†è“‹å½æ›²åº¦æª¢æŸ¥
                left_knee = kpts[13] if len(kpts) > 13 else None
                right_knee = kpts[14] if len(kpts) > 14 else None
                
                if left_knee and right_knee and left_hip and right_hip:
                    # æª¢æŸ¥è†è“‹æ˜¯å¦éåº¦å½æ›²ï¼ˆå¯èƒ½è¡¨ç¤ºè·Œå€’ï¼‰
                    left_knee_angle = abs(left_knee['y'] - left_hip['y'])
                    right_knee_angle = abs(right_knee['y'] - right_hip['y'])
                    
                    if left_knee_angle < 0.1 or right_knee_angle < 0.1:
                        fall_risk_indicators.append("è†è“‹ç•°å¸¸å½æ›²")
                        risk_score += 0.3
        
        except Exception as e:
            logger.error(f"âŒ è·Œå€’é¢¨éšªåˆ†æå¤±æ•—: {e}")
            return {"fall_risk": "analysis_error", "confidence": 0.0, "error": str(e)}
        
        # åˆ¤å®šé¢¨éšªç­‰ç´š
        if risk_score >= 0.7:
            risk_level = "high"
            risk_message = "âš ï¸ é«˜è·Œå€’é¢¨éšª"
        elif risk_score >= 0.4:
            risk_level = "medium"
            risk_message = "ğŸ”¶ ä¸­ç­‰è·Œå€’é¢¨éšª"
        elif risk_score >= 0.1:
            risk_level = "low"
            risk_message = "ğŸ”· ä½è·Œå€’é¢¨éšª"
        else:
            risk_level = "normal"
            risk_message = "âœ… æ­£å¸¸ç‹€æ…‹"
        
        return {
            "fall_risk": risk_level,
            "risk_score": risk_score,
            "confidence": min(risk_score * 1.5, 1.0),
            "message": risk_message,
            "indicators": fall_risk_indicators,
            "recommendation": self._get_safety_recommendation(risk_level)
        }
    
    def _get_safety_recommendation(self, risk_level: str) -> str:
        """æ ¹æ“šé¢¨éšªç­‰ç´šæä¾›å®‰å…¨å»ºè­°"""
        recommendations = {
            "high": "ç«‹å³æª¢æŸ¥ç’°å¢ƒå®‰å…¨ï¼Œå»ºè­°å°‹æ±‚å”åŠ©æˆ–åä¸‹ä¼‘æ¯",
            "medium": "æ³¨æ„å‘¨åœç’°å¢ƒï¼Œæ”¾æ…¢å‹•ä½œï¼Œç¢ºä¿æœ‰æ”¯æ’ç‰©åœ¨é™„è¿‘",
            "low": "ä¿æŒè¬¹æ…ï¼Œæ³¨æ„è…³ä¸‹ç‹€æ³",
            "normal": "ç¹¼çºŒä¿æŒè‰¯å¥½å§¿æ…‹"
        }
        return recommendations.get(risk_level, "ä¿æŒå®‰å…¨æ„è­˜")
    
    def comprehensive_fall_prevention_detection(self, image: np.ndarray) -> Dict[str, Any]:
        """ç¶œåˆè·Œå€’é é˜²æª¢æ¸¬"""
        results = {
            "timestamp": time.time(),
            "dragon_x_device": self.target_device.name if self.target_device else None,
            "fall_prevention_analysis": {},
            "detections": {},
            "qai_hub_jobs": {}
        }
        
        # å§¿æ…‹æª¢æ¸¬ï¼ˆæ ¸å¿ƒï¼‰
        if 'pose_fall_detection' in self.qai_hub_models:
            logger.info("ğŸš¶â€â™‚ï¸ åŸ·è¡Œå§¿æ…‹æª¢æ¸¬ (è·Œå€’é é˜²æ ¸å¿ƒ)...")
            if 'pose_fall_detection' in self.onnx_sessions:
                pose_detection = self._run_pose_inference_edge(image)
                if pose_detection.get('keypoints'):
                    fall_analysis = self.analyze_fall_risk(pose_detection["keypoints"])
                    results["fall_prevention_analysis"] = fall_analysis
                results["detections"]["pose"] = pose_detection
            else:
                # æ¨¡æ“¬
                mock_pose_results = {
                    "keypoints": [{
                        "keypoints": [
                            {"x": 0.5, "y": 0.3, "confidence": 0.8},
                            {"x": 0.45, "y": 0.5, "confidence": 0.9},
                            {"x": 0.55, "y": 0.5, "confidence": 0.9},
                        ]
                    }]
                }
                fall_analysis = self.analyze_fall_risk(mock_pose_results["keypoints"])
                results["fall_prevention_analysis"] = fall_analysis
                results["detections"]["pose"] = mock_pose_results
        
        # è¨˜éŒ„Dragon Xç·¨è­¯Jobè³‡è¨Š
        for job_name, job in self.compiled_models.items():
            model_type = job_name.replace('_job', '')
            results["qai_hub_jobs"][model_type] = {
                "job_id": job.job_id,
                "dashboard_url": f"https://app.aihub.qualcomm.com/jobs/{job.job_id}",
                "target_device": self.target_device.name
            }
        
        return results

    # === Edge Runtime ç›¸é—œè¼”åŠ© ===
    def _wait_for_all_compile_jobs(self, timeout: int = 1800, poll: int = 10):
        start = time.time()
        pending = True
        while pending:
            pending = False
            for name, job in self.compiled_models.items():
                try:
                    job.wait(timeout=1)
                except Exception:
                    pending = True
            elapsed = time.time() - start
            if elapsed > timeout:
                logger.warning("âš ï¸ è¶…æ™‚ï¼Œä»æœ‰ç·¨è­¯Jobæœªå®Œæˆï¼Œç¹¼çºŒå¾ŒçºŒæµç¨‹")
                break
            if pending:
                logger.info(f"â³ ç­‰å¾…ç·¨è­¯Jobså®Œæˆ... å·²ç­‰å¾… {int(elapsed)}s")
                time.sleep(poll)

    def _download_compiled_target_models(self):
        """å˜—è©¦å°æ¯å€‹ compile job å–å¾— target_model ä¸¦ä¸‹è¼‰ç‚º ONNX / DLCã€‚
        å„ªå…ˆä¸‹è¼‰ç‚º .onnx (è‹¥ SDK æä¾›)ã€‚"""
        for job_key, compile_job in self.compiled_models.items():
            label = job_key.replace('_job', '')
            target_path = self.download_dir / f"compiled_{label}.onnx"
            if target_path.exists():
                continue
            try:
                logger.info(f"ğŸ’¾ å–å¾— target_model ä¸¦ä¸‹è¼‰: {label}")
                target_model = compile_job.get_target_model()
                if hasattr(target_model, 'download'):
                    target_model.download(str(target_path))
                    logger.info(f"âœ… å·²ä¸‹è¼‰ {target_path}")
                else:
                    logger.warning(f"âš ï¸ target_model ç„¡ download æ–¹æ³•: {label}")
            except Exception as e:
                logger.warning(f"âš ï¸ ä¸‹è¼‰ {label} å¤±æ•—: {e}")

    def _create_onnx_sessions_from_downloads(self):
        """ç‚ºå·²ä¸‹è¼‰æ¨¡å‹å»ºç«‹ ONNX Runtime sessionã€‚"""
        providers = self._select_providers()
        for onnx_file in self.download_dir.glob('compiled_*.onnx'):
            label = onnx_file.stem.replace('compiled_', '')
            if label in self.onnx_sessions:
                continue
            try:
                session = ort.InferenceSession(str(onnx_file), providers=providers)
                input_meta = session.get_inputs()[0]
                self.onnx_sessions[label] = {
                    'session': session,
                    'input_name': input_meta.name,
                    'shape': input_meta.shape,
                    'path': str(onnx_file)
                }
                logger.info(f"âœ… ONNX Session å»ºç«‹æˆåŠŸ: {label} providers={providers}")
            except Exception as e:
                logger.warning(f"âš ï¸ å»ºç«‹ {label} ONNX Session å¤±æ•—: {e}")

    def _select_providers(self) -> List[str]:
        available = ort.get_available_providers()
        priority = [
            'QNNExecutionProvider',  # è‹¥è£ç½®å®‰è£ QNN EP
            'CUDAExecutionProvider',
            'DmlExecutionProvider',
            'CoreMLExecutionProvider',
            'CPUExecutionProvider'
        ]
        chosen = [p for p in priority if p in available]
        if not chosen:
            chosen = ['CPUExecutionProvider']
        return chosen

    def _preprocess_for_session(self, image: np.ndarray, shape: List[int]) -> np.ndarray:
        # shape å¯èƒ½ç‚º [1,3,H,W] æˆ– [1,H,W,3] æˆ– å‹•æ…‹ç¶­åº¦
        if len(shape) == 4:
            if shape[1] == 3:  # NCHW
                H = int(shape[2]) if isinstance(shape[2], (int, float)) else 256
                W = int(shape[3]) if isinstance(shape[3], (int, float)) else 256
                resized = cv2.resize(image, (W, H))
                rgb = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
                norm = rgb.astype(np.float32) / 255.0
                tensor = np.transpose(norm, (2, 0, 1))[None, ...]
                return tensor
            elif shape[-1] == 3:  # NHWC
                H = int(shape[1]) if isinstance(shape[1], (int, float)) else 256
                W = int(shape[2]) if isinstance(shape[2], (int, float)) else 256
                resized = cv2.resize(image, (W, H))
                rgb = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
                norm = rgb.astype(np.float32) / 255.0
                tensor = norm[None, ...]
                return tensor
        # fallback
        resized = cv2.resize(image, (256, 256))
        rgb = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
        norm = rgb.astype(np.float32) / 255.0
        tensor = np.transpose(norm, (2, 0, 1))[None, ...]
        return tensor

    def _run_pose_inference_edge(self, image: np.ndarray) -> Dict[str, Any]:
        if 'pose_fall_detection' not in self.onnx_sessions:
            return {"error": "no_pose_session"}
        sess_info = self.onnx_sessions['pose_fall_detection']
        session = sess_info['session']
        input_name = sess_info['input_name']
        shape = sess_info['shape']
        inp = self._preprocess_for_session(image, shape)
        t0 = time.time()
        try:
            outputs = session.run(None, {input_name: inp})
            latency = (time.time() - t0) * 1000
            # ç°¡åŒ–: å˜—è©¦å°‡ç¬¬ä¸€å€‹è¼¸å‡ºè¦–ç‚ºé—œéµé» (è‹¥å½¢ç‹€ç›¸å®¹)ï¼Œå¦å‰‡å›å‚³ raw shape
            keypoints = []
            first = outputs[0]
            if isinstance(first, np.ndarray) and first.ndim in (2, 3, 4):
                flat = first.reshape(-1, first.shape[-1]) if first.shape[-1] in (2, 3, 4) else None
                if flat is not None and flat.shape[1] >= 2:
                    # å–å‰ 17 å€‹ (æ¨™æº– COCO) è‹¥è¶³å¤ 
                    for row in flat[:17]:
                        x = float(row[0]) if np.isfinite(row[0]) else 0.0
                        y = float(row[1]) if np.isfinite(row[1]) else 0.0
                        conf = float(row[2]) if flat.shape[1] > 2 and np.isfinite(row[2]) else 0.5
                        keypoints.append({"x": x, "y": y, "confidence": conf})
            return {
                "inference_ms": round(latency, 2),
                "output_shapes": [o.shape if isinstance(o, np.ndarray) else str(type(o)) for o in outputs],
                "keypoints": [{"keypoints": keypoints}] if keypoints else [],
                "providers": session.get_providers(),
            }
        except Exception as e:
            return {"error": str(e)}

    def run_realtime_inference(self):
        cap = cv2.VideoCapture(self.camera_index)
        if not cap.isOpened():
            logger.error("âŒ ç„¡æ³•é–‹å•Ÿæ”å½±æ©Ÿï¼ŒçµæŸå³æ™‚æ¨è«–")
            return
        frame_id = 0
        t_last_fps = time.time()
        fps = 0.0
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    logger.warning("âš ï¸ è®€å–å½±æ ¼å¤±æ•—ï¼Œåœæ­¢")
                    break
                result = self.comprehensive_fall_prevention_detection(frame)
                frame_id += 1
                # FPS è¨ˆç®—
                if frame_id % 10 == 0:
                    now = time.time()
                    fps = 10.0 / (now - t_last_fps)
                    t_last_fps = now
                # è¦–è¦ºåŒ– (åƒ…é¡¯ç¤º FPS & é¢¨éšª)
                overlay = frame.copy()
                fall_info = result.get('fall_prevention_analysis', {})
                status = fall_info.get('message', 'N/A')
                cv2.putText(overlay, f"FPS:{fps:.1f}", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,255,255),2)
                cv2.putText(overlay, status, (10,60), cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,255,0),2)
                cv2.imshow('DragonX Edge Realtime', overlay)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    logger.info("ğŸ‘‹ ä½¿ç”¨è€…çµæŸå³æ™‚æ¨è«–")
                    break
                if self.max_frames and frame_id >= self.max_frames:
                    logger.info("ğŸ›‘ å·²é”æœ€å¤§å½±æ ¼æ•¸ï¼ŒçµæŸå³æ™‚æ¨è«–")
                    break
        finally:
            cap.release()
            cv2.destroyAllWindows()
    
    def get_dragon_x_status_report(self) -> Dict[str, Any]:
        """ç²å–Dragon Xç³»çµ±ç‹€æ…‹å ±å‘Š"""
        report = {
            "system_name": "Dragon Xè€äººè·Œå€’é é˜²æª¢æ¸¬ç³»çµ±",
            "timestamp": time.time(),
            "dragon_x_device": {
                "name": self.target_device.name if self.target_device else None,
                "status": "ready" if self.target_device else "not_found"
            },
            "models_status": {},
            "qai_hub_jobs": {},
            "hackathon_readiness": True
        }
        
        # æª¢æŸ¥æ¨¡å‹ç‹€æ…‹
        for model_name in self.qai_hub_models:
            report["models_status"][model_name] = "loaded"
        
        # æª¢æŸ¥ç·¨è­¯Jobç‹€æ…‹
        for job_name, job in self.compiled_models.items():
            try:
                # å˜—è©¦å¿«é€Ÿæª¢æŸ¥ç‹€æ…‹
                job.wait(timeout=1)
                status = "completed"
            except:
                status = "compiling"
            
            report["qai_hub_jobs"][job_name] = {
                "job_id": job.job_id,
                "status": status,
                "dashboard_url": f"https://app.aihub.qualcomm.com/jobs/{job.job_id}"
            }
        
        return report

def main():
    import argparse
    parser = argparse.ArgumentParser(description='Dragon X Edge æ¨è«–ç³»çµ±')
    parser.add_argument('--download-compiled', action='store_true', help='ç­‰å¾…ä¸¦ä¸‹è¼‰ compiled target models ä¾› edge æ¨è«–')
    parser.add_argument('--wait-compile', action='store_true', help='åˆå§‹åŒ–æœŸé–“ç­‰å¾… compile jobs å®Œæˆ')
    parser.add_argument('--realtime', action='store_true', help='å•Ÿå‹•å³æ™‚æ”å½±æ©Ÿæ¨è«– (éœ€å·²å»ºç«‹ ONNX sessions)')
    parser.add_argument('--camera-index', type=int, default=0, help='æ”å½±æ©Ÿç´¢å¼• (é è¨­0)')
    parser.add_argument('--max-frames', type=int, default=None, help='æ¸¬è©¦æ¨¡å¼æœ€å¤§å½±æ ¼æ•¸')
    args = parser.parse_args()

    print("ğŸ‰ Dragon Xè€äººè·Œå€’é é˜²æª¢æ¸¬ç³»çµ± (Edge ç‰ˆæœ¬)")
    print("=" * 60)
    print("ğŸ¯ Snapdragon X Elite Edge Deployment")
    print()

    try:
        dragon_system = DragonXFallDetectionSystem(download_compiled=args.download_compiled,
                                                   wait_compile=args.wait_compile,
                                                   realtime=args.realtime,
                                                   camera_index=args.camera_index,
                                                   max_frames=args.max_frames)

        status_report = dragon_system.get_dragon_x_status_report()
        print("ğŸ“Š ç³»çµ±ç‹€æ…‹:")
        print(f"   ğŸ‰ ç›®æ¨™è¨­å‚™: {status_report['dragon_x_device']['name']}")
        print(f"   ğŸ“± è¨­å‚™ç‹€æ…‹: {status_report['dragon_x_device']['status']}")
        print(f"   ğŸ§  å·²è¼‰å…¥æ¨¡å‹: {len(status_report['models_status'])}")
        print(f"   âš¡ Compile Jobs: {len(status_report['qai_hub_jobs'])}")
        print(f"   ï¿½ Edge ONNX Sessions: {len(dragon_system.onnx_sessions)}")
        print()

        # è‹¥æœªé€²å…¥å³æ™‚æ¨¡å¼ä¸”å·²å…·å‚™ ONNX sessionï¼Œåšä¸€æ¬¡éœæ…‹æ¸¬è©¦
        if not args.realtime:
            test_image = np.random.randint(0,255,(480,640,3),dtype=np.uint8)
            results = dragon_system.comprehensive_fall_prevention_detection(test_image)
            fall_analysis = results.get('fall_prevention_analysis', {})
            print("âœ… å–®å¼µå½±åƒåˆ†æ:")
            print(f"   ç‹€æ…‹: {fall_analysis.get('message','N/A')}")
            print(f"   é¢¨éšª: {fall_analysis.get('risk_score',0):.2f}")
            if fall_analysis.get('indicators'):
                print(f"   æŒ‡æ¨™: {', '.join(fall_analysis['indicators'])}")
            with open('dragon_x_edge_single_infer.json','w') as f:
                json.dump({"status_report": status_report, "result": results}, f, indent=2, default=str)
            print("ğŸ“ å·²è¼¸å‡º dragon_x_edge_single_infer.json")

        if args.realtime and not dragon_system.onnx_sessions:
            print("âš ï¸ æœªå»ºç«‹ ONNX Sessionsï¼Œè«‹åŠ ä¸Š --download-compiled æˆ–å…ˆè¡Œä¸‹è¼‰æ¨¡å‹")

    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–æˆ–æ¨è«–å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
