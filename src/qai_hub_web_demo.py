#!/usr/bin/env python3
"""
ğŸ¯ QAI Hub ä¸€èˆ¬Web Demo
HTML/JavaScriptå¯¦æ™‚è€äººè¡Œç‚ºæª¢æ¸¬ç³»çµ±
"""

import cv2
import numpy as np
import os
import time
import json
import base64
from datetime import datetime
import threading
from http.server import HTTPServer, BaseHTTPRequestHandler
import urllib.parse
import logging

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class QAIHubWebDemo:
    def __init__(self):
        """åˆå§‹åŒ–Web Demoç³»çµ±"""
        self.detector = None
        self.predictor = None
        self.camera = None
        self.is_streaming = False
        self.load_systems()
    
    def load_systems(self):
        """è¼‰å…¥æª¢æ¸¬ç³»çµ±"""
        try:
            from official_qai_hub_detector import OfficialQAIHubDetector
            from elderly_behavior_predictor import ElderlyBehaviorPredictor
            
            self.detector = OfficialQAIHubDetector()
            self.predictor = ElderlyBehaviorPredictor()
            
            logger.info("âœ… QAI Hubæª¢æ¸¬ç³»çµ±è¼‰å…¥æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æª¢æ¸¬ç³»çµ±è¼‰å…¥å¤±æ•—: {e}")
            return False
    
    def process_image(self, image_data):
        """è™•ç†åœ–åƒæ•¸æ“š"""
        try:
            # è§£ç¢¼base64åœ–åƒ
            if 'data:image' in image_data:
                image_data = image_data.split(',')[1]
            
            img_bytes = base64.b64decode(image_data)
            nparr = np.frombuffer(img_bytes, np.uint8)
            image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if image is None:
                return {'error': 'ç„¡æ³•è§£ç¢¼åœ–åƒ'}
            
            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # åŸ·è¡Œæª¢æ¸¬
            unified_result = self.detector.unified_detection(rgb_image)
            
            # è¡Œç‚ºåˆ†æ
            user_id = f"web_user_{int(time.time())}"
            interaction_result = self.predictor.process_user_interaction(user_id, image)
            
            # ç”Ÿæˆæ¨™è¨»åœ–åƒ
            annotated_images = {}
            
            # äººè‡‰æª¢æ¸¬çµæœ
            face_result = self.detector.detect_faces(rgb_image, raw_output=False)
            if face_result.get('success') and 'annotated_image' in face_result:
                annotated_images['face'] = self.image_to_base64(face_result['annotated_image'])
            
            # å§¿æ…‹æª¢æ¸¬çµæœ
            pose_result = self.detector.detect_pose(rgb_image, raw_output=False)
            if pose_result.get('success') and 'annotated_image' in pose_result:
                annotated_images['pose'] = self.image_to_base64(pose_result['annotated_image'])
            
            # æ‰‹éƒ¨æª¢æ¸¬çµæœ
            hand_result = self.detector.detect_hands(rgb_image, raw_output=False)
            if hand_result.get('success') and 'annotated_image' in hand_result:
                annotated_images['hand'] = self.image_to_base64(hand_result['annotated_image'])
            
            return {
                'success': True,
                'unified_result': unified_result,
                'interaction_result': interaction_result,
                'annotated_images': annotated_images,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"è™•ç†åœ–åƒéŒ¯èª¤: {e}")
            return {'error': str(e)}
    
    def image_to_base64(self, image):
        """å°‡åœ–åƒè½‰æ›ç‚ºbase64æ ¼å¼"""
        try:
            if isinstance(image, np.ndarray):
                if len(image.shape) == 3 and image.shape[2] == 3:
                    # RGB to BGR for OpenCV
                    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
                
                _, buffer = cv2.imencode('.jpg', image)
                img_str = base64.b64encode(buffer).decode('utf-8')
                return f"data:image/jpeg;base64,{img_str}"
            return None
        except Exception as e:
            logger.error(f"åœ–åƒç·¨ç¢¼éŒ¯èª¤: {e}")
            return None
    
    def start_camera_stream(self):
        """å•Ÿå‹•æ”å½±æ©Ÿä¸²æµ"""
        try:
            self.camera = cv2.VideoCapture(0)
            if not self.camera.isOpened():
                return False
            
            self.is_streaming = True
            return True
        except Exception as e:
            logger.error(f"æ”å½±æ©Ÿå•Ÿå‹•å¤±æ•—: {e}")
            return False
    
    def stop_camera_stream(self):
        """åœæ­¢æ”å½±æ©Ÿä¸²æµ"""
        self.is_streaming = False
        if self.camera:
            self.camera.release()
    
    def get_camera_frame(self):
        """ç²å–æ”å½±æ©Ÿå¹€"""
        if not self.camera or not self.is_streaming:
            return None
        
        ret, frame = self.camera.read()
        if not ret:
            return None
        
        # è™•ç†å¹€
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # åŸ·è¡Œæª¢æ¸¬
        unified_result = self.detector.unified_detection(rgb_frame)
        
        # è¡Œç‚ºåˆ†æ
        user_id = f"camera_user_{int(time.time())}"
        interaction_result = self.predictor.process_user_interaction(user_id, frame)
        
        return {
            'frame': self.image_to_base64(rgb_frame),
            'unified_result': unified_result,
            'interaction_result': interaction_result
        }

class DemoRequestHandler(BaseHTTPRequestHandler):
    """HTTPè«‹æ±‚è™•ç†å™¨"""
    
    def __init__(self, *args, demo_instance=None, **kwargs):
        self.demo = demo_instance
        super().__init__(*args, **kwargs)
    
    def do_GET(self):
        """è™•ç†GETè«‹æ±‚"""
        if self.path == '/' or self.path == '/index.html':
            self.serve_html()
        elif self.path == '/style.css':
            self.serve_css()
        elif self.path == '/script.js':
            self.serve_js()
        elif self.path == '/api/camera/start':
            self.handle_camera_start()
        elif self.path == '/api/camera/stop':
            self.handle_camera_stop()
        elif self.path == '/api/camera/frame':
            self.handle_camera_frame()
        else:
            self.send_error(404)
    
    def do_POST(self):
        """è™•ç†POSTè«‹æ±‚"""
        if self.path == '/api/process_image':
            self.handle_process_image()
        else:
            self.send_error(404)
    
    def serve_html(self):
        """æä¾›HTMLé é¢"""
        html_content = """
<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>QAI Hub è€äººè¡Œç‚ºæª¢æ¸¬ç³»çµ±</title>
    <link rel="stylesheet" href="/style.css">
</head>
<body>
    <div class="container">
        <header>
            <h1>ğŸ§  QAI Hub è€äººè¡Œç‚ºæª¢æ¸¬ç³»çµ±</h1>
            <p>åŸºæ–¼Qualcomm AI Hubçš„å¯¦æ™‚è€äººè¡Œç‚ºç›£æ¸¬èˆ‡é¢¨éšªè©•ä¼°</p>
        </header>
        
        <div class="demo-tabs">
            <button class="tab-button active" onclick="showTab('upload')">ğŸ“· åœ–åƒä¸Šå‚³</button>
            <button class="tab-button" onclick="showTab('camera')">ğŸ“¹ ç¶²è·¯æ”å½±æ©Ÿ</button>
            <button class="tab-button" onclick="showTab('samples')">ğŸ–¼ï¸ ç¤ºä¾‹åœ–åƒ</button>
        </div>
        
        <!-- åœ–åƒä¸Šå‚³æ¨™ç±¤ -->
        <div id="upload-tab" class="tab-content active">
            <h2>ğŸ“· åœ–åƒä¸Šå‚³æª¢æ¸¬</h2>
            <div class="upload-area">
                <input type="file" id="image-upload" accept="image/*" onchange="handleImageUpload(event)">
                <div class="upload-preview">
                    <img id="preview-image" style="display: none;">
                </div>
            </div>
        </div>
        
        <!-- æ”å½±æ©Ÿæ¨™ç±¤ -->
        <div id="camera-tab" class="tab-content">
            <h2>ğŸ“¹ ç¶²è·¯æ”å½±æ©Ÿå¯¦æ™‚æª¢æ¸¬</h2>
            <div class="camera-controls">
                <button id="start-camera" onclick="startCamera()">ğŸ¥ å•Ÿå‹•æ”å½±æ©Ÿ</button>
                <button id="stop-camera" onclick="stopCamera()" disabled>â¹ï¸ åœæ­¢æ”å½±æ©Ÿ</button>
            </div>
            <div class="camera-view">
                <video id="camera-video" style="display: none;" autoplay></video>
                <canvas id="camera-canvas" style="display: none;"></canvas>
            </div>
        </div>
        
        <!-- ç¤ºä¾‹åœ–åƒæ¨™ç±¤ -->
        <div id="samples-tab" class="tab-content">
            <h2>ğŸ–¼ï¸ ç¤ºä¾‹åœ–åƒæª¢æ¸¬</h2>
            <div class="samples-grid">
                <div class="sample-item" onclick="loadSample('andy.jpg')">
                    <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNkYPhfDwAChwGA60e6kgAAAABJRU5ErkJggg==" alt="Andy">
                    <p>Andy æ¸¬è©¦åœ–åƒ</p>
                </div>
            </div>
        </div>
        
        <!-- çµæœé¡¯ç¤ºå€åŸŸ -->
        <div id="results-section" class="results-section" style="display: none;">
            <h2>ğŸ” æª¢æ¸¬çµæœ</h2>
            
            <!-- çµ±è¨ˆæŒ‡æ¨™ -->
            <div class="metrics-grid">
                <div class="metric-card">
                    <h3>ğŸ‘¤ äººè‡‰æª¢æ¸¬</h3>
                    <span id="face-count">0</span>å€‹
                </div>
                <div class="metric-card">
                    <h3>ğŸš¶ å§¿æ…‹æª¢æ¸¬</h3>
                    <span id="pose-count">0</span>å€‹
                </div>
                <div class="metric-card">
                    <h3>âœ‹ æ‰‹éƒ¨æª¢æ¸¬</h3>
                    <span id="hand-count">0</span>å€‹
                </div>
            </div>
            
            <!-- è¡Œç‚ºåˆ†æ -->
            <div class="analysis-section">
                <h3>ğŸ§  è¡Œç‚ºåˆ†æ</h3>
                <div class="analysis-grid">
                    <div class="analysis-item">
                        <h4>âš–ï¸ å¹³è¡¡è©•åˆ†</h4>
                        <span id="balance-score">--</span>
                    </div>
                    <div class="analysis-item">
                        <h4>ğŸ¯ ç©©å®šæ€§è©•åˆ†</h4>
                        <span id="stability-score">--</span>
                    </div>
                    <div class="analysis-item">
                        <h4>ğŸ“ å§¿æ…‹åå·®</h4>
                        <span id="posture-deviation">--</span>
                    </div>
                </div>
            </div>
            
            <!-- é¢¨éšªè©•ä¼° -->
            <div class="risk-section">
                <h3>ğŸš¨ é¢¨éšªè©•ä¼°</h3>
                <div id="risk-alert" class="risk-alert">
                    <div id="risk-level">--</div>
                    <div id="risk-score">è©•åˆ†: --</div>
                </div>
            </div>
            
            <!-- è¦–è¦ºåŒ–çµæœ -->
            <div class="visualization-section">
                <h3>ğŸ–¼ï¸ æª¢æ¸¬çµæœè¦–è¦ºåŒ–</h3>
                <div class="images-grid">
                    <div class="image-result">
                        <h4>ğŸ‘¤ äººè‡‰æª¢æ¸¬</h4>
                        <img id="face-result" style="display: none;">
                    </div>
                    <div class="image-result">
                        <h4>ğŸš¶ å§¿æ…‹æª¢æ¸¬</h4>
                        <img id="pose-result" style="display: none;">
                    </div>
                    <div class="image-result">
                        <h4>âœ‹ æ‰‹éƒ¨æª¢æ¸¬</h4>
                        <img id="hand-result" style="display: none;">
                    </div>
                </div>
            </div>
        </div>
        
        <!-- è¼‰å…¥æŒ‡ç¤ºå™¨ -->
        <div id="loading" class="loading" style="display: none;">
            <div class="spinner"></div>
            <p>ğŸ” æ­£åœ¨åŸ·è¡ŒQAI Hubæª¢æ¸¬...</p>
        </div>
    </div>
    
    <script src="/script.js"></script>
</body>
</html>
        """
        
        self.send_response(200)
        self.send_header('Content-type', 'text/html; charset=utf-8')
        self.end_headers()
        self.wfile.write(html_content.encode('utf-8'))
    
    def serve_css(self):
        """æä¾›CSSæ¨£å¼"""
        css_content = """
* {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
}

body {
    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    min-height: 100vh;
    color: #333;
}

.container {
    max-width: 1200px;
    margin: 0 auto;
    padding: 20px;
}

header {
    text-align: center;
    margin-bottom: 30px;
    color: white;
}

header h1 {
    font-size: 3rem;
    margin-bottom: 10px;
    text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
}

header p {
    font-size: 1.2rem;
    opacity: 0.9;
}

.demo-tabs {
    display: flex;
    justify-content: center;
    margin-bottom: 30px;
    gap: 10px;
}

.tab-button {
    padding: 12px 24px;
    border: none;
    border-radius: 25px;
    background: rgba(255,255,255,0.2);
    color: white;
    font-size: 1rem;
    cursor: pointer;
    transition: all 0.3s ease;
}

.tab-button:hover {
    background: rgba(255,255,255,0.3);
    transform: translateY(-2px);
}

.tab-button.active {
    background: white;
    color: #667eea;
    font-weight: bold;
}

.tab-content {
    display: none;
    background: white;
    border-radius: 15px;
    padding: 30px;
    margin-bottom: 20px;
    box-shadow: 0 10px 30px rgba(0,0,0,0.1);
}

.tab-content.active {
    display: block;
}

.upload-area {
    border: 2px dashed #ddd;
    border-radius: 10px;
    padding: 40px;
    text-align: center;
    margin-bottom: 20px;
}

.upload-area:hover {
    border-color: #667eea;
    background: #f8f9ff;
}

#image-upload {
    margin-bottom: 20px;
}

.upload-preview img {
    max-width: 100%;
    max-height: 400px;
    border-radius: 10px;
    box-shadow: 0 5px 15px rgba(0,0,0,0.1);
}

.camera-controls {
    text-align: center;
    margin-bottom: 20px;
}

.camera-controls button {
    padding: 12px 24px;
    margin: 0 10px;
    border: none;
    border-radius: 25px;
    background: #667eea;
    color: white;
    font-size: 1rem;
    cursor: pointer;
    transition: all 0.3s ease;
}

.camera-controls button:hover {
    background: #5a6fd8;
    transform: translateY(-2px);
}

.camera-controls button:disabled {
    background: #ccc;
    cursor: not-allowed;
    transform: none;
}

.camera-view {
    text-align: center;
}

.samples-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
    gap: 20px;
}

.sample-item {
    border: 1px solid #ddd;
    border-radius: 10px;
    padding: 20px;
    text-align: center;
    cursor: pointer;
    transition: all 0.3s ease;
}

.sample-item:hover {
    border-color: #667eea;
    background: #f8f9ff;
    transform: translateY(-2px);
}

.results-section {
    background: white;
    border-radius: 15px;
    padding: 30px;
    box-shadow: 0 10px 30px rgba(0,0,0,0.1);
}

.metrics-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
    gap: 20px;
    margin-bottom: 30px;
}

.metric-card {
    background: #f8f9ff;
    padding: 20px;
    border-radius: 10px;
    text-align: center;
    border-left: 4px solid #667eea;
}

.metric-card h3 {
    margin-bottom: 10px;
    color: #667eea;
}

.metric-card span {
    font-size: 2rem;
    font-weight: bold;
    color: #333;
}

.analysis-section, .risk-section, .visualization-section {
    margin-bottom: 30px;
}

.analysis-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
    gap: 15px;
}

.analysis-item {
    background: #f8f9ff;
    padding: 15px;
    border-radius: 8px;
    text-align: center;
}

.analysis-item h4 {
    margin-bottom: 8px;
    color: #667eea;
    font-size: 0.9rem;
}

.analysis-item span {
    font-size: 1.5rem;
    font-weight: bold;
}

.risk-alert {
    background: #f0fff4;
    border: 1px solid #38a169;
    border-radius: 10px;
    padding: 20px;
    text-align: center;
}

.risk-alert.high {
    background: #fee;
    border-color: #c53030;
    color: #c53030;
}

.risk-alert.medium {
    background: #fffbf0;
    border-color: #d69e2e;
    color: #d69e2e;
}

.risk-alert.low {
    background: #f0fff4;
    border-color: #38a169;
    color: #38a169;
}

.images-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
    gap: 20px;
}

.image-result {
    text-align: center;
}

.image-result h4 {
    margin-bottom: 10px;
    color: #667eea;
}

.image-result img {
    max-width: 100%;
    border-radius: 10px;
    box-shadow: 0 5px 15px rgba(0,0,0,0.1);
}

.loading {
    position: fixed;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    background: rgba(0,0,0,0.8);
    display: flex;
    flex-direction: column;
    justify-content: center;
    align-items: center;
    color: white;
    z-index: 1000;
}

.spinner {
    width: 50px;
    height: 50px;
    border: 5px solid #667eea;
    border-top: 5px solid white;
    border-radius: 50%;
    animation: spin 1s linear infinite;
    margin-bottom: 20px;
}

@keyframes spin {
    0% { transform: rotate(0deg); }
    100% { transform: rotate(360deg); }
}

@media (max-width: 768px) {
    .container {
        padding: 10px;
    }
    
    header h1 {
        font-size: 2rem;
    }
    
    .demo-tabs {
        flex-direction: column;
    }
    
    .tab-content {
        padding: 20px;
    }
    
    .metrics-grid,
    .images-grid {
        grid-template-columns: 1fr;
    }
}
        """
        
        self.send_response(200)
        self.send_header('Content-type', 'text/css')
        self.end_headers()
        self.wfile.write(css_content.encode('utf-8'))
    
    def serve_js(self):
        """æä¾›JavaScriptä»£ç¢¼"""
        js_content = """
// å…¨å±€è®Šé‡
let currentStream = null;
let isProcessing = false;

// æ¨™ç±¤åˆ‡æ›
function showTab(tabName) {
    // éš±è—æ‰€æœ‰æ¨™ç±¤å…§å®¹
    const tabs = document.querySelectorAll('.tab-content');
    tabs.forEach(tab => tab.classList.remove('active'));
    
    // ç§»é™¤æ‰€æœ‰æŒ‰éˆ•çš„activeé¡
    const buttons = document.querySelectorAll('.tab-button');
    buttons.forEach(btn => btn.classList.remove('active'));
    
    // é¡¯ç¤ºé¸ä¸­çš„æ¨™ç±¤
    document.getElementById(tabName + '-tab').classList.add('active');
    event.target.classList.add('active');
}

// è™•ç†åœ–åƒä¸Šå‚³
function handleImageUpload(event) {
    const file = event.target.files[0];
    if (!file) return;
    
    const reader = new FileReader();
    reader.onload = function(e) {
        const preview = document.getElementById('preview-image');
        preview.src = e.target.result;
        preview.style.display = 'block';
        
        // è™•ç†åœ–åƒ
        processImage(e.target.result);
    };
    reader.readAsDataURL(file);
}

// è™•ç†åœ–åƒ
async function processImage(imageData) {
    if (isProcessing) return;
    isProcessing = true;
    
    showLoading(true);
    
    try {
        const response = await fetch('/api/process_image', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            },
            body: JSON.stringify({ image: imageData })
        });
        
        const result = await response.json();
        
        if (result.success) {
            displayResults(result);
        } else {
            alert('è™•ç†å¤±æ•—: ' + (result.error || 'æœªçŸ¥éŒ¯èª¤'));
        }
    } catch (error) {
        console.error('è™•ç†åœ–åƒéŒ¯èª¤:', error);
        alert('è™•ç†åœ–åƒæ™‚ç™¼ç”ŸéŒ¯èª¤: ' + error.message);
    } finally {
        showLoading(false);
        isProcessing = false;
    }
}

// é¡¯ç¤ºçµæœ
function displayResults(result) {
    const resultsSection = document.getElementById('results-section');
    resultsSection.style.display = 'block';
    
    // æ›´æ–°çµ±è¨ˆ
    const unified = result.unified_result || {};
    const totals = unified.total_detections || {};
    
    document.getElementById('face-count').textContent = totals.faces || 0;
    document.getElementById('pose-count').textContent = totals.poses || 0;
    document.getElementById('hand-count').textContent = totals.hands || 0;
    
    // æ›´æ–°è¡Œç‚ºåˆ†æ
    const interaction = result.interaction_result || {};
    const poseAnalysis = interaction.pose_analysis || {};
    
    if (poseAnalysis && !poseAnalysis.error) {
        document.getElementById('balance-score').textContent = 
            (poseAnalysis.balance_score || 0).toFixed(2);
        document.getElementById('stability-score').textContent = 
            (poseAnalysis.stability_score || 0).toFixed(2);
        document.getElementById('posture-deviation').textContent = 
            (poseAnalysis.posture_deviation || 0).toFixed(2);
    }
    
    // æ›´æ–°é¢¨éšªè©•ä¼°
    const riskAssessment = interaction.risk_assessment || {};
    if (riskAssessment.level) {
        const riskAlert = document.getElementById('risk-alert');
        const riskLevel = document.getElementById('risk-level');
        const riskScore = document.getElementById('risk-score');
        
        riskLevel.textContent = getRiskIcon(riskAssessment.level) + ' ' + 
                               riskAssessment.level.toUpperCase();
        riskScore.textContent = 'è©•åˆ†: ' + (riskAssessment.score || 0).toFixed(2);
        
        // è¨­ç½®é¢¨éšªç­‰ç´šæ¨£å¼
        riskAlert.className = 'risk-alert ' + riskAssessment.level;
    }
    
    // é¡¯ç¤ºæ¨™è¨»åœ–åƒ
    const annotated = result.annotated_images || {};
    
    if (annotated.face) {
        const faceImg = document.getElementById('face-result');
        faceImg.src = annotated.face;
        faceImg.style.display = 'block';
    }
    
    if (annotated.pose) {
        const poseImg = document.getElementById('pose-result');
        poseImg.src = annotated.pose;
        poseImg.style.display = 'block';
    }
    
    if (annotated.hand) {
        const handImg = document.getElementById('hand-result');
        handImg.src = annotated.hand;
        handImg.style.display = 'block';
    }
    
    // æ»¾å‹•åˆ°çµæœå€åŸŸ
    resultsSection.scrollIntoView({ behavior: 'smooth' });
}

// ç²å–é¢¨éšªç­‰ç´šåœ–æ¨™
function getRiskIcon(level) {
    switch(level) {
        case 'high': return 'ğŸ”´';
        case 'medium': return 'ğŸŸ¡';
        case 'low': return 'ğŸŸ¢';
        default: return 'âšª';
    }
}

// å•Ÿå‹•æ”å½±æ©Ÿ
async function startCamera() {
    try {
        const response = await fetch('/api/camera/start');
        const result = await response.json();
        
        if (result.success) {
            document.getElementById('start-camera').disabled = true;
            document.getElementById('stop-camera').disabled = false;
            
            // å•Ÿå‹•æœ¬åœ°æ”å½±æ©Ÿé è¦½
            const video = document.getElementById('camera-video');
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            video.srcObject = stream;
            video.style.display = 'block';
            currentStream = stream;
            
            // é–‹å§‹è™•ç†å¹€
            startFrameProcessing();
        } else {
            alert('å•Ÿå‹•æ”å½±æ©Ÿå¤±æ•—: ' + (result.error || 'æœªçŸ¥éŒ¯èª¤'));
        }
    } catch (error) {
        console.error('æ”å½±æ©ŸéŒ¯èª¤:', error);
        alert('æ”å½±æ©ŸéŒ¯èª¤: ' + error.message);
    }
}

// åœæ­¢æ”å½±æ©Ÿ
async function stopCamera() {
    try {
        await fetch('/api/camera/stop');
        
        if (currentStream) {
            currentStream.getTracks().forEach(track => track.stop());
            currentStream = null;
        }
        
        document.getElementById('camera-video').style.display = 'none';
        document.getElementById('start-camera').disabled = false;
        document.getElementById('stop-camera').disabled = true;
    } catch (error) {
        console.error('åœæ­¢æ”å½±æ©ŸéŒ¯èª¤:', error);
    }
}

// é–‹å§‹å¹€è™•ç†
function startFrameProcessing() {
    if (!currentStream) return;
    
    const video = document.getElementById('camera-video');
    const canvas = document.getElementById('camera-canvas');
    const ctx = canvas.getContext('2d');
    
    function processFrame() {
        if (!currentStream) return;
        
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        ctx.drawImage(video, 0, 0);
        
        // æ¯2ç§’è™•ç†ä¸€æ¬¡å¹€
        const imageData = canvas.toDataURL('image/jpeg', 0.8);
        processImage(imageData);
        
        setTimeout(processFrame, 2000);
    }
    
    // ç­‰å¾…è¦–é »è¼‰å…¥
    video.addEventListener('loadedmetadata', () => {
        setTimeout(processFrame, 1000);
    });
}

// è¼‰å…¥ç¤ºä¾‹åœ–åƒ
function loadSample(imageName) {
    // é€™è£¡å¯ä»¥å¯¦ç¾è¼‰å…¥ç¤ºä¾‹åœ–åƒçš„é‚è¼¯
    alert('è¼‰å…¥ç¤ºä¾‹åœ–åƒ: ' + imageName);
}

// é¡¯ç¤º/éš±è—è¼‰å…¥æŒ‡ç¤ºå™¨
function showLoading(show) {
    const loading = document.getElementById('loading');
    loading.style.display = show ? 'flex' : 'none';
}

// é é¢è¼‰å…¥å®Œæˆæ™‚çš„åˆå§‹åŒ–
document.addEventListener('DOMContentLoaded', function() {
    console.log('QAI Hub Web Demo å·²è¼‰å…¥');
});
        """
        
        self.send_response(200)
        self.send_header('Content-type', 'application/javascript')
        self.end_headers()
        self.wfile.write(js_content.encode('utf-8'))
    
    def handle_process_image(self):
        """è™•ç†åœ–åƒè™•ç†è«‹æ±‚"""
        try:
            content_length = int(self.headers['Content-Length'])
            post_data = self.rfile.read(content_length)
            data = json.loads(post_data.decode('utf-8'))
            
            image_data = data.get('image')
            if not image_data:
                self.send_json_response({'error': 'æ²’æœ‰åœ–åƒæ•¸æ“š'})
                return
            
            result = self.demo.process_image(image_data)
            self.send_json_response(result)
            
        except Exception as e:
            logger.error(f"è™•ç†åœ–åƒè«‹æ±‚éŒ¯èª¤: {e}")
            self.send_json_response({'error': str(e)})
    
    def handle_camera_start(self):
        """è™•ç†æ”å½±æ©Ÿå•Ÿå‹•è«‹æ±‚"""
        success = self.demo.start_camera_stream()
        self.send_json_response({'success': success})
    
    def handle_camera_stop(self):
        """è™•ç†æ”å½±æ©Ÿåœæ­¢è«‹æ±‚"""
        self.demo.stop_camera_stream()
        self.send_json_response({'success': True})
    
    def handle_camera_frame(self):
        """è™•ç†æ”å½±æ©Ÿå¹€è«‹æ±‚"""
        frame_data = self.demo.get_camera_frame()
        if frame_data:
            self.send_json_response({'success': True, 'data': frame_data})
        else:
            self.send_json_response({'success': False, 'error': 'ç„¡æ³•ç²å–æ”å½±æ©Ÿå¹€'})
    
    def send_json_response(self, data):
        """ç™¼é€JSONéŸ¿æ‡‰"""
        response = json.dumps(data, ensure_ascii=False)
        self.send_response(200)
        self.send_header('Content-type', 'application/json; charset=utf-8')
        self.end_headers()
        self.wfile.write(response.encode('utf-8'))

def create_handler(demo_instance):
    """å‰µå»ºè«‹æ±‚è™•ç†å™¨"""
    def handler(*args, **kwargs):
        return DemoRequestHandler(*args, demo_instance=demo_instance, **kwargs)
    return handler

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ å•Ÿå‹•QAI Hub Web Demo...")
    
    # åˆå§‹åŒ–Demoç³»çµ±
    demo = QAIHubWebDemo()
    
    # å‰µå»ºHTTPæœå‹™å™¨
    port = 8080
    server = HTTPServer(('localhost', port), create_handler(demo))
    
    print(f"âœ… Webæœå‹™å™¨å·²å•Ÿå‹•")
    print(f"ğŸŒ è«‹è¨ªå•: http://localhost:{port}")
    print("æŒ‰ Ctrl+C åœæ­¢æœå‹™å™¨")
    
    try:
        server.serve_forever()
    except KeyboardInterrupt:
        print("\nğŸ›‘ åœæ­¢æœå‹™å™¨...")
        demo.stop_camera_stream()
        server.shutdown()

if __name__ == "__main__":
    main()
