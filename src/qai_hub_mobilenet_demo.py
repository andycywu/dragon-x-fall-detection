#!/usr/bin/env python3
"""
ğŸ“˜ QAI Hub å®˜æ–¹ Post-Install æ•™ç¨‹é¢¨æ ¼ç¯„ä¾‹ (MobileNetV2)

æ­¥é©Ÿ: Compile â†’ Profile â†’ Inference â†’ Download
ç›®æ¨™è¨­å‚™: Snapdragon X Elite CRD (è‹¥æ‰¾ä¸åˆ°å‰‡å›é€€ç¬¬ä¸€å°å¯ç”¨è¨­å‚™)

éœ€æ±‚å¥—ä»¶: qai-hub, torch, torchvision, requests, pillow, numpy
åŸ·è¡Œå‰è«‹ç¢ºä¿å·²è¨­ç½®ç’°å¢ƒè®Šæ•¸ QAI_HUB_API_TOKEN æˆ–åœ¨ client.ini ä¸­å®Œæˆ configureã€‚

ç”¨æ³•:
  python qai_hub_mobilenet_demo.py
  python qai_hub_mobilenet_demo.py --device "Snapdragon X Elite CRD" --skip-profile

åƒæ•¸:
  --device          æŒ‡å®šè¨­å‚™åç¨± (é è¨­å„ªå…ˆæ‰¾å« Snapdragon X Elite çš„åç¨±)
  --skip-profile    è·³é profiling æ­¥é©Ÿ (åƒ… compile + inference)
  --download-path   æŒ‡å®šä¸‹è¼‰ onnx æ¨¡å‹è·¯å¾‘ (é è¨­ mobilenet_v2.onnx)
  --timeout         å–®ä¸€ Job ç­‰å¾…é€¾æ™‚ç§’æ•¸ (é è¨­ 900 ç§’)

"""
import os
import sys
import time
import argparse
import logging
import json
import numpy as np
import requests
from PIL import Image

import torch
from torchvision.models import mobilenet_v2
import qai_hub as hub

logging.basicConfig(level=logging.INFO, format='%(levelname)s:%(message)s')
logger = logging.getLogger("mobilenet_demo")


def wait_job(job, label: str, timeout: int = 900, poll: int = 5):
    start = time.time()
    while True:
        try:
            job.wait(timeout=1)
            logger.info(f"âœ… {label} å®Œæˆ (job_id={job.job_id})")
            return True
        except Exception:
            pass
        if time.time() - start > timeout:
            logger.error(f"â° {label} ç­‰å¾…é€¾æ™‚ {timeout}s")
            return False
        if int(time.time() - start) % poll == 0:
            logger.info(f"â³ ç­‰å¾… {label} ... å·² {int(time.time()-start)}s")
        time.sleep(1)


def pick_device(preferred_name: str | None):
    devices = hub.get_devices()
    if not devices:
        raise RuntimeError("ç„¡å¯ç”¨è¨­å‚™")
    if preferred_name:
        for d in devices:
            if d.name.strip().lower() == preferred_name.strip().lower():
                logger.info(f"ğŸ¯ ä½¿ç”¨æŒ‡å®šè¨­å‚™: {d.name}")
                return d
    # å„ªå…ˆåŒ…å« Snapdragon X Elite
    for d in devices:
        if 'snapdragon x elite' in d.name.lower():
            logger.info(f"ğŸ¯ é¸æ“‡ Snapdragon X Elite: {d.name}")
            return d
    logger.info(f"âš ï¸ æœªæ‰¾åˆ° Snapdragon X Eliteï¼Œå›é€€ç¬¬ä¸€å°: {devices[0].name}")
    return devices[0]


def run_pipeline(args):
    # Step 0: æº–å‚™ & é©—è­‰ token
    api_token = os.getenv('QAI_HUB_API_TOKEN')
    if not api_token:
        logger.warning("âš ï¸ æ²’æœ‰ QAI_HUB_API_TOKENï¼Œå‡è¨­å·²é€é client.ini é…ç½®")

    device = pick_device(args.device)

    # Step 1: è¼‰å…¥é è¨“ç·´ Torch æ¨¡å‹ä¸¦ trace
    logger.info("ğŸ” è¼‰å…¥ torchvision MobileNetV2 (pretrained)")
    torch_model = mobilenet_v2(pretrained=True)
    torch_model.eval()
    input_shape = (1, 3, 224, 224)
    example_input = torch.rand(input_shape)
    traced_torch_model = torch.jit.trace(torch_model, example_input)
    logger.info("âœ… TorchScript trace å®Œæˆ")

    # Step 2: Compile
    logger.info("ğŸš€ æäº¤ Compile Job (target_runtime=onnx)...")
    compile_job = hub.submit_compile_job(
        model=traced_torch_model,
        device=device,
        input_specs=dict(image=input_shape),
        options="--target_runtime onnx",
    )
    wait_job(compile_job, "Compile")

    target_model = compile_job.get_target_model()

    # Step 3: Profile (å¯é¸)
    profile_job = None
    if not args.skip_profile:
        logger.info("ğŸ“ˆ æäº¤ Profile Job ...")
        try:
            profile_job = hub.submit_profile_job(model=target_model, device=device)
            wait_job(profile_job, "Profile")
        except Exception as e:
            logger.warning(f"âš ï¸ Profile å¤±æ•— (ç•¥é): {e}")
    else:
        logger.info("â­ï¸ è·³é Profile Job")

    # Step 4: Inference
    logger.info("ğŸ§ª æäº¤é›²ç«¯ Inference Job ...")
    sample_image_url = (
        "https://qaihub-public-assets.s3.us-west-2.amazonaws.com/apidoc/input_image1.jpg"
    )
    response = requests.get(sample_image_url, stream=True, timeout=30)
    response.raise_for_status()
    response.raw.decode_content = True
    image = Image.open(response.raw).resize((224, 224))
    input_array = np.expand_dims(
        np.transpose(np.array(image, dtype=np.float32) / 255.0, (2, 0, 1)), axis=0
    )

    inference_job = hub.submit_inference_job(
        model=target_model,
        device=device,
        inputs=dict(image=[input_array]),
    )
    wait_job(inference_job, "Inference")
    on_device_output = inference_job.download_output_data()

    output_name = list(on_device_output.keys())[0]
    out = on_device_output[output_name][0]
    on_device_probabilities = np.exp(out) / np.sum(np.exp(out), axis=1)

    classes_url = "https://qaihub-public-assets.s3.us-west-2.amazonaws.com/apidoc/imagenet_classes.txt"
    cls_resp = requests.get(classes_url, stream=True, timeout=30)
    cls_resp.raise_for_status()
    cls_resp.raw.decode_content = True
    categories = [str(s.strip()) for s in cls_resp.raw]

    logger.info("ğŸ Top-5 On-Device predictions:")
    top5 = np.argsort(on_device_probabilities[0])[-5:][::-1]
    for c in top5:
        logger.info(f"  {c:>4} {categories[c]:25s} {on_device_probabilities[0][c]:6.2%}")

    # Step 5: Download compiled (target) model
    download_path = args.download_path
    logger.info(f"ğŸ’¾ ä¸‹è¼‰ç›®æ¨™æ¨¡å‹åˆ° {download_path} ...")
    target_model.download(download_path)
    logger.info("âœ… ä¸‹è¼‰å®Œæˆ")

    summary = {
        "device": device.name,
        "compile_job_id": compile_job.job_id,
        "profile_job_id": getattr(profile_job, 'job_id', None),
        "inference_job_id": inference_job.job_id,
        "download_path": download_path,
        "timestamp": time.time(),
    }
    with open('mobilenet_demo_summary.json', 'w') as f:
        json.dump(summary, f, indent=2)
    logger.info("ğŸ“ Summary å·²å¯«å…¥ mobilenet_demo_summary.json")


def parse_args():
    p = argparse.ArgumentParser(description="QAI Hub MobileNet Demo")
    p.add_argument('--device', type=str, default=None, help='æŒ‡å®šè¨­å‚™åç¨±')
    p.add_argument('--skip-profile', action='store_true', help='è·³é Profiling')
    p.add_argument('--download-path', type=str, default='mobilenet_v2.onnx', help='ä¸‹è¼‰æ¨¡å‹æª”æ¡ˆè·¯å¾‘')
    p.add_argument('--timeout', type=int, default=900, help='å–®ä¸€ Job ç­‰å¾…é€¾æ™‚ç§’æ•¸')
    return p.parse_args()


if __name__ == '__main__':
    try:
        args = parse_args()
        run_pipeline(args)
    except Exception as e:
        logger.error(f"âŒ Demo å¤±æ•—: {e}")
        raise
