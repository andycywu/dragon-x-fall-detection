#!/usr/bin/env python3
"""
ğŸš€ Dragon X Fall Detection System
ä½¿ç”¨çœŸæ­£çš„QAI Hubé€²è¡Œæ¨è«–çš„è·Œå€’æª¢æ¸¬ç³»çµ±
"""

import os
import sys
import cv2
import numpy as np
import logging
import time
import json
from typing import Dict, Any, Optional, List, Tuple
import random

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(levelname)s:%(name)s:%(message)s')
logger = logging.getLogger(__name__)

# é…ç½®QAI Hubç’°å¢ƒè®Šæ•¸
os.environ["QAI_API_KEY"] = "pcu8nz63e4j3nzqgy7tjzvr2dmpc01cocltahr0d"
os.environ["QAI_API_TOKEN"] = "pcu8nz63e4j3nzqgy7tjzvr2dmpc01cocltahr0d"
os.environ["QAI_HOST"] = "https://api.aihub.qualcomm.com"
os.environ["QAI_API_URL"] = "https://api.aihub.qualcomm.com"
os.environ["QAI_API_VERSION"] = "v1"

print("QAI Hubç’°å¢ƒè®Šæ•¸å·²è¨­å®š")

# å˜—è©¦å°å…¥QAI Hubç›¸é—œæ¨¡çµ„
try:
    import qai_hub as hub
    import onnxruntime as ort
    USING_REAL_QAI_HUB = True
    print("æˆåŠŸå°å…¥QAI Hub")
except ImportError as e:
    print(f"ç„¡æ³•å°å…¥QAI Hub: {e}")
    USING_REAL_QAI_HUB = False
    print("å°‡ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")

# QAI Hubæ¨¡å‹åˆ—è¡¨ - æŒ‰å„ªå…ˆé †åºæ’åˆ—
QAI_HUB_MODELS = [
    "qai-hub/mobilenetv3-small-minimalistic",
    "qai-hub/efficientnet-lite4",
    "qai-hub/mobilenet-v2-1.0",
    "qai-hub/squeezenet1-1",
    "qai-hub/pose-estimation-hrnet"
]

class FallDetectionModel:
    """è·Œå€’æª¢æ¸¬æ¨¡å‹ï¼Œä½¿ç”¨QAI Hubæˆ–ONNX Runtime"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ¨¡å‹"""
        self.qai_model = None
        self.onnx_session = None
        self.model_name = None
        self.input_shape = (224, 224)  # é»˜èªè¼¸å…¥å°ºå¯¸
        
        # åˆå§‹åŒ–QAI Hub
        if USING_REAL_QAI_HUB:
            self._init_qai_hub()
        else:
            logger.info("QAI Hubä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")
    
    def _init_qai_hub(self):
        """åˆå§‹åŒ–QAI Hubé€£æ¥ä¸¦åŠ è¼‰æ¨¡å‹"""
        try:
            # å˜—è©¦ç²å–å¯ç”¨è¨­å‚™
            logger.info("ç²å–QAI Hubå¯ç”¨è¨­å‚™...")
            devices = hub.get_devices()
            logger.info(f"æ‰¾åˆ°{len(devices)}å€‹QAI Hubè¨­å‚™")
            
            # å˜—è©¦è¼‰å…¥æ¨¡å‹
            for model_name in QAI_HUB_MODELS:
                try:
                    logger.info(f"å˜—è©¦è¼‰å…¥æ¨¡å‹: {model_name}")
                    self.qai_model = hub.load(model_name)
                    self.model_name = model_name
                    logger.info(f"æˆåŠŸè¼‰å…¥æ¨¡å‹: {model_name}")
                    break
                except Exception as e:
                    logger.warning(f"ç„¡æ³•è¼‰å…¥æ¨¡å‹ {model_name}: {e}")
            
            if self.qai_model is None:
                logger.warning("ç„¡æ³•è¼‰å…¥ä»»ä½•QAI Hubæ¨¡å‹ï¼Œå°‡ä½¿ç”¨ONNXæ¨¡å¼")
                self._init_onnx_fallback()
        
        except Exception as e:
            logger.error(f"QAI Hubåˆå§‹åŒ–å¤±æ•—: {e}")
            logger.info("åˆ‡æ›åˆ°ONNXæ¨¡å¼")
            self._init_onnx_fallback()
    
    def _init_onnx_fallback(self):
        """åˆå§‹åŒ–ONNX Runtimeä½œç‚ºå‚™ç”¨æ–¹æ¡ˆ"""
        try:
            logger.info("åˆå§‹åŒ–ONNX Runtime...")
            
            # æª¢æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„ONNXæ¨¡å‹æ–‡ä»¶
            onnx_models = [f for f in os.listdir('.') if f.endswith('.onnx')]
            
            if onnx_models:
                onnx_path = onnx_models[0]
                logger.info(f"ä½¿ç”¨ONNXæ¨¡å‹: {onnx_path}")
                
                # ç²å–å¯ç”¨çš„åŸ·è¡Œæä¾›å•†
                available_providers = ort.get_available_providers()
                logger.info(f"å¯ç”¨ONNXæä¾›å•†: {available_providers}")
                
                # å„ªå…ˆä½¿ç”¨GPUåŠ é€Ÿ
                providers = []
                if 'CUDAExecutionProvider' in available_providers:
                    providers.append('CUDAExecutionProvider')
                elif 'DmlExecutionProvider' in available_providers:
                    providers.append('DmlExecutionProvider')
                providers.append('CPUExecutionProvider')
                
                # å‰µå»ºONNXæœƒè©±
                self.onnx_session = ort.InferenceSession(onnx_path, providers=providers)
                logger.info(f"ONNXæœƒè©±å‰µå»ºæˆåŠŸï¼Œä½¿ç”¨æä¾›å•†: {providers}")
                
                # ç²å–è¼¸å…¥å½¢ç‹€
                input_name = self.onnx_session.get_inputs()[0].name
                input_shape = self.onnx_session.get_inputs()[0].shape
                logger.info(f"ONNXè¼¸å…¥: {input_name}, å½¢ç‹€: {input_shape}")
                
                if len(input_shape) >= 3:
                    # å‡è¨­å½¢ç‹€æ˜¯[batch, channels, height, width]æˆ–[batch, height, width, channels]
                    if input_shape[1] == 3:  # NCHWæ ¼å¼
                        self.input_shape = (int(input_shape[3]), int(input_shape[2]))
                    else:  # NHWCæ ¼å¼
                        self.input_shape = (int(input_shape[2]), int(input_shape[1]))
            else:
                logger.warning("æ‰¾ä¸åˆ°ONNXæ¨¡å‹æ–‡ä»¶ï¼Œå°‡ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")
        
        except Exception as e:
            logger.error(f"ONNXåˆå§‹åŒ–å¤±æ•—: {e}")
            logger.warning("å°‡ä½¿ç”¨å®Œå…¨æ¨¡æ“¬æ¨¡å¼")
    
    def preprocess_image(self, image: np.ndarray) -> np.ndarray:
        """é è™•ç†è¼¸å…¥åœ–åƒ"""
        # èª¿æ•´å¤§å°
        resized = cv2.resize(image, self.input_shape)
        
        # è½‰æ›ç‚ºRGBï¼ˆå¦‚æœæ˜¯BGRï¼‰
        rgb = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
        
        # æ¨™æº–åŒ–åˆ°[0,1]
        normalized = rgb.astype(np.float32) / 255.0
        
        # æ ¹æ“šä½¿ç”¨çš„æ¨¡å‹é¡å‹èª¿æ•´æ ¼å¼
        if self.qai_model:
            # QAI Hubé€šå¸¸éœ€è¦NCHWæ ¼å¼ [batch, channels, height, width]
            input_tensor = np.transpose(normalized, (2, 0, 1))
            input_tensor = np.expand_dims(input_tensor, axis=0)
        elif self.onnx_session:
            # ç²å–ONNXæ¨¡å‹çš„è¼¸å…¥æ ¼å¼
            input_name = self.onnx_session.get_inputs()[0].name
            input_shape = self.onnx_session.get_inputs()[0].shape
            
            if len(input_shape) == 4 and input_shape[1] == 3:
                # NCHWæ ¼å¼ [batch, channels, height, width]
                input_tensor = np.transpose(normalized, (2, 0, 1))
                input_tensor = np.expand_dims(input_tensor, axis=0)
            else:
                # NHWCæ ¼å¼ [batch, height, width, channels]
                input_tensor = np.expand_dims(normalized, axis=0)
        else:
            # é»˜èªä½¿ç”¨NCHWæ ¼å¼
            input_tensor = np.transpose(normalized, (2, 0, 1))
            input_tensor = np.expand_dims(input_tensor, axis=0)
            
        return input_tensor
    
    def infer(self, image: np.ndarray) -> Dict[str, Any]:
        """åŸ·è¡Œæ¨è«–"""
        # é è™•ç†åœ–åƒ
        input_tensor = self.preprocess_image(image)
        
        result = {
            "success": False,
            "inference_time_ms": 0,
            "model_type": "unknown",
            "is_fall": False,
            "confidence": 0.0
        }
        
        # é–‹å§‹è¨ˆæ™‚
        start_time = time.time()
        
        try:
            # å˜—è©¦ä½¿ç”¨QAI Hubæ¨¡å‹
            if self.qai_model:
                logger.debug("ä½¿ç”¨QAI Hubæ¨¡å‹é€²è¡Œæ¨è«–")
                predictions = self.qai_model(input_tensor)
                
                result["model_type"] = f"QAI_Hub_{self.model_name}"
                result["success"] = True
                
                # æå–é æ¸¬çµæœ
                if isinstance(predictions, dict):
                    # æå–å‡ºå­—å…¸ä¸­çš„é æ¸¬å€¼
                    if "predictions" in predictions:
                        pred_value = predictions["predictions"]
                    elif "output" in predictions:
                        pred_value = predictions["output"]
                    else:
                        # ä½¿ç”¨ç¬¬ä¸€å€‹å¯ç”¨çš„éµ
                        pred_key = list(predictions.keys())[0]
                        pred_value = predictions[pred_key]
                else:
                    # ç›´æ¥ä½¿ç”¨è¿”å›å€¼
                    pred_value = predictions
                
                # å˜—è©¦å°‡é æ¸¬è½‰æ›ç‚ºNumPyæ•¸çµ„
                if not isinstance(pred_value, np.ndarray):
                    try:
                        pred_value = np.array(pred_value)
                    except:
                        logger.warning("ç„¡æ³•å°‡é æ¸¬è½‰æ›ç‚ºNumPyæ•¸çµ„")
                
                # ä½¿ç”¨é æ¸¬ä¾†åˆ¤æ–·æ˜¯å¦ç‚ºè·Œå€’
                try:
                    if isinstance(pred_value, np.ndarray):
                        # å–æœ€å¤§å€¼ä½œç‚ºä¿¡å¿ƒåº¦
                        confidence = float(np.max(pred_value))
                        # ç°¡å–®é–¾å€¼åˆ¤æ–·
                        is_fall = confidence > 0.7
                        
                        result["confidence"] = confidence
                        result["is_fall"] = is_fall
                        result["prediction_shape"] = pred_value.shape
                except Exception as e:
                    logger.error(f"è™•ç†QAI Hubé æ¸¬æ™‚å‡ºéŒ¯: {e}")
                    
            # å˜—è©¦ä½¿ç”¨ONNXæ¨¡å‹
            elif self.onnx_session:
                logger.debug("ä½¿ç”¨ONNXæ¨¡å‹é€²è¡Œæ¨è«–")
                input_name = self.onnx_session.get_inputs()[0].name
                outputs = self.onnx_session.run(None, {input_name: input_tensor})
                
                result["model_type"] = "ONNX_Runtime"
                result["success"] = True
                
                # è™•ç†ONNXè¼¸å‡º
                if outputs and len(outputs) > 0:
                    # ä½¿ç”¨ç¬¬ä¸€å€‹è¼¸å‡º
                    output = outputs[0]
                    
                    # å–æœ€å¤§å€¼ä½œç‚ºä¿¡å¿ƒåº¦
                    confidence = float(np.max(output))
                    # ç°¡å–®é–¾å€¼åˆ¤æ–·
                    is_fall = confidence > 0.7
                    
                    result["confidence"] = confidence
                    result["is_fall"] = is_fall
                    result["prediction_shape"] = output.shape
            
            # ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼
            else:
                logger.debug("ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼é€²è¡Œæ¨è«–")
                # éš¨æ©Ÿç”Ÿæˆçµæœï¼Œä½†åå‘æ–¼éè·Œå€’ç‹€æ…‹
                is_fall = random.random() < 0.05  # 5%çš„æ©Ÿç‡æª¢æ¸¬åˆ°è·Œå€’
                confidence = random.uniform(0.8, 0.95) if is_fall else random.uniform(0.1, 0.3)
                
                result["model_type"] = "Simulated"
                result["success"] = True
                result["confidence"] = confidence
                result["is_fall"] = is_fall
                
        except Exception as e:
            logger.error(f"æ¨è«–å¤±æ•—: {e}")
            result["error"] = str(e)
            
            # å‡ºéŒ¯æ™‚ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼
            is_fall = random.random() < 0.05
            confidence = random.uniform(0.8, 0.95) if is_fall else random.uniform(0.1, 0.3)
            
            result["model_type"] = "Simulated_Fallback"
            result["confidence"] = confidence
            result["is_fall"] = is_fall
        
        # è¨ˆç®—æ¨è«–æ™‚é–“
        inference_time = (time.time() - start_time) * 1000
        result["inference_time_ms"] = round(inference_time, 2)
        
        return result


class FallDetectionSystem:
    """è·Œå€’æª¢æ¸¬ç³»çµ±"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç³»çµ±"""
        self.model = FallDetectionModel()
        self.frame_count = 0
        self.fall_count = 0
        self.last_fall_time = 0
        self.fall_cooldown = 3.0  # æª¢æ¸¬åˆ°è·Œå€’å¾Œçš„å†·å»æ™‚é–“ï¼ˆç§’ï¼‰
        
        # æ­·å²ç‹€æ…‹è¿½è¹¤
        self.recent_results = []
        self.max_history = 10
        
        # æ€§èƒ½è¿½è¹¤
        self.fps = 0
        self.avg_inference_time = 0
        self.inference_times = []
        self.max_inference_times = 50
    
    def process_frame(self, frame: np.ndarray) -> Tuple[np.ndarray, bool]:
        """è™•ç†å–®å¹€åœ–åƒä¸¦æª¢æ¸¬è·Œå€’"""
        self.frame_count += 1
        
        # åŸ·è¡Œæ¨è«–
        result = self.model.infer(frame)
        
        # æ›´æ–°æ€§èƒ½æŒ‡æ¨™
        self.inference_times.append(result["inference_time_ms"])
        if len(self.inference_times) > self.max_inference_times:
            self.inference_times.pop(0)
        self.avg_inference_time = sum(self.inference_times) / len(self.inference_times)
        
        # æ·»åŠ åˆ°æ­·å²è¨˜éŒ„
        self.recent_results.append(result)
        if len(self.recent_results) > self.max_history:
            self.recent_results.pop(0)
        
        # æª¢æ¸¬æ˜¯å¦ç‚ºè·Œå€’
        is_fall = result["is_fall"]
        current_time = time.time()
        
        # å¢åŠ å†·å»æ™‚é–“é¿å…é€£çºŒæª¢æ¸¬åˆ°è·Œå€’
        if is_fall and (current_time - self.last_fall_time > self.fall_cooldown):
            self.fall_count += 1
            self.last_fall_time = current_time
            logger.info(f"æª¢æ¸¬åˆ°è·Œå€’! ä¿¡å¿ƒåº¦: {result['confidence']:.2f}, æ¨¡å‹: {result['model_type']}")
        else:
            is_fall = False  # åœ¨å†·å»æœŸé–“ä¸å ±å‘Šè·Œå€’
        
        # åœ¨åœ–åƒä¸Šç¹ªè£½ä¿¡æ¯
        processed_frame = self.draw_info(frame, result, is_fall)
        
        return processed_frame, is_fall
    
    def draw_info(self, frame: np.ndarray, result: Dict[str, Any], is_fall: bool) -> np.ndarray:
        """åœ¨åœ–åƒä¸Šç¹ªè£½ä¿¡æ¯"""
        # å‰µå»ºå‰¯æœ¬ä»¥é¿å…ä¿®æ”¹åŸå§‹å¹€
        output = frame.copy()
        
        # é¡¯ç¤ºFPS
        cv2.putText(output, f"FPS: {self.fps:.1f}", (10, 30), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        
        # é¡¯ç¤ºæ¨è«–æ™‚é–“
        cv2.putText(output, f"Inference: {result['inference_time_ms']:.1f}ms (Avg: {self.avg_inference_time:.1f}ms)", 
                    (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        
        # é¡¯ç¤ºæ¨¡å‹é¡å‹
        cv2.putText(output, f"Model: {result['model_type']}", 
                    (10, output.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        
        # é¡¯ç¤ºè·Œå€’ç‹€æ…‹
        status_text = "FALL DETECTED!" if is_fall else "Normal"
        status_color = (0, 0, 255) if is_fall else (0, 255, 0)
        cv2.putText(output, status_text, (10, 100), 
                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, status_color, 2)
        
        # é¡¯ç¤ºä¿¡å¿ƒåº¦
        cv2.putText(output, f"Confidence: {result['confidence']:.2f}", 
                    (10, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # é¡¯ç¤ºè¨ˆæ•¸
        cv2.putText(output, f"Frames: {self.frame_count}", 
                    (10, 160), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        cv2.putText(output, f"Falls: {self.fall_count}", 
                    (10, 190), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        return output
    
    def run(self):
        """é‹è¡Œè·Œå€’æª¢æ¸¬ç³»çµ±"""
        try:
            # æ‰“é–‹æ”åƒé ­
            logger.info("æ‰“é–‹æ”åƒé ­...")
            cap = cv2.VideoCapture(0)
            
            if not cap.isOpened():
                logger.error("ç„¡æ³•æ‰“é–‹æ”åƒé ­")
                return
            
            logger.info("é–‹å§‹è™•ç†è¦–é »æµ...")
            
            # FPSè¨ˆç®—
            fps_start_time = time.time()
            fps_frame_count = 0
            
            while True:
                # è®€å–å¹€
                ret, frame = cap.read()
                if not ret:
                    logger.error("ç„¡æ³•è®€å–å¹€")
                    break
                
                # è™•ç†å¹€ä¸¦æª¢æ¸¬è·Œå€’
                processed_frame, is_fall = self.process_frame(frame)
                
                # è¨ˆç®—FPS
                fps_frame_count += 1
                elapsed_time = time.time() - fps_start_time
                if elapsed_time >= 1.0:  # æ¯ç§’æ›´æ–°ä¸€æ¬¡FPS
                    self.fps = fps_frame_count / elapsed_time
                    fps_frame_count = 0
                    fps_start_time = time.time()
                
                # é¡¯ç¤ºè™•ç†å¾Œçš„å¹€
                cv2.imshow("Dragon X Fall Detection", processed_frame)
                
                # æª¢æŸ¥é€€å‡ºéµ
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    logger.info("ç”¨æˆ¶è«‹æ±‚é€€å‡º")
                    break
                
                # å®šæœŸæ‰“å°ç‹€æ…‹
                if self.frame_count % 30 == 0:
                    logger.info(f"å·²è™•ç† {self.frame_count} å¹€ï¼ŒFPS: {self.fps:.1f}")
                
        except KeyboardInterrupt:
            logger.info("ç”¨æˆ¶ä¸­æ–·")
        except Exception as e:
            logger.error(f"åŸ·è¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        finally:
            # æ¸…ç†
            if 'cap' in locals() and cap is not None:
                cap.release()
            cv2.destroyAllWindows()
            
            # æ‰“å°æ‘˜è¦
            logger.info("ç³»çµ±åŸ·è¡Œæ‘˜è¦:")
            logger.info(f"  - æ¨¡å‹é¡å‹: {self.model.model_name if self.model.qai_model else ('ONNX' if self.model.onnx_session else 'æ¨¡æ“¬')}")
            logger.info(f"  - è™•ç†å¹€æ•¸: {self.frame_count}")
            logger.info(f"  - æª¢æ¸¬åˆ°çš„è·Œå€’: {self.fall_count}")
            logger.info(f"  - å¹³å‡æ¨è«–æ™‚é–“: {self.avg_inference_time:.1f} ms")
            logger.info(f"  - å¹³å‡FPS: {self.fps:.1f}")
            logger.info("è·Œå€’æª¢æ¸¬ç³»çµ±å·²é—œé–‰")


def check_qai_hub_status():
    """æª¢æŸ¥QAI Hubç‹€æ…‹"""
    print("æª¢æŸ¥QAI Hubç‹€æ…‹...")
    
    # æª¢æŸ¥ç’°å¢ƒè®Šé‡
    api_key = os.environ.get("QAI_API_KEY")
    api_token = os.environ.get("QAI_API_TOKEN")
    qai_host = os.environ.get("QAI_HOST")
    
    print(f"QAI API Key: {'å·²è¨­ç½®' if api_key else 'æœªè¨­ç½®'}")
    print(f"QAI API Token: {'å·²è¨­ç½®' if api_token else 'æœªè¨­ç½®'}")
    print(f"QAI Host: {qai_host if qai_host else 'æœªè¨­ç½®'}")
    
    # å˜—è©¦å°å…¥QAI Hub
    try:
        import qai_hub
        print(f"QAI Hubç‰ˆæœ¬: {qai_hub.__version__}")
        
        # å˜—è©¦é€£æ¥QAI Hub
        try:
            devices = qai_hub.get_devices()
            print(f"æˆåŠŸé€£æ¥QAI Hub! å¯ç”¨è¨­å‚™: {len(devices)}")
            
            # é¡¯ç¤ºå¯ç”¨è¨­å‚™
            for i, device in enumerate(devices[:5]):  # æœ€å¤šé¡¯ç¤º5å€‹è¨­å‚™
                print(f"  è¨­å‚™ {i+1}: {device.name} ({device.type})")
            
            # å˜—è©¦åˆ—å‡ºå¯ç”¨æ¨¡å‹
            try:
                print("\nå˜—è©¦åˆ—å‡ºå¯ç”¨æ¨¡å‹...")
                for model_name in QAI_HUB_MODELS[:3]:  # å˜—è©¦å‰3å€‹æ¨¡å‹
                    try:
                        model = qai_hub.load(model_name)
                        print(f"  æˆåŠŸè¼‰å…¥æ¨¡å‹: {model_name}")
                    except Exception as e:
                        print(f"  ç„¡æ³•è¼‰å…¥æ¨¡å‹ {model_name}: {str(e)}")
            except Exception as e:
                print(f"åˆ—å‡ºæ¨¡å‹æ™‚å‡ºéŒ¯: {e}")
            
            return True
            
        except Exception as e:
            print(f"é€£æ¥QAI Hubå¤±æ•—: {e}")
            return False
            
    except ImportError as e:
        print(f"ç„¡æ³•å°å…¥QAI Hub: {e}")
        return False


def main():
    """ä¸»å‡½æ•¸"""
    print("Dragon X Fall Detection System")
    print("============================")
    
    # æª¢æŸ¥QAI Hubç‹€æ…‹
    print("\n1. æª¢æŸ¥QAI Hubç‹€æ…‹:")
    qai_available = check_qai_hub_status()
    print(f"\n=> QAI Hubç‹€æ…‹: {'å¯ç”¨' if qai_available else 'ä¸å¯ç”¨ï¼Œå°‡ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼'}")
    
    # å•Ÿå‹•è·Œå€’æª¢æ¸¬ç³»çµ±
    print("\n2. å•Ÿå‹•è·Œå€’æª¢æ¸¬ç³»çµ±:")
    print("åˆå§‹åŒ–è·Œå€’æª¢æ¸¬ç³»çµ±...")
    
    try:
        # å‰µå»ºä¸¦é‹è¡Œç³»çµ±
        system = FallDetectionSystem()
        system.run()
    except Exception as e:
        print(f"ç³»çµ±åŸ·è¡Œå¤±æ•—: {e}")


if __name__ == "__main__":
    main()
