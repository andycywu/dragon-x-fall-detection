"""
æ ¼å¼æª¢æŸ¥æ¨¡çµ„ - è² è²¬æ¨¡å‹æ ¼å¼é©—è­‰å’Œæª¢æŸ¥
"""
import onnx
from pathlib import Path
from typing import List, Tuple, Optional, Dict, Any


class FormatChecker:
    """æ¨¡å‹æ ¼å¼æª¢æŸ¥å™¨"""
    
    def __init__(self, base_dir: Optional[Path] = None):
        self.base_dir = base_dir or Path.cwd()
    
    def fix_onnx_value_info(self, onnx_path: Path) -> bool:
        """
        ä¿®å¾© ONNX æ¨¡å‹çš„ value_info é‡è¤‡å•é¡Œ
        
        Args:
            onnx_path: ONNX æ¨¡å‹è·¯å¾‘
            
        Returns:
            æ˜¯å¦ä¿®å¾©æˆåŠŸ
        """
        try:
            model = onnx.load(str(onnx_path))
            io_names = set()
            
            # æ”¶é›†æ‰€æœ‰ input å’Œ output çš„åç¨±
            for t in list(model.graph.input) + list(model.graph.output):
                io_names.add(t.name)
            
            # ç§»é™¤ value_info ä¸­èˆ‡ input/output é‡è¤‡çš„ tensor
            new_value_info = [vi for vi in model.graph.value_info if vi.name not in io_names]
            del model.graph.value_info[:]
            model.graph.value_info.extend(new_value_info)
            
            # å„²å­˜ä¿®å¾©å¾Œçš„æ¨¡å‹
            onnx.save(model, str(onnx_path))
            return True
            
        except Exception as e:
            print(f"ä¿®å¾© value_info å¤±æ•—: {onnx_path.name} | {e}")
            return False
    
    def check_onnx_model(self, onnx_path: Path, full_check: bool = True) -> Optional[str]:
        """
        æª¢æŸ¥ ONNX æ¨¡å‹æ ¼å¼
        
        Args:
            onnx_path: ONNX æ¨¡å‹è·¯å¾‘
            full_check: æ˜¯å¦é€²è¡Œå®Œæ•´æª¢æŸ¥
            
        Returns:
            éŒ¯èª¤è¨Šæ¯ï¼ˆå¦‚æœæª¢æŸ¥å¤±æ•—ï¼‰ï¼Œå¦å‰‡è¿”å› None
        """
        try:
            onnx.checker.check_model(str(onnx_path), full_check=full_check)
            return None
        except onnx.checker.ValidationError as e:
            return str(e)
        except Exception as e:
            return f"æª¢æŸ¥ç•°å¸¸: {str(e)}"
    
    def batch_fix_onnx_models(self, onnx_files: List[Path]) -> List[Tuple[Path, bool]]:
        """
        æ‰¹æ¬¡ä¿®å¾©å¤šå€‹ ONNX æ¨¡å‹
        
        Args:
            onnx_files: ONNX æª”æ¡ˆåˆ—è¡¨
            
        Returns:
            ä¿®å¾©çµæœåˆ—è¡¨ï¼ˆæª”æ¡ˆè·¯å¾‘, æ˜¯å¦æˆåŠŸï¼‰
        """
        results = []
        
        for onnx_path in onnx_files:
            success = self.fix_onnx_value_info(onnx_path)
            results.append((onnx_path, success))
            
            if success:
                print(f"[Auto] ä¿®æ­£ value_info: {onnx_path.name}")
            else:
                print(f"[Warning] ä¿®æ­£ value_info å¤±æ•—: {onnx_path.name}")
        
        return results

    def batch_fix_onnx_value_info(self, onnx_dir: Path) -> List[Tuple[Path, bool]]:
        """
        æ‰¹æ¬¡ä¿®å¾©æŒ‡å®šç›®éŒ„ä¸‹æ‰€æœ‰ ONNX æ¨¡å‹çš„ value_info
        
        Args:
            onnx_dir: ONNX æ¨¡å‹ç›®éŒ„
            
        Returns:
            ä¿®å¾©çµæœåˆ—è¡¨ï¼ˆæª”æ¡ˆè·¯å¾‘, æ˜¯å¦æˆåŠŸï¼‰
        """
        if not onnx_dir.exists():
            print(f"âŒ ONNX ç›®éŒ„ä¸å­˜åœ¨: {onnx_dir}")
            return []
            
        onnx_files = list(onnx_dir.glob('*.onnx'))
        if not onnx_files:
            print(f"âŒ ONNX ç›®éŒ„ä¸­æ²’æœ‰ .onnx æª”æ¡ˆ: {onnx_dir}")
            return []
            
        print(f"ğŸ”„ é–‹å§‹æ‰¹æ¬¡ä¿®å¾© {len(onnx_files)} å€‹ ONNX æª”æ¡ˆçš„ value_info...")
        return self.batch_fix_onnx_models(onnx_files)

    def check_onnx_models(self, qai_hub_models: Dict[str, Any]) -> List[Tuple[str, str, str]]:
        """
        æª¢æŸ¥ QAI Hub æ¨¡å‹å­—å…¸ä¸­çš„æ‰€æœ‰ ONNX æ¨¡å‹
        
        Args:
            qai_hub_models: QAI Hub æ¨¡å‹å­—å…¸
            
        Returns:
            ç•°å¸¸æ¨¡å‹æ¸…å–®ï¼ˆæ¨¡å‹åç¨±, æª”æ¡ˆè·¯å¾‘, éŒ¯èª¤è¨Šæ¯ï¼‰
        """
        invalid = []
        
        for model_name, model_info in qai_hub_models.items():
            if model_info.get('format') == 'onnx' and model_info.get('loaded'):
                path = model_info.get('model_path')
                if path and Path(path).exists():
                    try:
                        error = self.check_onnx_model(Path(path))
                        if error:
                            invalid.append((model_name, path, error))
                    except Exception as e:
                        invalid.append((model_name, path, str(e)))
        
        return invalid
    
    def batch_check_onnx_models(self, onnx_files: List[Path]) -> List[Tuple[Path, Optional[str]]]:
        """
        æ‰¹æ¬¡æª¢æŸ¥å¤šå€‹ ONNX æ¨¡å‹
        
        Args:
            onnx_files: ONNX æª”æ¡ˆåˆ—è¡¨
            
        Returns:
            æª¢æŸ¥çµæœåˆ—è¡¨ï¼ˆæª”æ¡ˆè·¯å¾‘, éŒ¯èª¤è¨Šæ¯ï¼‰
        """
        results = []
        invalid_models = []
        
        for onnx_path in onnx_files:
            error = self.check_onnx_model(onnx_path)
            results.append((onnx_path, error))
            
            if error:
                invalid_models.append((onnx_path.name, onnx_path, error))
                print(f"âŒ ONNX æª¢æŸ¥å¤±æ•—: {onnx_path.name} - {error}")
            else:
                print(f"âœ… ONNX æª¢æŸ¥é€šé: {onnx_path.name}")
        
        return results, invalid_models
    
    def validate_model_support(self, device_attrs: List[str], model_format: str) -> bool:
        """
        é©—è­‰è£ç½®æ˜¯å¦æ”¯æ´ç‰¹å®šæ¨¡å‹æ ¼å¼
        
        Args:
            device_attrs: è£ç½®å±¬æ€§åˆ—è¡¨
            model_format: æ¨¡å‹æ ¼å¼ï¼ˆ'onnx', 'tflite', 'dlc'ï¼‰
            
        Returns:
            æ˜¯å¦æ”¯æ´
        """
        framework_key = f'framework:{model_format}'
        return any(framework_key in attr for attr in device_attrs)
    
    def get_device_support_info(self, device_attrs: List[str]) -> Dict[str, bool]:
        """
        å–å¾—è£ç½®æ”¯æ´æ ¼å¼è³‡è¨Š
        
        Args:
            device_attrs: è£ç½®å±¬æ€§åˆ—è¡¨
            
        Returns:
            æ”¯æ´æ ¼å¼å­—å…¸
        """
        return {
            'onnx': self.validate_model_support(device_attrs, 'onnx'),
            'tflite': self.validate_model_support(device_attrs, 'tflite'),
            'dlc': self.validate_model_support(device_attrs, 'dlc')
        }


# å–®ä¾‹å¯¦ä¾‹
format_checker = FormatChecker()


def fix_onnx_value_info(onnx_path: Path) -> bool:
    """
    å¿«é€Ÿä¿®å¾© ONNX value_info
    
    Args:
        onnx_path: ONNX æ¨¡å‹è·¯å¾‘
        
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    return format_checker.fix_onnx_value_info(onnx_path)


def check_onnx_model(onnx_path: Path) -> Optional[str]:
    """
    å¿«é€Ÿæª¢æŸ¥ ONNX æ¨¡å‹
    
    Args:
        onnx_path: ONNX æ¨¡å‹è·¯å¾‘
        
    Returns:
        éŒ¯èª¤è¨Šæ¯æˆ– None
    """
    return format_checker.check_onnx_model(onnx_path)


def batch_fix_onnx_models(onnx_files: List[Path]) -> List[Tuple[Path, bool]]:
    """
    å¿«é€Ÿæ‰¹æ¬¡ä¿®å¾© ONNX æ¨¡å‹
    
    Args:
        onnx_files: ONNX æª”æ¡ˆåˆ—è¡¨
        
    Returns:
        ä¿®å¾©çµæœ
    """
    return format_checker.batch_fix_onnx_models(onnx_files)


def get_device_support(device_attrs: List[str]) -> Dict[str, bool]:
    """
    å¿«é€Ÿå–å¾—è£ç½®æ”¯æ´è³‡è¨Š
    
    Args:
        device_attrs: è£ç½®å±¬æ€§åˆ—è¡¨
        
    Returns:
        æ”¯æ´æ ¼å¼å­—å…¸
    """
    return format_checker.get_device_support_info(device_attrs)


if __name__ == "__main__":
    # æ¸¬è©¦ç¨‹å¼
    test_dir = Path(__file__).parent.parent.parent / 'models' / 'onnx'
    
    if test_dir.exists():
        onnx_files = list(test_dir.glob('*.onnx'))
        if onnx_files:
            print(f"æ¸¬è©¦æª¢æŸ¥ {len(onnx_files)} å€‹ ONNX æª”æ¡ˆ...")
            results, invalid = format_checker.batch_check_onnx_models(onnx_files)
            
            if invalid:
                print(f"\nç™¼ç¾ {len(invalid)} å€‹ç„¡æ•ˆæ¨¡å‹ï¼š")
                for name, path, error in invalid:
                    print(f"  - {name}: {error}")
            else:
                print("æ‰€æœ‰æ¨¡å‹æª¢æŸ¥é€šéï¼")
        else:
            print("æ¸¬è©¦ç›®éŒ„ä¸­æ²’æœ‰ ONNX æª”æ¡ˆ")
    else:
        print("æ¸¬è©¦ç›®éŒ„ä¸å­˜åœ¨")
