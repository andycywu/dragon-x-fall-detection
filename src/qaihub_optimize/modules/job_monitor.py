"""
ä»»å‹™ç‹€æ…‹ç›£æ§æ¨¡çµ„
è² è²¬ç›£æ§ QAI Hub ä»»å‹™ç‹€æ…‹å’Œé€²åº¦
ä½¿ç”¨ Qualcomm AI Hub å®˜æ–¹ SDK é€²è¡Œç‹€æ…‹æŸ¥è©¢å’Œè¼ªè©¢
"""
import time
import threading
import sys
import os
from pathlib import Path
from typing import Dict, List, Optional, Callable, Any
from datetime import datetime, timedelta

try:
    import qai_hub as hub
    from qai_hub import JobStatus, JobType
    QAI_HUB_AVAILABLE = True
except ImportError:
    QAI_HUB_AVAILABLE = False
    print("âš ï¸  qai_hub å¥—ä»¶æœªå®‰è£ï¼Œå°‡ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")


class JobMonitor:
    """QAI Hub ä»»å‹™ç‹€æ…‹ç›£æ§é¡åˆ¥"""
    
    # å®Œæ•´çš„å®Œæˆç‹€æ…‹åˆ—è¡¨ï¼ˆèˆ‡ qaihub_client.py ä¿æŒä¸€è‡´ï¼‰
    COMPLETED_STATUS = ('COMPLETED', 'SUCCEEDED', 'SUCCESS', 'FINISHED', 
                       'COMPLETED_SUCCESSFULLY', 'RESULTS_READY', 'RESULTS READY', 
                       'results_ready', 'Results Ready')
    
    # éŒ¯èª¤ç‹€æ…‹åˆ—è¡¨
    ERROR_STATUS = ('FAILED', 'ERROR', 'CANCELLED', 'TIMEOUT')
    
    def __init__(self):
        """åˆå§‹åŒ–ä»»å‹™ç›£æ§å™¨"""
        self.monitored_jobs = {}
        self.is_monitoring = False
        self.monitor_thread = None
        self.callbacks = {
            'on_job_start': [],
            'on_job_progress': [],
            'on_job_complete': [],
            'on_job_error': [],
            'on_timeout': []
        }
    
    def add_job(self, job_id: str, job_type: str, model_name: str, 
                timeout: int = 1800, metadata: Optional[Dict] = None):
        """
        æ–°å¢è¦ç›£æ§çš„ä»»å‹™
        
        Args:
            job_id: ä»»å‹™ID
            job_type: ä»»å‹™é¡å‹ ('compile', 'profile')
            model_name: æ¨¡å‹åç¨±
            timeout: è¶…æ™‚æ™‚é–“ï¼ˆç§’ï¼‰
            metadata: é¡å¤–å…ƒæ•¸æ“š
        """
        self.monitored_jobs[job_id] = {
            'job_id': job_id,
            'job_type': job_type,
            'model_name': model_name,
            'status': 'PENDING',
            'start_time': datetime.now(),
            'timeout': timeout,
            'last_check': None,
            'progress': 0,
            'metadata': metadata or {},
            'error': None
        }
        
        # è§¸ç™¼ä»»å‹™é–‹å§‹å›èª¿
        self._trigger_callbacks('on_job_start', self.monitored_jobs[job_id])
    
    def remove_job(self, job_id: str):
        """ç§»é™¤ç›£æ§çš„ä»»å‹™"""
        if job_id in self.monitored_jobs:
            del self.monitored_jobs[job_id]
    
    def update_job_status(self, job_id: str, status: str, progress: int = 0, 
                         error: Optional[str] = None):
        """
        æ›´æ–°ä»»å‹™ç‹€æ…‹
        
        Args:
            job_id: ä»»å‹™ID
            status: ç‹€æ…‹
            progress: é€²åº¦ç™¾åˆ†æ¯” (0-100)
            error: éŒ¯èª¤è¨Šæ¯
        """
        if job_id not in self.monitored_jobs:
            return
        
        job = self.monitored_jobs[job_id]
        old_status = job['status']
        job['status'] = status
        job['progress'] = progress
        job['last_check'] = datetime.now()
        
        if error:
            job['error'] = error
        
        # è§¸ç™¼é€²åº¦å›èª¿
        self._trigger_callbacks('on_job_progress', job)
        
        # æª¢æŸ¥ç‹€æ…‹è®ŠåŒ–
        if old_status != status:
            # ä½¿ç”¨å¤§å°å¯«ä¸æ•æ„Ÿçš„ç‹€æ…‹æª¢æŸ¥
            status_upper = str(status).upper()
            completed_upper = [s.upper() for s in self.COMPLETED_STATUS]
            error_upper = [s.upper() for s in self.ERROR_STATUS]
            
            if status_upper in completed_upper:
                self._trigger_callbacks('on_job_complete', job)
            elif status_upper in error_upper:
                self._trigger_callbacks('on_job_error', job)
    
    def get_job_status(self, job_id: str) -> Optional[Dict]:
        """å–å¾—ä»»å‹™ç‹€æ…‹"""
        return self.monitored_jobs.get(job_id)
    
    def get_all_jobs(self) -> Dict[str, Dict]:
        """å–å¾—æ‰€æœ‰ç›£æ§ä¸­çš„ä»»å‹™"""
        return self.monitored_jobs.copy()
    
    def get_jobs_by_status(self, status: str) -> List[Dict]:
        """æ ¹æ“šç‹€æ…‹ç¯©é¸ä»»å‹™"""
        return [job for job in self.monitored_jobs.values() if job['status'] == status]
    
    def get_jobs_by_type(self, job_type: str) -> List[Dict]:
        """æ ¹æ“šé¡å‹ç¯©é¸ä»»å‹™"""
        return [job for job in self.monitored_jobs.values() if job['job_type'] == job_type]
    
    def register_callback(self, event_type: str, callback: Callable):
        """
        è¨»å†Šå›èª¿å‡½æ•¸
        
        Args:
            event_type: äº‹ä»¶é¡å‹ ('on_job_start', 'on_job_progress', 'on_job_complete', 'on_job_error', 'on_timeout')
            callback: å›èª¿å‡½æ•¸
        """
        if event_type in self.callbacks:
            self.callbacks[event_type].append(callback)
    
    def _trigger_callbacks(self, event_type: str, job_data: Dict):
        """è§¸ç™¼å›èª¿å‡½æ•¸"""
        for callback in self.callbacks.get(event_type, []):
            try:
                callback(job_data)
            except Exception as e:
                print(f"âŒ å›èª¿å‡½æ•¸åŸ·è¡Œå¤±æ•—: {e}")
    
    def start_monitoring(self, interval: int = 10):
        """
        é–‹å§‹ç›£æ§ä»»å‹™
        
        Args:
            interval: æª¢æŸ¥é–“éš”ï¼ˆç§’ï¼‰
        """
        if self.is_monitoring:
            print("âš ï¸ ç›£æ§å·²ç¶“åœ¨åŸ·è¡Œä¸­")
            return
        
        self.is_monitoring = True
        self.monitor_thread = threading.Thread(
            target=self._monitor_loop,
            args=(interval,),
            daemon=True
        )
        self.monitor_thread.start()
        print("âœ… é–‹å§‹ç›£æ§ä»»å‹™ç‹€æ…‹...")
    
    def stop_monitoring(self):
        """åœæ­¢ç›£æ§"""
        self.is_monitoring = False
        if self.monitor_thread and self.monitor_thread.is_alive():
            self.monitor_thread.join(timeout=5)
        print("â¹ï¸ åœæ­¢ç›£æ§ä»»å‹™ç‹€æ…‹")
    
    def _monitor_loop(self, interval: int):
        """ç›£æ§å¾ªç’°"""
        while self.is_monitoring:
            try:
                self._check_jobs_status()
                self._check_timeouts()
                time.sleep(interval)
            except Exception as e:
                print(f"âŒ ç›£æ§å¾ªç’°ç™¼ç”ŸéŒ¯èª¤: {e}")
                time.sleep(interval)  # ç¹¼çºŒåŸ·è¡Œ
    
    def _check_jobs_status(self):
        """æª¢æŸ¥ä»»å‹™ç‹€æ…‹ï¼ˆéœ€è¦å­é¡åˆ¥å¯¦ä½œï¼‰"""
        # é€™å€‹æ–¹æ³•æ‡‰è©²ç”±å…·é«”çš„å¯¦ä½œä¾†è¦†å¯«ï¼Œä¾‹å¦‚ä½¿ç”¨ QAI Hub API æŸ¥è©¢ç‹€æ…‹
        pass
    
    def _check_timeouts(self):
        """æª¢æŸ¥è¶…æ™‚ä»»å‹™"""
        current_time = datetime.now()
        timed_out_jobs = []
        
        for job_id, job in self.monitored_jobs.items():
            # ä½¿ç”¨å¤§å°å¯«ä¸æ•æ„Ÿçš„ç‹€æ…‹æª¢æŸ¥
            status_upper = str(job['status']).upper()
            completed_upper = [s.upper() for s in self.COMPLETED_STATUS]
            error_upper = [s.upper() for s in self.ERROR_STATUS]
            
            if status_upper in completed_upper or status_upper in error_upper:
                continue
            
            elapsed = (current_time - job['start_time']).total_seconds()
            if elapsed > job['timeout']:
                job['status'] = 'TIMEOUT'
                job['error'] = f"ä»»å‹™è¶…æ™‚ ({elapsed:.0f}ç§’ > {job['timeout']}ç§’)"
                timed_out_jobs.append(job)
        
        for job in timed_out_jobs:
            self._trigger_callbacks('on_timeout', job)
    
    def generate_status_report(self) -> str:
        """
        ç”¢ç”Ÿç‹€æ…‹å ±å‘Š
        
        Returns:
            ç‹€æ…‹å ±å‘Šæ–‡å­—
        """
        report_lines = []
        current_time = datetime.now()
        
        report_lines.append(f"ğŸ“Š ä»»å‹™ç‹€æ…‹å ±å‘Š - {current_time.strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append("=" * 60)
        
        # æŒ‰é¡å‹åˆ†çµ„
        compile_jobs = self.get_jobs_by_type('compile')
        profile_jobs = self.get_jobs_by_type('profile')
        
        if compile_jobs:
            report_lines.append("\nğŸ› ï¸ ç·¨è­¯ä»»å‹™:")
            report_lines.append("-" * 40)
            for job in compile_jobs:
                elapsed = (current_time - job['start_time']).total_seconds()
                report_lines.append(
                    f"  {job['model_name']}: {job['status']} "
                    f"(é€²åº¦: {job['progress']}%, è€—æ™‚: {elapsed:.0f}ç§’)"
                )
        
        if profile_jobs:
            report_lines.append("\nğŸ“ˆ åˆ†æä»»å‹™:")
            report_lines.append("-" * 40)
            for job in profile_jobs:
                elapsed = (current_time - job['start_time']).total_seconds()
                report_lines.append(
                    f"  {job['model_name']}: {job['status']} "
                    f"(é€²åº¦: {job['progress']}%, è€—æ™‚: {elapsed:.0f}ç§’)"
                )
        
        # çµ±è¨ˆè³‡è¨Š
        total_jobs = len(self.monitored_jobs)
        completed = len(self.get_jobs_by_status('COMPLETED'))
        failed = len(self.get_jobs_by_status('FAILED')) + len(self.get_jobs_by_status('ERROR'))
        pending = len(self.get_jobs_by_status('PENDING')) + len(self.get_jobs_by_status('RUNNING'))
        
        report_lines.append("\nğŸ“ˆ çµ±è¨ˆè³‡è¨Š:")
        report_lines.append("-" * 40)
        report_lines.append(f"  ç¸½ä»»å‹™æ•¸: {total_jobs}")
        report_lines.append(f"  å·²å®Œæˆ: {completed}")
        report_lines.append(f"  å¤±æ•—: {failed}")
        report_lines.append(f"  é€²è¡Œä¸­: {pending}")
        
        if total_jobs > 0:
            success_rate = (completed / total_jobs) * 100
            report_lines.append(f"  æˆåŠŸç‡: {success_rate:.1f}%")
        
        return "\n".join(report_lines)
    
    def print_status(self):
        """æ‰“å°ç•¶å‰ç‹€æ…‹"""
        print(self.generate_status_report())
    
    def wait_for_completion(self, timeout: Optional[int] = None, 
                          check_interval: int = 10) -> bool:
        """
        ç­‰å¾…æ‰€æœ‰ä»»å‹™å®Œæˆ
        
        Args:
            timeout: ç¸½è¶…æ™‚æ™‚é–“ï¼ˆç§’ï¼‰
            check_interval: æª¢æŸ¥é–“éš”ï¼ˆç§’ï¼‰
            
        Returns:
            æ˜¯å¦æ‰€æœ‰ä»»å‹™éƒ½æˆåŠŸå®Œæˆ
        """
        start_time = time.time()
        
        if not self.is_monitoring:
            self.start_monitoring(check_interval)
        
        print("â³ ç­‰å¾…æ‰€æœ‰ä»»å‹™å®Œæˆ...")
        
        while True:
            # æª¢æŸ¥æ˜¯å¦æ‰€æœ‰ä»»å‹™éƒ½å®Œæˆï¼ˆä½¿ç”¨å¤§å°å¯«ä¸æ•æ„Ÿçš„ç‹€æ…‹æª¢æŸ¥ï¼‰
            all_completed = True
            for job in self.monitored_jobs.values():
                status_upper = str(job['status']).upper()
                completed_upper = [s.upper() for s in self.COMPLETED_STATUS]
                error_upper = [s.upper() for s in self.ERROR_STATUS]
                
                if status_upper not in completed_upper and status_upper not in error_upper:
                    all_completed = False
                    break
            
            if all_completed:
                break
            
            # æª¢æŸ¥ç¸½è¶…æ™‚
            if timeout and (time.time() - start_time) > timeout:
                print("âš ï¸ ç­‰å¾…è¶…æ™‚ï¼Œå¼·åˆ¶çµæŸ")
                break
            
            # æ‰“å°ç•¶å‰ç‹€æ…‹
            self.print_status()
            time.sleep(check_interval)
        
        # æœ€çµ‚ç‹€æ…‹å ±å‘Š
        print("\nğŸ¯ ä»»å‹™å®Œæˆæœ€çµ‚ç‹€æ…‹:")
        self.print_status()
        
        # æª¢æŸ¥æ˜¯å¦æœ‰å¤±æ•—çš„ä»»å‹™
        failed_jobs = []
        for job in self.monitored_jobs.values():
            status_upper = str(job['status']).upper()
            error_upper = [s.upper() for s in self.ERROR_STATUS]
            
            if status_upper in error_upper:
                failed_jobs.append(job)
        
        if failed_jobs:
            print(f"\nâŒ æœ‰ {len(failed_jobs)} å€‹ä»»å‹™å¤±æ•—:")
            for job in failed_jobs:
                print(f"   - {job['model_name']}: {job['status']} - {job.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
            return False
        
        return True

    def wait_for_compile_jobs(self, qai_hub_models: Dict, timeout_minutes: int = 30) -> bool:
        """
        ç­‰å¾…æ‰€æœ‰ç·¨è­¯ä»»å‹™å®Œæˆ
        
        Args:
            qai_hub_models: QAI Hub æ¨¡å‹å­—å…¸
            timeout_minutes: è¶…æ™‚æ™‚é–“ï¼ˆåˆ†é˜ï¼‰
            
        Returns:
            æ˜¯å¦æ‰€æœ‰ç·¨è­¯ä»»å‹™éƒ½æˆåŠŸå®Œæˆ
        """
        print(f"â³ ç­‰å¾…æ‰€æœ‰ç·¨è­¯ä»»å‹™å®Œæˆï¼ˆè¶…æ™‚: {timeout_minutes} åˆ†é˜ï¼‰...")
        
        # å°‡æ‰€æœ‰ç·¨è­¯ä»»å‹™æ·»åŠ åˆ°ç›£æ§å™¨
        for model_name, model_info in qai_hub_models.items():
            compile_job = model_info.get('compile_job')
            if compile_job and hasattr(compile_job, 'job_id'):
                job_id = compile_job.job_id
                if job_id not in self.monitored_jobs:
                    self.add_job(job_id, 'compile', model_name, timeout=timeout_minutes * 60)
        
        # é–‹å§‹ç›£æ§ä¸¦ç­‰å¾…å®Œæˆ
        return self.wait_for_completion(timeout=timeout_minutes * 60, check_interval=15)

    def wait_for_profile_jobs(self, qai_hub_models: Dict, timeout_minutes: int = 30) -> bool:
        """
        ç­‰å¾…æ‰€æœ‰åˆ†æä»»å‹™å®Œæˆ
        
        Args:
            qai_hub_models: QAI Hub æ¨¡å‹å­—å…¸
            timeout_minutes: è¶…æ™‚æ™‚é–“ï¼ˆåˆ†é˜ï¼‰
            
        Returns:
            æ˜¯å¦æ‰€æœ‰åˆ†æä»»å‹™éƒ½æˆåŠŸå®Œæˆ
        """
        print(f"â³ ç­‰å¾…æ‰€æœ‰åˆ†æä»»å‹™å®Œæˆï¼ˆè¶…æ™‚: {timeout_minutes} åˆ†é˜ï¼‰...")
        
        # å°‡æ‰€æœ‰åˆ†æä»»å‹™æ·»åŠ åˆ°ç›£æ§å™¨
        for model_name, model_info in qai_hub_models.items():
            profile_job = model_info.get('profile_job')
            if profile_job and hasattr(profile_job, 'job_id'):
                job_id = profile_job.job_id
                if job_id not in self.monitored_jobs:
                    self.add_job(job_id, 'profile', model_name, timeout=timeout_minutes * 60)
        
        # é–‹å§‹ç›£æ§ä¸¦ç­‰å¾…å®Œæˆ
        return self.wait_for_completion(timeout=timeout_minutes * 60, check_interval=15)

    def generate_compile_report(self, qai_hub_models: Dict, output_file: str) -> bool:
        """
        ç”¢ç”Ÿç·¨è­¯ä»»å‹™HTMLå ±å‘Š
        
        Args:
            qai_hub_models: QAI Hub æ¨¡å‹å­—å…¸
            output_file: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
            
        Returns:
            æ˜¯å¦æˆåŠŸç”¢ç”Ÿå ±å‘Š
        """
        print(f"ğŸ“Š ç”¢ç”Ÿç·¨è­¯ä»»å‹™å ±å‘Š: {output_file}")
        # æš«æ™‚å…ˆè¿”å›æˆåŠŸï¼Œå¯¦éš›å ±å‘ŠåŠŸèƒ½å¾…å¯¦ç¾
        return True

    def generate_profile_report(self, qai_hub_models: Dict, output_file: str) -> bool:
        """
        ç”¢ç”Ÿåˆ†æä»»å‹™HTMLå ±å‘Š
        
        Args:
            qai_hub_models: QAI Hub æ¨¡å‹å­—å…¸
            output_file: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
            
        Returns:
            æ˜¯å¦æˆåŠŸç”¢ç”Ÿå ±å‘Š
        """
        print(f"ğŸ“Š ç”¢ç”Ÿåˆ†æä»»å‹™å ±å‘Š: {output_file}")
        # æš«æ™‚å…ˆè¿”å›æˆåŠŸï¼Œå¯¦éš›å ±å‘ŠåŠŸèƒ½å¾…å¯¦ç¾
        return True


class QAIHubJobMonitor(JobMonitor):
    """QAI Hub å°ˆç”¨çš„ä»»å‹™ç›£æ§å™¨ï¼Œä½¿ç”¨å®˜æ–¹ SDK é€²è¡Œç‹€æ…‹æŸ¥è©¢"""
    
    def __init__(self, qaihub_client):
        """
        åˆå§‹åŒ– QAI Hub ä»»åŠ¡ç›‘æ§å™¨
        
        Args:
            qaihub_client: QAIHubClient å®ä¾‹
        """
        super().__init__()
        self.qaihub_client = qaihub_client
        
        # ä¿®æ­£è·¯å¾„é…ç½®ï¼šç›´æ¥ä½¿ç”¨ qaihub_client çš„ base_dir ä½œä¸ºä¼˜åŒ–æ¨¡å‹ç›®å½•
        # å› ä¸º qaihub_client.base_dir å·²ç»æ˜¯æ­£ç¡®çš„ models ç›®å½•
        self.optimized_models_dir = self.qaihub_client.base_dir / 'qaihub_optimized'
        self.optimized_models_dir.mkdir(parents=True, exist_ok=True)
        print(f"ğŸ“ ä¼˜åŒ–æ¨¡å‹è¾“å‡ºç›®å½•: {self.optimized_models_dir}")
    
    def _check_jobs_status(self):
        """ä½¿ç”¨ QAI Hub SDK æª¢æŸ¥ä»»å‹™ç‹€æ…‹"""
        try:
            for job_id, job_info in self.monitored_jobs.items():
                # å¦‚æœä»»å‹™å·²ç¶“å®Œæˆæˆ–å¤±æ•—ï¼Œè·³éæª¢æŸ¥
                status_upper = str(job_info['status']).upper()
                completed_upper = [s.upper() for s in self.COMPLETED_STATUS]
                error_upper = [s.upper() for s in self.ERROR_STATUS]
                
                if status_upper in completed_upper or status_upper in error_upper:
                    continue
                
                try:
                    # ä½¿ç”¨ QAI Hub SDK å–å¾—ä»»å‹™ç‹€æ…‹
                    if QAI_HUB_AVAILABLE:
                        # å¾ qai_hub_models ä¸­å–å¾—å°æ‡‰çš„ job ç‰©ä»¶
                        model_name = job_info['model_name']
                        job_type = job_info['job_type']
                        
                        qaihub_model = self.qaihub_client.qai_hub_models.get(model_name, {})
                        job = qaihub_model.get(f'{job_type}_job')
                        
                        if job:
                            # åˆ·æ–°ä»»å‹™ç‹€æ…‹ï¼ˆå¦‚æœæ”¯æ´ï¼‰
                            try:
                                if hasattr(job, 'refresh'):
                                    job.refresh()
                                elif hasattr(job, 'get_status'):
                                    # å¦‚æœæ²’æœ‰ refresh æ–¹æ³•ï¼Œä½¿ç”¨ get_status ä¾†æ›´æ–°ç‹€æ…‹
                                    job.get_status()
                            except Exception as refresh_error:
                                print(f"âš ï¸  ç„¡æ³•åˆ·æ–°ä»»å‹™ç‹€æ…‹ {job_id}: {refresh_error}")
                                # ç¹¼çºŒåŸ·è¡Œï¼Œä½¿ç”¨ç¾æœ‰ç‹€æ…‹
                            
                            # å–å¾—ä»»å‹™ç‹€æ…‹
                            status = getattr(job, 'status', None)
                            if hasattr(job, 'get_status'):
                                status = job.get_status()
                            
                            if status:
                                # æ›´æ–°ä»»å‹™ç‹€æ…‹
                                status_code = status.code if hasattr(status, 'code') else str(status)
                                progress = self._get_progress_from_status(status)
                                self.update_job_status(job_id, status_code, progress)
                                
                                # å¦‚æœä»»å‹™å¤±æ•—ï¼Œç²å–è©³ç´°éŒ¯èª¤ä¿¡æ¯
                                error_msg = self._extract_detailed_error_info(job, status, status_code, job_id)
                                
                                # æª¢æŸ¥æ˜¯å¦æ˜¯å¤±æ•—ç‹€æ…‹
                                if status_code.upper() in ['FAILED', 'ERROR'] and error_msg:
                                    self.update_job_status(job_id, status_code, 100, error_msg)
                                    print(f"âŒ ä»»å‹™ {job_id} å¤±æ•—: {error_msg}")
                                elif status_code.upper() in ['FAILED', 'ERROR']:
                                    # å¦‚æœæ²’æœ‰å…·é«”éŒ¯èª¤è¨Šæ¯ï¼Œæä¾›è©³ç´°çš„èª¿è©¦ä¿¡æ¯
                                    error_msg = self._get_comprehensive_error_info(job, status, status_code, job_id)
                                    self.update_job_status(job_id, status_code, 100, error_msg)
                                    print(f"âŒ ä»»å‹™ {job_id} å¤±æ•—: {error_msg}")
                                
                                # å¦‚æœä»»å‹™æˆåŠŸå®Œæˆï¼Œä¸‹è¼‰å„ªåŒ–å¾Œçš„æ¨¡å‹
                                if hasattr(status, 'success') and status.success:
                                    print(f"âœ… ä»»å‹™ {job_id} æˆåŠŸå®Œæˆï¼Œé–‹å§‹ä¸‹è¼‰å„ªåŒ–æ¨¡å‹...")
                                    self._download_optimized_model(job_id, job_info)
                                elif hasattr(status, 'code') and str(status.code).upper() in ['SUCCESS', 'COMPLETED']:
                                    print(f"âœ… ä»»å‹™ {job_id} æˆåŠŸå®Œæˆï¼Œé–‹å§‹ä¸‹è¼‰å„ªåŒ–æ¨¡å‹...")
                                    self._download_optimized_model(job_id, job_info)
                                elif hasattr(status, 'code') and str(status.code).upper() in ['SUCCEEDED', 'FINISHED']:
                                    print(f"âœ… ä»»å‹™ {job_id} æˆåŠŸå®Œæˆï¼Œé–‹å§‹ä¸‹è¼‰å„ªåŒ–æ¨¡å‹...")
                                    self._download_optimized_model(job_id, job_info)
                                else:
                                    # æ·»åŠ èª¿è©¦ä¿¡æ¯
                                    print(f"ğŸ’¡ ä»»å‹™ç‹€æ…‹èª¿è©¦: job_id={job_id}, status_code={status_code}, has_success={hasattr(status, 'success')}")
                                    if hasattr(status, 'success'):
                                        print(f"ğŸ’¡ status.success = {status.success}")
                                    if hasattr(status, 'code'):
                                        print(f"ğŸ’¡ status.code = {status.code}")
                        else:
                            # å¦‚æœæ‰¾ä¸åˆ° job ç‰©ä»¶ï¼Œå˜—è©¦ä½¿ç”¨ hub.get_job
                            try:
                                job = hub.get_job(job_id)
                                status = job.get_status()
                                
                                # æ›´æ–°ä»»å‹™ç‹€æ…‹
                                self.update_job_status(job_id, status.code, self._get_progress_from_status(status))
                                
                                # å¦‚æœä»»å‹™å¤±æ•—ï¼Œç²å–è©³ç´°éŒ¯èª¤ä¿¡æ¯
                                if hasattr(status, 'error') and status.error:
                                    error_msg = f"QAI Hub Error: {status.error}"
                                    self.update_job_status(job_id, status.code, 100, error_msg)
                                    print(f"âŒ ä»»å‹™ {job_id} å¤±æ•—: {status.error}")
                                
                                # å¦‚æœä»»å‹™æˆåŠŸå®Œæˆï¼Œä¸‹è¼‰å„ªåŒ–å¾Œçš„æ¨¡å‹
                                if status.success:
                                    print(f"âœ… ä»»å‹™ {job_id} æˆåŠŸå®Œæˆï¼Œé–‹å§‹ä¸‹è¼‰å„ªåŒ–æ¨¡å‹...")
                                    self._download_optimized_model(job_id, job_info)
                                elif hasattr(status, 'code') and str(status.code).upper() in ['SUCCESS', 'COMPLETED', 'SUCCEEDED', 'FINISHED']:
                                    print(f"âœ… ä»»å‹™ {job_id} æˆåŠŸå®Œæˆï¼Œé–‹å§‹ä¸‹è¼‰å„ªåŒ–æ¨¡å‹...")
                                    self._download_optimized_model(job_id, job_info)
                            except Exception as get_job_error:
                                print(f"âŒ ç„¡æ³•å–å¾—ä»»å‹™ {job_id}: {get_job_error}")
                                self.update_job_status(job_id, 'ERROR', 0, f"ç„¡æ³•å–å¾—ä»»å‹™: {get_job_error}")
                    else:
                        # æ¨¡æ“¬æ¨¡å¼ï¼šä½¿ç”¨èˆŠçš„æª¢æŸ¥æ–¹å¼
                        self._check_job_status_legacy(job_id, job_info)
                        
                except Exception as e:
                    print(f"âŒ æª¢æŸ¥ä»»å‹™ç‹€æ…‹å¤±æ•— {job_id}: {e}")
                    self.update_job_status(job_id, 'ERROR', 0, str(e))
        
        except Exception as e:
            print(f"âŒ ç›£æ§å¾ªç’°ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def _check_job_status_legacy(self, job_id: str, job_info: Dict):
        """èˆŠçš„ä»»å‹™ç‹€æ…‹æª¢æŸ¥æ–¹æ³•ï¼ˆç”¨æ–¼æ¨¡æ“¬æ¨¡å¼ï¼‰"""
        job_type = job_info['job_type']
        model_name = job_info['model_name']
        
        # å¾ qaihub_client å–å¾—å°æ‡‰çš„ job
        qaihub_model = self.qaihub_client.qai_hub_models.get(model_name, {})
        job = qaihub_model.get(f'{job_type}_job')
        
        if job:
            # åˆ·æ–°ç‹€æ…‹
            if hasattr(job, 'refresh'):
                job.refresh()
            
            status = getattr(job, 'status', None) or getattr(job, 'state', None)
            progress = self._estimate_progress(status)
            
            self.update_job_status(job_id, str(status), progress)
    
    def _get_progress_from_status(self, status) -> int:
        """
        æ ¹æ“š QAI Hub JobStatus ä¼°è¨ˆé€²åº¦ç™¾åˆ†æ¯”
        
        Args:
            status: JobStatus ç‰©ä»¶
            
        Returns:
            é€²åº¦ç™¾åˆ†æ¯” (0-100)
        """
        if not QAI_HUB_AVAILABLE:
            return self._estimate_progress(status.code if hasattr(status, 'code') else str(status))
        
        # æ ¹æ“š QAI Hub å®˜æ–¹ç‹€æ…‹æ˜ å°„é€²åº¦
        progress_map = {
            'UNSPECIFIED': 0,
            'CREATED': 10,
            'OPTIMIZING_MODEL': 30,
            'PROVISIONING_DEVICE': 50,
            'MEASURING_PERFORMANCE': 70,
            'RUNNING_INFERENCE': 80,
            'QUANTIZING_MODEL': 90,
            'LINKING_MODELS': 95,
            'SUCCESS': 100,
            'FAILED': 100
        }
        
        status_code = status.code if hasattr(status, 'code') else str(status)
        return progress_map.get(status_code, 0)
    
    def _download_optimized_model(self, job_id: str, job_info: Dict):
        """
        ä¸‹è¼‰å„ªåŒ–å¾Œçš„æ¨¡å‹åˆ°æœ¬åœ°
        
        Args:
            job_id: ä»»å‹™ID
            job_info: ä»»å‹™è³‡è¨Š
        """
        if not QAI_HUB_AVAILABLE:
            print(f"âš ï¸  QAI Hub SDK ä¸å¯ç”¨ï¼Œç„¡æ³•ä¸‹è¼‰å„ªåŒ–æ¨¡å‹ {job_id}")
            return
        
        try:
            model_name = job_info['model_name']
            job_type = job_info['job_type']
            
            print(f"ğŸ” é–‹å§‹ä¸‹è¼‰å„ªåŒ–æ¨¡å‹: job_id={job_id}, model={model_name}, type={job_type}")
            
            # é¦–å…ˆå˜—è©¦å¾ qai_hub_models ä¸­å–å¾— job ç‰©ä»¶
            qaihub_model = self.qaihub_client.qai_hub_models.get(model_name, {})
            job = qaihub_model.get(f'{job_type}_job')
            
            # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå˜—è©¦ä½¿ç”¨ hub.get_job
            if not job:
                print(f"ğŸ” å¾ qai_hub_models æ‰¾ä¸åˆ° jobï¼Œå˜—è©¦ä½¿ç”¨ hub.get_job({job_id})")
                try:
                    job = hub.get_job(job_id)
                    print(f"âœ… æˆåŠŸä½¿ç”¨ hub.get_job å–å¾—ä»»å‹™: {job_id}")
                except Exception as get_job_error:
                    print(f"âŒ ç„¡æ³•å–å¾—ä»»å‹™ {job_id}: {get_job_error}")
                    return
            
            # ä½¿ç”¨ QAI Hub æä¾›çš„ç°¡å–®ä¸‹è¼‰ API
            if job_type == 'compile':
                print(f"ğŸ’¾ ä½¿ç”¨ QAI Hub download_target_model() ä¸‹è¼‰å„ªåŒ–æ¨¡å‹...")
                
                # ç¢ºä¿ç›®éŒ„å­˜åœ¨
                self.optimized_models_dir.mkdir(parents=True, exist_ok=True)
                print(f"ğŸ“ ç¢ºä¿ç›®éŒ„å­˜åœ¨: {self.optimized_models_dir}")
                
                # ä½¿ç”¨ job ID ä½œç‚ºå‰ç¶´ç”Ÿæˆæª”æ¡ˆåç¨±ï¼ˆQAI Hub å¯èƒ½æœƒä¸‹è¼‰ç‚º zip æ–‡ä»¶ï¼‰
                temp_filename = f"{job_id}_{model_name}_optimized.zip"
                temp_path = self.optimized_models_dir / temp_filename
                
                # æœ€çµ‚çš„æª”æ¡ˆåç¨±ï¼ˆä¿æŒåŸå§‹åç¨±ï¼ŒåªåŠ  job ID å‰ç¶´ï¼‰
                final_filename = f"{job_id}_{model_name}_optimized.onnx"
                final_path = self.optimized_models_dir / final_filename
                
                try:
                    # ä½¿ç”¨ download_target_model() æ–¹æ³•ï¼Œå®ƒæœƒè‡ªå‹•é˜»å¡ç›´åˆ°ä»»å‹™å®Œæˆ
                    if hasattr(job, 'download_target_model'):
                        print(f"â¬‡ï¸  é–‹å§‹ä¸‹è¼‰ç›®æ¨™æ¨¡å‹åˆ°è‡¨æ™‚æª”æ¡ˆ: {temp_path}")
                        job.download_target_model(temp_path)
                        print(f"âœ… æ¨¡å‹ä¸‹è¼‰å®Œæˆ: {temp_path}")
                    elif hasattr(job, 'download_results'):
                        print(f"â¬‡ï¸  é–‹å§‹ä¸‹è¼‰çµæœåˆ°è‡¨æ™‚æª”æ¡ˆ: {temp_path}")
                        job.download_results(temp_path)
                        print(f"âœ… æ¨¡å‹ä¸‹è¼‰å®Œæˆ: {temp_path}")
                    else:
                        print(f"âŒ job ç‰©ä»¶ä¸æ”¯æ´ download_target_model æˆ– download_results æ–¹æ³•")
                        job_info['error'] = "ä¸æ”¯æ´çš„ job ä¸‹è¼‰æ–¹æ³•"
                        return
                    
                    # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
                    if temp_path.exists():
                        file_size = temp_path.stat().st_size
                        print(f"ğŸ“Š ä¸‹è¼‰æª”æ¡ˆå¤§å°: {file_size} bytes")
                        
                        # è™•ç†ä¸‹è¼‰çš„æª”æ¡ˆï¼ˆå¯èƒ½æ˜¯ zip æˆ– onnxï¼‰
                        print(f"ğŸ’¡ é–‹å§‹è™•ç†ä¸‹è¼‰æª”æ¡ˆ: temp_path={temp_path}, final_path={final_path}")
                        process_result = self._process_downloaded_file(temp_path, final_path, model_name)
                        if process_result:
                            print(f"âœ… æ¨¡å‹è™•ç†å®Œæˆ: {final_path}")
                            
                            # æ›´æ–°ä»»å‹™è³‡è¨Šå’Œ qai_hub_models å­—å…¸
                            job_info['optimized_model_path'] = str(final_path)
                            job_info['optimized_model_downloaded'] = True
                            
                            # åŒæ™‚æ›´æ–° qaihub_client ä¸­çš„æ¨¡å‹è³‡è¨Š
                            if hasattr(self.qaihub_client, 'qai_hub_models'):
                                if model_name in self.qaihub_client.qai_hub_models:
                                    self.qaihub_client.qai_hub_models[model_name]['optimized_model_path'] = str(final_path)
                                    self.qaihub_client.qai_hub_models[model_name]['optimized_model_downloaded'] = True
                                    print(f"ğŸ“ å·²æ›´æ–° {model_name} çš„ä¸‹è¼‰ç‹€æ…‹åˆ° qai_hub_models")
                            
                            # è§¸ç™¼ä¸‹è¼‰å®Œæˆå›èª¿
                            self._trigger_callbacks('on_job_complete', job_info)
                            print(f"ğŸ‰ å„ªåŒ–æ¨¡å‹ä¸‹è¼‰å’Œè™•ç†æˆåŠŸå®Œæˆ!")
                        else:
                            print(f"âŒ æª”æ¡ˆè™•ç†å¤±æ•—")
                            job_info['error'] = f"ä¸‹è¼‰å®Œæˆä½†æª”æ¡ˆè™•ç†å¤±æ•—"
                            # æ·»åŠ è©³ç´°èª¿è©¦ä¿¡æ¯
                            print(f"ğŸ’¡ èª¿è©¦ä¿¡æ¯: temp_path={temp_path}, final_path={final_path}")
                            actual_files = list(temp_path.parent.glob(f"*{model_name}*optimized*"))
                            print(f"ğŸ’¡ æ‰¾åˆ°çš„å¯¦éš›æª”æ¡ˆ: {[f.name for f in actual_files]}")
                            # æª¢æŸ¥æ‰€æœ‰å¯èƒ½çš„æª”æ¡ˆ
                            all_files = list(temp_path.parent.glob('*'))
                            print(f"ğŸ’¡ ç›®éŒ„ä¸­çš„æ‰€æœ‰æª”æ¡ˆ: {[f.name for f in all_files]}")
                            # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
                            print(f"ğŸ’¡ temp_path æ˜¯å¦å­˜åœ¨: {temp_path.exists()}")
                            if temp_path.exists():
                                print(f"ğŸ’¡ temp_path æª”æ¡ˆå¤§å°: {temp_path.stat().st_size} bytes")
                    else:
                        print(f"âŒ æª”æ¡ˆä¸å­˜åœ¨: {temp_path}")
                        job_info['error'] = f"ä¸‹è¼‰å®Œæˆä½†æª”æ¡ˆä¸å­˜åœ¨: {temp_path}"
                        # æª¢æŸ¥å¯¦éš›ä¸‹è¼‰çš„æª”æ¡ˆåç¨±
                        actual_files = list(self.optimized_models_dir.glob(f"*{job_id}*{model_name}*optimized*"))
                        print(f"ğŸ’¡ å¯¦éš›æ‰¾åˆ°çš„æª”æ¡ˆ: {[f.name for f in actual_files]}")
                        if actual_files:
                            print(f"ğŸ’¡ å¯¦éš›æª”æ¡ˆè·¯å¾‘: {actual_files[0]}")
                            print(f"ğŸ’¡ å¯¦éš›æª”æ¡ˆå¤§å°: {actual_files[0].stat().st_size} bytes")
                            # å˜—è©¦ä½¿ç”¨å¯¦éš›æª”æ¡ˆåç¨±
                            actual_file = actual_files[0]
                            print(f"ğŸ’¡ å˜—è©¦ä½¿ç”¨å¯¦éš›æª”æ¡ˆ: {actual_file}")
                            process_result = self._process_downloaded_file(actual_file, final_path, model_name)
                            if process_result:
                                print(f"âœ… ä½¿ç”¨å¯¦éš›æª”æ¡ˆè™•ç†æˆåŠŸ: {final_path}")
                                job_info['optimized_model_path'] = str(final_path)
                                job_info['optimized_model_downloaded'] = True
                                self._trigger_callbacks('on_job_complete', job_info)
                                print(f"ğŸ‰ å„ªåŒ–æ¨¡å‹ä¸‹è¼‰å’Œè™•ç†æˆåŠŸå®Œæˆ!")
                        
                except Exception as download_error:
                    print(f"âŒ ä¸‹è¼‰å¤±æ•—: {download_error}")
                    job_info['error'] = f"ä¸‹è¼‰å¤±æ•—: {download_error}"
                    # å˜—è©¦è¨˜éŒ„è©³ç´°éŒ¯èª¤ä¿¡æ¯
                    import traceback
                    error_details = traceback.format_exc()
                    print(f"è©³ç´°éŒ¯èª¤å †ç–Š:\n{error_details}")
            
        except Exception as e:
            print(f"âŒ ä¸‹è¼‰å„ªåŒ–æ¨¡å‹å¤±æ•— {job_id}: {e}")
            # å˜—è©¦è¨˜éŒ„è©³ç´°éŒ¯èª¤ä¿¡æ¯
            import traceback
            error_details = traceback.format_exc()
            print(f"è©³ç´°éŒ¯èª¤å †ç–Š:\n{error_details}")
    
    def _process_downloaded_file(self, temp_path: Path, final_path: Path, model_name: str) -> bool:
        """
        è™•ç†ä¸‹è¼‰çš„æª”æ¡ˆï¼Œå¯èƒ½æ˜¯ zip æ–‡ä»¶æˆ–ç›´æ¥çš„ onnx æ–‡ä»¶
        
        Args:
            temp_path: è‡¨æ™‚ä¸‹è¼‰æª”æ¡ˆè·¯å¾‘
            final_path: æœ€çµ‚ onnx æª”æ¡ˆè·¯å¾‘
            model_name: æ¨¡å‹åç¨±
            
        Returns:
            è™•ç†æ˜¯å¦æˆåŠŸ
        """
        try:
            # QAI Hub ä¸‹è¼‰çš„æ–‡ä»¶åæ ¼å¼ç‚º {job_id}_{model_name}_optimized.zip.onnx.zip
            # æˆ‘å€‘éœ€è¦æ‰¾åˆ°å¯¦éš›ä¸‹è¼‰çš„æ–‡ä»¶ï¼ˆå¯èƒ½èˆ‡ temp_path åç¨±ä¸å®Œå…¨ç›¸åŒï¼‰
            actual_files = list(temp_path.parent.glob(f"*{model_name}*optimized*"))
            
            if not actual_files:
                print(f"âŒ æ‰¾ä¸åˆ°å¯¦éš›ä¸‹è¼‰çš„æª”æ¡ˆï¼Œé æœŸåŒ…å«: {model_name}_optimized")
                # åˆ—å‡ºç›®éŒ„ä¸­çš„æ‰€æœ‰æª”æ¡ˆä¾†èª¿è©¦
                all_files = list(temp_path.parent.glob('*'))
                print(f"ğŸ’¡ ç›®éŒ„ä¸­çš„æ‰€æœ‰æª”æ¡ˆ: {[f.name for f in all_files]}")
                return False
            
            # ä½¿ç”¨å¯¦éš›ä¸‹è¼‰çš„æª”æ¡ˆ
            actual_file = actual_files[0]
            print(f"ğŸ“ å¯¦éš›ä¸‹è¼‰æª”æ¡ˆ: {actual_file.name}")
            print(f"ğŸ’¡ æª”æ¡ˆå®Œæ•´è·¯å¾‘: {actual_file}")
            print(f"ğŸ’¡ æª”æ¡ˆå¤§å°: {actual_file.stat().st_size} bytes")
            
            # æª¢æŸ¥æª”æ¡ˆé¡å‹ - QAI Hub ä¸‹è¼‰çš„æ˜¯ .zip.onnx.zip æ–‡ä»¶
            if actual_file.suffix.lower() == '.zip' or '.zip' in actual_file.suffixes:
                print(f"ğŸ“¦ æª¢æ¸¬åˆ° ZIP æ–‡ä»¶ï¼Œé–‹å§‹è§£å£“ç¸®...")
                
                # å°å…¥ zipfile æ¨¡çµ„
                import zipfile
                
                # å‰µå»ºè‡¨æ™‚è§£å£“ç¸®ç›®éŒ„
                extract_dir = actual_file.parent / f"{model_name}_extracted"
                extract_dir.mkdir(exist_ok=True)
                
                # è§£å£“ç¸®æ–‡ä»¶
                with zipfile.ZipFile(actual_file, 'r') as zip_ref:
                    zip_ref.extractall(extract_dir)
                
                print(f"âœ… è§£å£“ç¸®å®Œæˆåˆ°: {extract_dir}")
                
                # å°‹æ‰¾è§£å£“ç¸®å¾Œçš„ onnx æ–‡ä»¶
                onnx_files = list(extract_dir.glob('**/*.onnx'))
                
                if onnx_files:
                    # æ‰¾åˆ° onnx æ–‡ä»¶ï¼Œç§»å‹•åˆ°æœ€çµ‚ä½ç½®
                    first_onnx = onnx_files[0]
                    print(f"ğŸ” æ‰¾åˆ° ONNX æ–‡ä»¶: {first_onnx}")
                    
                    # ç§»å‹•æ–‡ä»¶åˆ°æœ€çµ‚ä½ç½®
                    import shutil
                    shutil.move(str(first_onnx), str(final_path))
                    print(f"âœ… ç§»å‹• ONNX æ–‡ä»¶åˆ°: {final_path}")
                    
                    # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
                    try:
                        shutil.rmtree(extract_dir)
                        actual_file.unlink()
                        print(f"ğŸ§¹ æ¸…ç†è‡¨æ™‚æ–‡ä»¶å®Œæˆ")
                    except Exception as cleanup_error:
                        print(f"âš ï¸  æ¸…ç†è‡¨æ™‚æ–‡ä»¶å¤±æ•—: {cleanup_error}")
                    
                    return True
                else:
                    print(f"âŒ åœ¨ ZIP æ–‡ä»¶ä¸­æ‰¾ä¸åˆ° ONNX æ–‡ä»¶")
                    # æª¢æŸ¥æ˜¯å¦æœ‰å…¶ä»–å¯èƒ½çš„æ¨¡å‹æ–‡ä»¶
                    all_files = list(extract_dir.glob('**/*'))
                    print(f"ğŸ“‹ è§£å£“ç¸®æ–‡ä»¶åˆ—è¡¨: {[f.name for f in all_files]}")
                    
                    # å¦‚æœæ²’æœ‰æ‰¾åˆ° ONNX æ–‡ä»¶ï¼Œä½† ZIP æ–‡ä»¶å­˜åœ¨ï¼Œç›´æ¥ä½¿ç”¨ ZIP æ–‡ä»¶
                    print(f"ğŸ“¦ ç›´æ¥ä½¿ç”¨ ZIP æ–‡ä»¶ä½œç‚ºå„ªåŒ–æ¨¡å‹")
                    import shutil
                    shutil.move(str(actual_file), str(final_path))
                    print(f"âœ… ç§»å‹• ZIP æ–‡ä»¶åˆ°: {final_path}")
                    return True
            
            elif actual_file.suffix.lower() == '.onnx' or '.onnx' in actual_file.suffixes:
                print(f"ğŸ“„ æª¢æ¸¬åˆ° ONNX æ–‡ä»¶ï¼Œç›´æ¥é‡å‘½å...")
                
                # ç›´æ¥é‡å‘½åæ–‡ä»¶
                import shutil
                shutil.move(str(actual_file), str(final_path))
                print(f"âœ… é‡å‘½åå®Œæˆ: {final_path}")
                return True
            
            else:
                print(f"â“ æœªçŸ¥æ–‡ä»¶é¡å‹: {actual_file.suffix}")
                print(f"ğŸ“‹ å˜—è©¦ç›´æ¥é‡å‘½åç‚º ONNX æ–‡ä»¶...")
                
                # å˜—è©¦ç›´æ¥é‡å‘½åç‚º onnx æ–‡ä»¶
                import shutil
                shutil.move(str(actual_file), str(final_path))
                print(f"âœ… é‡å‘½åå®Œæˆ: {final_path}")
                return True
                
        except Exception as e:
            print(f"âŒ æ–‡ä»¶è™•ç†å¤±æ•—: {e}")
            import traceback
            error_details = traceback.format_exc()
            print(f"è©³ç´°éŒ¯èª¤å †ç–Š:\n{error_details}")
            return False
    
    def _estimate_progress(self, status: str) -> int:
        """
        æ ¹æ“šç‹€æ…‹ä¼°è¨ˆé€²åº¦ç™¾åˆ†æ¯”ï¼ˆå‚™ç”¨æ–¹æ³•ï¼‰
        
        Args:
            status: ä»»å‹™ç‹€æ…‹
            
        Returns:
            é€²åº¦ç™¾åˆ†æ¯” (0-100)
        """
        status = str(status).upper()
        
        progress_map = {
            'PENDING': 0,
            'QUEUED': 10,
            'RUNNING': 50,
            'PROCESSING': 70,
            'COMPLETED': 100,
            'SUCCEEDED': 100,
            'SUCCESS': 100,
            'FINISHED': 100,
            'COMPLETED_SUCCESSFULLY': 100,
            'RESULTS_READY': 100,
            'RESULTS READY': 100,
            'FAILED': 100,
            'ERROR': 100,
            'CANCELLED': 100,
            'TIMEOUT': 100
        }
        
        for key, value in progress_map.items():
            if key in status:
                return value
        
        return 0  # æœªçŸ¥ç‹€æ…‹
    
    def get_running_jobs(self, limit: int = 50) -> List[Dict]:
        """
        å–å¾—åŸ·è¡Œä¸­çš„ä»»å‹™åˆ—è¡¨
        
        Args:
            limit: æœ€å¤§è¿”å›æ•¸é‡
            
        Returns:
            åŸ·è¡Œä¸­ä»»å‹™åˆ—è¡¨
        """
        if not QAI_HUB_AVAILABLE:
            print("âš ï¸  QAI Hub SDK ä¸å¯ç”¨ï¼Œç„¡æ³•å–å¾—åŸ·è¡Œä¸­ä»»å‹™åˆ—è¡¨")
            return []
        
        try:
            running_states = JobStatus.all_running_states() if hasattr(JobStatus, 'all_running_states') else []
            jobs = hub.get_job_summaries(state=running_states, limit=limit)
            
            result = []
            for js in jobs:
                result.append({
                    'job_id': js.job_id,
                    'name': js.name,
                    'status': js.status.code if hasattr(js.status, 'code') else str(js.status),
                    'job_type': js.job_type if hasattr(js, 'job_type') else 'unknown',
                    'url': js.url if hasattr(js, 'url') else ''
                })
            
            return result
            
        except Exception as e:
            print(f"âŒ å–å¾—åŸ·è¡Œä¸­ä»»å‹™åˆ—è¡¨å¤±æ•—: {e}")
            return []
    
    def wait_for_job_completion(self, job_id: str, timeout: Optional[int] = None) -> str:
        """
        ç­‰å¾…å–®ä¸€ä»»å‹™å®Œæˆ
        
        Args:
            job_id: ä»»å‹™ID
            timeout: è¶…æ™‚æ™‚é–“ï¼ˆç§’ï¼‰
            
        Returns:
            æœ€çµ‚ç‹€æ…‹ ('SUCCESS' æˆ– 'FAILED')
        """
        if not QAI_HUB_AVAILABLE:
            print("âš ï¸  QAI Hub SDK ä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ“¬ç­‰å¾…")
            return self._wait_for_job_completion_legacy(job_id, timeout)
        
        try:
            job = hub.get_job(job_id)
            final_status = job.wait(timeout=timeout)
            return final_status
            
        except Exception as e:
            print(f"âŒ ç­‰å¾…ä»»å‹™å®Œæˆå¤±æ•— {job_id}: {e}")
            return 'FAILED'
    
    def _extract_detailed_error_info(self, job, status, status_code: str, job_id: str) -> Optional[str]:
        """
        å¾ Job å’Œ Status ç‰©ä»¶ä¸­æå–è©³ç´°çš„éŒ¯èª¤ä¿¡æ¯
        
        Args:
            job: QAI Hub Job ç‰©ä»¶
            status: QAI Hub Status ç‰©ä»¶
            status_code: ç‹€æ…‹ä»£ç¢¼
            job_id: ä»»å‹™ID
            
        Returns:
            éŒ¯èª¤è¨Šæ¯å­—ä¸²ï¼Œå¦‚æœæ‰¾ä¸åˆ°å‰‡è¿”å› None
        """
        error_msg = None
        
        # æ¨™æº–éŒ¯èª¤å±¬æ€§æª¢æŸ¥
        if hasattr(status, 'error') and status.error:
            error_msg = f"QAI Hub Error: {status.error}"
        elif hasattr(job, 'error') and job.error:
            error_msg = f"QAI Hub Job Error: {job.error}"
        elif hasattr(job, 'failure_reason') and job.failure_reason:
            error_msg = f"QAI Hub Failure: {job.failure_reason}"
        elif hasattr(job, 'status_message') and job.status_message:
            error_msg = f"QAI Hub Status: {job.status_message}"
        
        # å¦‚æœæ¨™æº–å±¬æ€§æ²’æœ‰éŒ¯èª¤ä¿¡æ¯ï¼Œå˜—è©¦å…¶ä»–æ–¹æ³•
        if not error_msg and status_code.upper() in ['FAILED', 'ERROR']:
            # å˜—è©¦å¾ Job ç‰©ä»¶çš„å…¶ä»–å±¬æ€§ä¸­å°‹æ‰¾éŒ¯èª¤ä¿¡æ¯
            job_attrs_to_check = [
                'failure_details', 'details', 'metadata', 'error_message',
                'error_info', 'failure_info', 'status_details'
            ]
            
            for attr in job_attrs_to_check:
                if hasattr(job, attr):
                    value = getattr(job, attr)
                    if value is not None and str(value).strip() and str(value).strip() != 'None':
                        error_msg = f"QAI Hub {attr}: {value}"
                        break
        
        return error_msg
    
    def _get_comprehensive_error_info(self, job, status, status_code: str, job_id: str) -> str:
        """
        ç²å–å…¨é¢çš„éŒ¯èª¤ä¿¡æ¯ï¼ŒåŒ…æ‹¬èª¿è©¦å»ºè­°
        
        Args:
            job: QAI Hub Job ç‰©ä»¶
            status: QAI Hub Status ç‰©ä»¶
            status_code: ç‹€æ…‹ä»£ç¢¼
            job_id: ä»»å‹™ID
            
        Returns:
            å®Œæ•´çš„éŒ¯èª¤è¨Šæ¯å­—ä¸²
        """
        # é¦–å…ˆå˜—è©¦æ¨™æº–éŒ¯èª¤æå–
        error_msg = self._extract_detailed_error_info(job, status, status_code, job_id)
        
        if error_msg:
            return error_msg
        
        # å¦‚æœæ²’æœ‰æ¨™æº–éŒ¯èª¤ä¿¡æ¯ï¼Œæä¾›è©³ç´°çš„èª¿è©¦ä¿¡æ¯
        debug_info = []
        
        # æ·»åŠ  Job åŸºæœ¬è³‡è¨Š
        debug_info.append(f"Job ID: {job_id}")
        debug_info.append(f"Status Code: {status_code}")
        
        # æ·»åŠ  Job ç‰©ä»¶çš„å¯ç”¨å±¬æ€§
        if hasattr(job, 'name'):
            debug_info.append(f"Job Name: {job.name}")
        if hasattr(job, 'device_name'):
            debug_info.append(f"Device: {job.device_name}")
        if hasattr(job, 'url'):
            debug_info.append(f"Web URL: {job.url}")
        
        # æ·»åŠ æ™‚é–“è³‡è¨Š
        if hasattr(job, 'date'):
            debug_info.append(f"Date: {job.date}")
        
        # æä¾›èª¿è©¦å»ºè­°
        debug_info.append("")
        debug_info.append("ğŸ’¡ èª¿è©¦å»ºè­°:")
        debug_info.append("1. æª¢æŸ¥ QAI Hub Web ç•Œé¢ç²å–è©³ç´°éŒ¯èª¤ä¿¡æ¯")
        debug_info.append("2. ç¢ºèªæ¨¡å‹æ ¼å¼å’Œå…¼å®¹æ€§")
        debug_info.append("3. æª¢æŸ¥ç›®æ¨™è¨­å‚™çš„æ”¯æ´æƒ…æ³")
        debug_info.append("4. é©—è­‰æ¨¡å‹è¼¸å…¥è¼¸å‡ºæ ¼å¼")
        
        if hasattr(job, 'url'):
            debug_info.append(f"5. æŸ¥çœ‹è©³ç´°éŒ¯èª¤: {job.url}")
        
        return "\n".join(debug_info)
    
    def _wait_for_job_completion_legacy(self, job_id: str, timeout: Optional[int] = None) -> str:
        """èˆŠçš„ç­‰å¾…ä»»å‹™å®Œæˆæ–¹æ³•ï¼ˆç”¨æ–¼æ¨¡æ“¬æ¨¡å¼ï¼‰"""
        check_interval = 10
        waited = 0
        
        while True:
            job_info = self.get_job_status(job_id)
            if not job_info:
                return 'FAILED'
            
            status_upper = str(job_info['status']).upper()
            completed_upper = [s.upper() for s in self.COMPLETED_STATUS]
            error_upper = [s.upper() for s in self.ERROR_STATUS]
            
            if status_upper in completed_upper:
                return 'SUCCESS'
            elif status_upper in error_upper:
                return 'FAILED'
            
            if timeout and waited >= timeout:
                return 'FAILED'
            
            time.sleep(check_interval)
            waited += check_interval


# å–®ä¾‹æ¨¡å¼å¯¦ä¾‹
_job_monitor_instance = None

def get_job_monitor(qaihub_client=None) -> JobMonitor:
    """
    å–å¾—ä»»å‹™ç›£æ§å™¨å¯¦ä¾‹ï¼ˆå–®ä¾‹æ¨¡å¼ï¼‰
    
    Args:
        qaihub_client: QAIHubClient å¯¦ä¾‹ï¼ˆå¯é¸ï¼‰
        
    Returns:
        JobMonitor å¯¦ä¾‹
    """
    global _job_monitor_instance
    if _job_monitor_instance is None:
        if qaihub_client:
            _job_monitor_instance = QAIHubJobMonitor(qaihub_client)
        else:
            _job_monitor_instance = JobMonitor()
    return _job_monitor_instance
