"""
æ¨¡å‹é è™•ç†æ¨¡çµ„ - è² è²¬æ¨¡å‹çš„è‡ªå‹•è½‰æ›å’Œç§»å‹•
æ ¹æ“šç›®æ¨™è£ç½®æ”¯æ´æƒ…æ³ï¼Œè‡ªå‹•å°‡ raw ç›®éŒ„ä¸­çš„æ¨¡å‹è½‰æ›ä¸¦ç§»å‹•åˆ° onnx ç›®éŒ„
"""
import os
import shutil
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dotenv import load_dotenv

from .scanner import ModelScanner
from .conversion import ModelConverter
from .advanced_conversion import AdvancedModelConverter, get_advanced_converter
from .qaihub_client import QAIHubClient

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

MODEL_SOURCE_DIR = os.getenv('MODEL_SOURCE_DIR', 'raw')  # åŸå§‹æ¨¡å‹ç›®éŒ„åç¨±
ONNX_MODEL_DIR = os.getenv('ONNX_MODEL_DIR', 'onnx')  # ONNX æ¨¡å‹ç›®éŒ„åç¨±
ENABLE_PREPROCESSING = os.getenv('ENABLE_PREPROCESSING', 'true').lower() == 'true'
AUTO_CONVERT_TFLITE = os.getenv('AUTO_CONVERT_TFLITE', 'true').lower() == 'true'


class ModelPreprocessor:
    """æ¨¡å‹é è™•ç†å™¨"""
    
    def __init__(self, base_dir: Optional[Path] = None):
        """
        åˆå§‹åŒ–æ¨¡å‹é è™•ç†å™¨
        
        Args:
            base_dir: åŸºç¤ç›®éŒ„è·¯å¾‘
        """
        if base_dir is None:
            base_dir = Path(__file__).parent.parent.parent / 'models'
        self.base_dir = base_dir
        self.scanner = ModelScanner(base_dir)
        self.converter = ModelConverter()
        self.advanced_converter = get_advanced_converter()
        self.qaihub_client = QAIHubClient(base_dir)
    
    def check_device_support(self) -> Dict[str, bool]:
        """
        æª¢æŸ¥è£ç½®æ”¯æ´çš„æ ¼å¼
        
        Returns:
            æ”¯æ´çš„æ¡†æ¶æ ¼å¼å­—å…¸
        """
        return self.qaihub_client.check_device_support()
    
    def scan_raw_models(self) -> Dict[str, List[Path]]:
        """
        æƒæ raw ç›®éŒ„ä¸­çš„æ¨¡å‹æª”æ¡ˆ
        
        Returns:
            åŒ…å«å„ç¨®æ ¼å¼æ¨¡å‹æª”æ¡ˆçš„å­—å…¸
        """
        return self.scanner.scan_model_directory(MODEL_SOURCE_DIR)
    
    def scan_onnx_models(self) -> Dict[str, List[Path]]:
        """
        æƒæ onnx ç›®éŒ„ä¸­çš„æ¨¡å‹æª”æ¡ˆ
        
        Returns:
            åŒ…å«å„ç¨®æ ¼å¼æ¨¡å‹æª”æ¡ˆçš„å­—å…¸
        """
        return self.scanner.scan_model_directory(ONNX_MODEL_DIR)
    
    def move_supported_models(self, models: Dict[str, List[Path]], support_info: Dict[str, bool]) -> Tuple[List[Path], List[Path]]:
        """
        ç§»å‹•è£ç½®æ”¯æ´çš„æ¨¡å‹åˆ° onnx ç›®éŒ„
        
        Args:
            models: æ¨¡å‹æª”æ¡ˆå­—å…¸
            support_info: è£ç½®æ”¯æ´è³‡è¨Š
            
        Returns:
            (æˆåŠŸç§»å‹•çš„æª”æ¡ˆåˆ—è¡¨, å¤±æ•—çš„æª”æ¡ˆåˆ—è¡¨)
        """
        if not ENABLE_PREPROCESSING:
            return [], []
        
        onnx_dir = self.base_dir / ONNX_MODEL_DIR
        onnx_dir.mkdir(parents=True, exist_ok=True)
        
        moved_files = []
        failed_files = []
        
        # ç§»å‹•æ‰€æœ‰æ”¯æ´çš„ ONNX æª”æ¡ˆ
        if support_info.get('onnx', False) and models.get('onnx'):
            for onnx_path in models['onnx']:
                try:
                    dest_path = onnx_dir / onnx_path.name
                    if not dest_path.exists():
                        shutil.move(str(onnx_path), str(dest_path))
                        moved_files.append(dest_path)
                        print(f"âœ… ç§»å‹• ONNX æª”æ¡ˆ: {onnx_path.name} -> {ONNX_MODEL_DIR}/")
                    else:
                        print(f"â­ï¸ ONNX æª”æ¡ˆå·²å­˜åœ¨ï¼Œè·³éç§»å‹•: {onnx_path.name}")
                except Exception as e:
                    print(f"âŒ ç§»å‹• ONNX æª”æ¡ˆå¤±æ•— {onnx_path.name}: {e}")
                    failed_files.append(onnx_path)
        
        # ç§»å‹•æ‰€æœ‰æ”¯æ´çš„ DLC æª”æ¡ˆ
        if support_info.get('dlc', False) and models.get('dlc'):
            for dlc_path in models['dlc']:
                try:
                    dest_path = onnx_dir / dlc_path.name
                    if not dest_path.exists():
                        shutil.move(str(dlc_path), str(dest_path))
                        moved_files.append(dest_path)
                        print(f"âœ… ç§»å‹• DLC æª”æ¡ˆ: {dlc_path.name} -> {ONNX_MODEL_DIR}/")
                    else:
                        print(f"â­ï¸ DLC æª”æ¡ˆå·²å­˜åœ¨ï¼Œè·³éç§»å‹•: {dlc_path.name}")
                except Exception as e:
                    print(f"âŒ ç§»å‹• DLC æª”æ¡ˆå¤±æ•— {dlc_path.name}: {e}")
                    failed_files.append(dlc_path)
        
        return moved_files, failed_files
    
    def convert_and_move_tflite(self, tflite_files: List[Path], support_info: Dict[str, bool]) -> Tuple[List[Path], List[Path]]:
        """
        è½‰æ›ä¸¦ç§»å‹• TFLite æ¨¡å‹åˆ° onnx ç›®éŒ„
        
        Args:
            tflite_files: TFLite æª”æ¡ˆåˆ—è¡¨
            support_info: è£ç½®æ”¯æ´è³‡è¨Š
            
        Returns:
            (æˆåŠŸè½‰æ›çš„æª”æ¡ˆåˆ—è¡¨, å¤±æ•—çš„æª”æ¡ˆåˆ—è¡¨)
        """
        if not ENABLE_PREPROCESSING or not AUTO_CONVERT_TFLITE:
            return [], []
        
        converted_files = []
        failed_files = []
        onnx_dir = self.base_dir / ONNX_MODEL_DIR
        
        # å¦‚æœè£ç½®æ”¯æ´ TFLiteï¼Œç›´æ¥ç§»å‹•
        if support_info.get('tflite', False):
            for tflite_path in tflite_files:
                try:
                    dest_path = onnx_dir / tflite_path.name
                    if not dest_path.exists():
                        shutil.move(str(tflite_path), str(dest_path))
                        converted_files.append(dest_path)
                        print(f"âœ… ç§»å‹• TFLite æª”æ¡ˆ: {tflite_path.name} -> {ONNX_MODEL_DIR}/")
                    else:
                        print(f"â­ï¸ TFLite æª”æ¡ˆå·²å­˜åœ¨ï¼Œè·³éç§»å‹•: {tflite_path.name}")
                except Exception as e:
                    print(f"âŒ ç§»å‹• TFLite æª”æ¡ˆå¤±æ•— {tflite_path.name}: {e}")
                    failed_files.append(tflite_path)
        else:
            # å¦‚æœè£ç½®ä¸æ”¯æ´ TFLiteï¼Œè½‰æ›ç‚º ONNX
            for tflite_path in tflite_files:
                onnx_path = onnx_dir / f"{tflite_path.stem}.onnx"
                
                # æª¢æŸ¥ ONNX æª”æ¡ˆæ˜¯å¦å·²ç¶“å­˜åœ¨
                if onnx_path.exists():
                    print(f"â­ï¸ ONNX æª”æ¡ˆå·²å­˜åœ¨ï¼Œè·³éè½‰æ›: {tflite_path.name} -> {onnx_path.name}")
                    converted_files.append(onnx_path)
                    continue
                    
                print(f"ğŸ”„ è½‰æ› TFLite åˆ° ONNX: {tflite_path.name}")
                
                # ä½¿ç”¨é€²éšè½‰æ›å™¨é€²è¡Œè½‰æ›
                result = self.advanced_converter.convert_tflite_to_onnx_fixed(tflite_path, onnx_dir)
                
                if result["status"] == "ok":
                    converted_files.append(result["onnx_path"])
                    print(f"âœ… è½‰æ›æˆåŠŸ: {tflite_path.name} -> {result['onnx_path'].name}")
                elif result["status"] == "warning":
                    converted_files.append(result["onnx_path"])
                    print(f"âš ï¸  è½‰æ›å®Œæˆä½†æœ‰è­¦å‘Š: {tflite_path.name} - {result['message']}")
                else:
                    failed_files.append(tflite_path)
                    print(f"âŒ è½‰æ›å¤±æ•—: {tflite_path.name} - {result['message']}")
        
        return converted_files, failed_files
    
    def preprocess_models(self) -> Dict[str, List[Path]]:
        """
        åŸ·è¡Œæ¨¡å‹é è™•ç†æµç¨‹
        
        Returns:
            é è™•ç†çµæœå­—å…¸
        """
        if not ENABLE_PREPROCESSING:
            print("â„¹ï¸ æ¨¡å‹é è™•ç†å·²ç¦ç”¨ï¼Œè·³éé è™•ç†æµç¨‹")
            return {}
        
        print("ğŸ”§ é–‹å§‹æ¨¡å‹é è™•ç†æµç¨‹...")
        
        # æª¢æŸ¥è£ç½®æ”¯æ´
        support_info = self.check_device_support()
        print(f"ğŸ“‹ è£ç½®æ”¯æ´æ ¼å¼:")
        for framework, supported in support_info.items():
            status = "âœ…" if supported else "âŒ"
            print(f"   {status} {framework.upper()}: {'æ”¯æ´' if supported else 'ä¸æ”¯æ´'}")
        
        # æƒæ raw ç›®éŒ„
        raw_models = self.scan_raw_models()
        print(f"ğŸ“ åœ¨ {MODEL_SOURCE_DIR} ç›®éŒ„ä¸­æ‰¾åˆ° {sum(len(files) for files in raw_models.values())} å€‹æ¨¡å‹æª”æ¡ˆ")
        
        # ç§»å‹•æ”¯æ´çš„æ¨¡å‹
        moved_files, move_failed = self.move_supported_models(raw_models, support_info)
        
        # è½‰æ›å’Œç§»å‹• TFLite æ¨¡å‹
        converted_files, convert_failed = self.convert_and_move_tflite(raw_models.get('tflite', []), support_info)
        
        # æƒæè™•ç†å¾Œçš„ onnx ç›®éŒ„
        processed_models = self.scan_onnx_models()
        
        # çµ±è¨ˆçµæœ
        total_processed = len(moved_files) + len(converted_files)
        total_failed = len(move_failed) + len(convert_failed)
        
        print(f"\nğŸ“Š é è™•ç†å®Œæˆ:")
        print(f"   âœ… æˆåŠŸè™•ç†: {total_processed} å€‹æª”æ¡ˆ")
        print(f"   âŒ è™•ç†å¤±æ•—: {total_failed} å€‹æª”æ¡ˆ")
        print(f"   ğŸ“ ç¾åœ¨ {ONNX_MODEL_DIR} ç›®éŒ„ä¸­æœ‰ {sum(len(files) for files in processed_models.values())} å€‹æ¨¡å‹æª”æ¡ˆ")
        
        return {
            'moved_files': moved_files,
            'converted_files': converted_files,
            'move_failed': move_failed,
            'convert_failed': convert_failed,
            'processed_models': processed_models,
            'device_support': support_info
        }
    
    def get_ready_models(self) -> Dict[str, List[Path]]:
        """
        å–å¾—æº–å‚™å¥½çš„æ¨¡å‹ï¼ˆä½æ–¼ onnx ç›®éŒ„ä¸­ï¼‰
        
        Returns:
            æº–å‚™å¥½çš„æ¨¡å‹å­—å…¸
        """
        return self.scan_onnx_models()


# å–®ä¾‹å¯¦ä¾‹
_model_preprocessor = None

def get_model_preprocessor(base_dir: Optional[Path] = None) -> ModelPreprocessor:
    """
    å–å¾—æ¨¡å‹é è™•ç†å™¨å¯¦ä¾‹ï¼ˆå–®ä¾‹æ¨¡å¼ï¼‰
    
    Args:
        base_dir: åŸºç¤ç›®éŒ„è·¯å¾‘
        
    Returns:
        ModelPreprocessor å¯¦ä¾‹
    """
    global _model_preprocessor
    if _model_preprocessor is None:
        _model_preprocessor = ModelPreprocessor(base_dir)
    return _model_preprocessor


def preprocess_models() -> Dict[str, List[Path]]:
    """
    å¿«é€ŸåŸ·è¡Œæ¨¡å‹é è™•ç†
    
    Returns:
        é è™•ç†çµæœå­—å…¸
    """
    preprocessor = get_model_preprocessor()
    return preprocessor.preprocess_models()


def get_ready_models() -> Dict[str, List[Path]]:
    """
    å¿«é€Ÿå–å¾—æº–å‚™å¥½çš„æ¨¡å‹
    
    Returns:
        æº–å‚™å¥½çš„æ¨¡å‹å­—å…¸
    """
    preprocessor = get_model_preprocessor()
    return preprocessor.get_ready_models()


if __name__ == "__main__":
    # æ¸¬è©¦ç¨‹å¼
    result = preprocess_models()
    print(f"\né è™•ç†çµæœ: {len(result.get('moved_files', []))} ç§»å‹•, {len(result.get('converted_files', []))} è½‰æ›")
    
    ready_models = get_ready_models()
    print(f"æº–å‚™å¥½çš„æ¨¡å‹: {sum(len(files) for files in ready_models.values())} å€‹æª”æ¡ˆ")
