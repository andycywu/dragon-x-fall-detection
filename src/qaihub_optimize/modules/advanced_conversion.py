"""
é€²éšæ¨¡å‹è½‰æ›æ¨¡çµ„ - è§£æ±º tflite2onnx è½‰æ›å•é¡Œ
æä¾›å¤šç¨®è½‰æ›æ–¹æ³•å’ŒéŒ¯èª¤è™•ç†
"""
import subprocess
import os
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import logging
import shutil
import re

logger = logging.getLogger(__name__)

class AdvancedModelConverter:
    """é€²éšæ¨¡å‹è½‰æ›å™¨ï¼Œæ”¯æ´å¤šç¨®è½‰æ›æ–¹æ³•å’ŒéŒ¯èª¤è™•ç†"""
    
    def __init__(self):
        self.conversion_timeout = 600
        self.supported_formats = ['tflite', 'onnx', 'pt']
    
    def find_executable(self, exe_name: str) -> Optional[str]:
        """å°‹æ‰¾å¯åŸ·è¡Œæª”"""
        # æª¢æŸ¥è™›æ“¬ç’°å¢ƒ
        venv_bin = Path(__file__).parent.parent / '.venv' / 'bin'
        candidate = venv_bin / exe_name
        if candidate.exists():
            return str(candidate)
        
        # æª¢æŸ¥ç³»çµ± PATH
        which = shutil.which(exe_name)
        if which:
            return which
        
        return None
    
    def check_tflite_model(self, tflite_path: Path) -> Dict:
        """æª¢æŸ¥ TFLite æ¨¡å‹æ˜¯å¦å¯è½‰æ›"""
        try:
            # é¦–å…ˆæª¢æŸ¥åŸºæœ¬æª”æ¡ˆå±¬æ€§
            if tflite_path.stat().st_size == 0:
                return {
                    "status": "error", 
                    "message": "æ¨¡å‹æª”æ¡ˆç‚ºç©º"
                }
            
            # æª¢æŸ¥æª”æ¡ˆé ­éƒ¨æ˜¯å¦ç‚º TFLite (æ›´å¯¬é¬†çš„æª¢æŸ¥)
            with open(tflite_path, 'rb') as f:
                header = f.read(8)  # è®€å–æ›´å¤šä½å…ƒçµ„ä»¥é©æ‡‰ä¸åŒç‰ˆæœ¬
                
            # TFLite æª”æ¡ˆé€šå¸¸ä»¥ç‰¹å®šçš„é­”è¡“æ•¸å­—é–‹é ­
            # ä½†ä¸åŒç‰ˆæœ¬å¯èƒ½æœ‰æ‰€ä¸åŒï¼Œæˆ‘å€‘ä½¿ç”¨æ›´å¯¬é¬†çš„æª¢æŸ¥
            if len(header) < 4:
                return {
                    "status": "error",
                    "message": "æª”æ¡ˆéçŸ­ï¼Œä¸æ˜¯æœ‰æ•ˆçš„ TFLite æª”æ¡ˆ"
                }
            
            # æª¢æŸ¥æª”æ¡ˆå¤§å°å’ŒåŸºæœ¬çµæ§‹
            file_size = tflite_path.stat().st_size
            if file_size < 100:  # TFLite æª”æ¡ˆé€šå¸¸è‡³å°‘å¹¾KB
                return {
                    "status": "warning",
                    "message": "æª”æ¡ˆå¤§å°ç•°å¸¸ï¼Œå¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„ TFLite æ¨¡å‹"
                }
            
            return {
                "status": "ok",
                "message": "åŸºæœ¬æª¢æŸ¥é€šéï¼ˆç„¡æ³•æ·±åº¦åˆ†æï¼‰",
                "file_size": file_size
            }
                
        except Exception as e:
            return {
                "status": "error",
                "message": f"æ¨¡å‹æª¢æŸ¥ç•°å¸¸: {str(e)}"
            }
    
    def convert_tflite_to_onnx_via_tf2onnx(self, tflite_path: Path, output_dir: Path) -> Dict:
        """ä½¿ç”¨ tf2onnx é€²è¡Œè½‰æ›ï¼ˆæ›¿ä»£æ–¹æ¡ˆï¼‰"""
        try:
            # éœ€è¦å…ˆå°‡ tflite è½‰æ›ç‚º saved_modelï¼Œç„¶å¾Œå†è½‰ç‚º onnx
            # é€™æ˜¯ä¸€å€‹è¤‡é›œçš„éç¨‹ï¼Œéœ€è¦ TensorFlow ç’°å¢ƒ
            temp_dir = output_dir / "temp_saved_model"
            temp_dir.mkdir(exist_ok=True)
            
            # é€™è£¡åªæ˜¯ç¤ºä¾‹ï¼Œå¯¦éš›éœ€è¦å®Œæ•´çš„è½‰æ›æµç¨‹
            result = subprocess.run([
                'python', '-c', 
                f'''
import tensorflow as tf
import tf2onnx
converter = tf.lite.TFLiteConverter.from_saved_model("{temp_dir}")
tflite_model = converter.convert()
                '''
            ], capture_output=True, text=True, timeout=self.conversion_timeout)
            
            if result.returncode == 0:
                onnx_path = output_dir / f"{tflite_path.stem}.onnx"
                return {
                    "status": "ok",
                    "message": "è½‰æ›æˆåŠŸ",
                    "onnx_path": onnx_path
                }
            else:
                return {
                    "status": "error",
                    "message": f"tf2onnx è½‰æ›å¤±æ•—: {result.stderr}"
                }
                
        except Exception as e:
            return {
                "status": "error",
                "message": f"tf2onnx è½‰æ›ç•°å¸¸: {str(e)}"
            }
    
    def convert_tflite_to_onnx_fixed(self, tflite_path: Path, output_dir: Path) -> Dict:
        """
        ä¿®å¾©çš„ TFLite åˆ° ONNX è½‰æ›æ–¹æ³•
        è§£æ±ºåƒæ•¸å‚³éå’ŒéŒ¯èª¤è™•ç†å•é¡Œ
        """
        if not tflite_path.exists():
            return {
                "status": "error",
                "message": f"TFLite æª”æ¡ˆä¸å­˜åœ¨: {tflite_path}",
                "onnx_path": None
            }
        
        if tflite_path.stat().st_size == 0:
            return {
                "status": "error",
                "message": f"TFLite æª”æ¡ˆç‚ºç©º: {tflite_path.name}",
                "onnx_path": None
            }
        
        output_dir.mkdir(parents=True, exist_ok=True)
        onnx_path = output_dir / f"{tflite_path.stem}.onnx"
        
        # æª¢æŸ¥ ONNX æª”æ¡ˆæ˜¯å¦å·²ç¶“å­˜åœ¨
        if onnx_path.exists():
            return {
                "status": "ok",
                "message": "ONNX æª”æ¡ˆå·²å­˜åœ¨ï¼Œè·³éè½‰æ›",
                "onnx_path": onnx_path
            }
        
        # å°‹æ‰¾ tflite2onnx å¯åŸ·è¡Œæª”
        tflite2onnx_exec = self.find_executable('tflite2onnx')
        if not tflite2onnx_exec:
            return {
                "status": "error",
                "message": "æ‰¾ä¸åˆ° tflite2onnx å¯åŸ·è¡Œæª”ï¼Œè«‹å®‰è£æˆ–æ·»åŠ åˆ° PATH",
                "onnx_path": None
            }
        
        try:
            # æ­£ç¢ºçš„åƒæ•¸æ ¼å¼ï¼štflite2onnx input.tflite output.onnx
            result = subprocess.run(
                [tflite2onnx_exec, str(tflite_path), str(onnx_path)],
                capture_output=True,
                text=True,
                timeout=self.conversion_timeout
            )

            if result.returncode == 0 and onnx_path.exists():
                # æª¢æŸ¥è½‰æ›å¾Œçš„ ONNX æª”æ¡ˆæ˜¯å¦æœ‰æ•ˆ
                try:
                    import onnx
                    model = onnx.load(onnx_path)
                    onnx.checker.check_model(model)
                    
                    return {
                        "status": "ok",
                        "message": "è½‰æ›æˆåŠŸ",
                        "onnx_path": onnx_path,
                        "stdout": result.stdout,
                        "stderr": result.stderr
                    }
                except Exception as e:
                    return {
                        "status": "warning",
                        "message": f"è½‰æ›å®Œæˆä½† ONNX æª”æ¡ˆæª¢æŸ¥å¤±æ•—: {str(e)}",
                        "onnx_path": onnx_path,
                        "stdout": result.stdout,
                        "stderr": result.stderr
                    }
            else:
                # åˆ†æéŒ¯èª¤è¨Šæ¯
                error_output = result.stderr or result.stdout
                error_message = self.analyze_conversion_error(error_output, tflite_path.name)
                
                return {
                    "status": "error",
                    "message": error_message,
                    "onnx_path": None,
                    "stdout": result.stdout,
                    "stderr": result.stderr
                }

        except subprocess.TimeoutExpired:
            return {
                "status": "error",
                "message": f"è½‰æ›è¶…æ™‚ ({self.conversion_timeout}ç§’)",
                "onnx_path": None
            }
        except Exception as e:
            return {
                "status": "error",
                "message": f"è½‰æ›ç•°å¸¸: {str(e)}",
                "onnx_path": None
            }
    
    def analyze_conversion_error(self, error_output: str, model_name: str) -> str:
        """åˆ†æè½‰æ›éŒ¯èª¤ä¸¦æä¾›å‹å¥½çš„éŒ¯èª¤è¨Šæ¯"""
        error_output_lower = error_output.lower()
        
        if 'float16' in error_output_lower:
            return f"æ¨¡å‹ {model_name} åŒ…å« float16 è³‡æ–™é¡å‹ï¼Œtflite2onnx ä¸æ”¯æ´ã€‚å»ºè­°ï¼šä½¿ç”¨ TensorFlow å°‡æ¨¡å‹è½‰æ›ç‚º float32 æ ¼å¼å¾Œå†åŒ¯å‡ºç‚º TFLiteã€‚"
        
        if 'densify' in error_output_lower:
            return f"æ¨¡å‹ {model_name} åŒ…å« DENSIFY æ“ä½œï¼Œtflite2onnx ä¸æ”¯æ´æ­¤æ“ä½œã€‚å»ºè­°ï¼šä½¿ç”¨ tf2onnx æˆ–å…¶ä»–è½‰æ›å·¥å…·ï¼Œæˆ–åœ¨æ¨¡å‹åŒ¯å‡ºæ™‚é¿å…ä½¿ç”¨æ­¤æ“ä½œã€‚"
        
        if 'indexerror' in error_output_lower or 'index out of range' in error_output_lower:
            return f"æ¨¡å‹ {model_name} è½‰æ›æ™‚ç™¼ç”Ÿç´¢å¼•éŒ¯èª¤ï¼Œå¯èƒ½æ˜¯æ¨¡å‹æ ¼å¼å•é¡Œã€‚å»ºè­°ï¼šæª¢æŸ¥æ¨¡å‹æ˜¯å¦å®Œæ•´ä¸”æœ‰æ•ˆã€‚"
        
        if 'typeerror' in error_output_lower or 'has no len' in error_output_lower:
            return f"æ¨¡å‹ {model_name} è½‰æ›æ™‚ç™¼ç”Ÿé¡å‹éŒ¯èª¤ï¼Œå¯èƒ½æ˜¯ tflite2onnx ç‰ˆæœ¬ä¸ç›¸å®¹ã€‚å»ºè­°ï¼šæ›´æ–° tflite2onnx æˆ–å˜—è©¦å…¶ä»–ç‰ˆæœ¬ã€‚"
        
        if 'unrecognized arguments' in error_output_lower:
            return f"åƒæ•¸æ ¼å¼éŒ¯èª¤ï¼Œè«‹ä½¿ç”¨æ­£ç¢ºçš„ tflite2onnx å‘½ä»¤æ ¼å¼: tflite2onnx input.tflite output.onnx"
        
        # é€šç”¨éŒ¯èª¤è¨Šæ¯
        return f"è½‰æ›å¤±æ•—: {error_output[:200]}..." if len(error_output) > 200 else f"è½‰æ›å¤±æ•—: {error_output}"
    
    def batch_convert_with_fallback(self, tflite_files: List[Path], output_dir: Path) -> Tuple[List[Dict], List[Path]]:
        """
        æ‰¹æ¬¡è½‰æ›ä¸¦æä¾›å‚™ç”¨æ–¹æ¡ˆ
        
        Returns:
            (æˆåŠŸçµæœåˆ—è¡¨, å¤±æ•—æª”æ¡ˆåˆ—è¡¨)
        """
        successful_results = []
        failed_files = []
        
        for tflite_path in tflite_files:
            print(f"ğŸ”„ è™•ç† {tflite_path.name}...")
            
            # é¦–å…ˆæª¢æŸ¥æ¨¡å‹
            check_result = self.check_tflite_model(tflite_path)
            if check_result["status"] == "error":
                print(f"âŒ æ¨¡å‹æª¢æŸ¥å¤±æ•—: {check_result['message']}")
                failed_files.append(tflite_path)
                continue
            
            # å˜—è©¦æ¨™æº–è½‰æ›
            result = self.convert_tflite_to_onnx_fixed(tflite_path, output_dir)
            
            if result["status"] == "ok":
                successful_results.append(result)
                print(f"âœ… è½‰æ›æˆåŠŸ: {tflite_path.name}")
            else:
                print(f"âŒ æ¨™æº–è½‰æ›å¤±æ•—: {result['message']}")
                
                # å¦‚æœæ¨™æº–è½‰æ›å¤±æ•—ï¼Œå˜—è©¦å‚™ç”¨æ–¹æ¡ˆ
                print(f"ğŸ”„ å˜—è©¦å‚™ç”¨è½‰æ›æ–¹æ¡ˆ...")
                fallback_result = self.convert_tflite_to_onnx_via_tf2onnx(tflite_path, output_dir)
                
                if fallback_result["status"] == "ok":
                    successful_results.append(fallback_result)
                    print(f"âœ… å‚™ç”¨è½‰æ›æˆåŠŸ: {tflite_path.name}")
                else:
                    failed_files.append(tflite_path)
                    print(f"âŒ æ‰€æœ‰è½‰æ›æ–¹æ³•éƒ½å¤±æ•—: {tflite_path.name}")
        
        return successful_results, failed_files
    
    def generate_conversion_report(self, results: List[Dict], failed_files: List[Path]) -> str:
        """ç”Ÿæˆè½‰æ›å ±å‘Š"""
        report = [
            "ğŸ“Š æ¨¡å‹è½‰æ›å ±å‘Š",
            "=" * 50,
            f"âœ… æˆåŠŸè½‰æ›: {len(results)} å€‹æª”æ¡ˆ",
            f"âŒ è½‰æ›å¤±æ•—: {len(failed_files)} å€‹æª”æ¡ˆ",
            "",
            "æˆåŠŸè½‰æ›çš„æª”æ¡ˆ:"
        ]
        
        for result in results:
            if result["status"] == "ok":
                report.append(f"  - {result['onnx_path'].name if result.get('onnx_path') else 'æœªçŸ¥'}")
        
        if failed_files:
            report.extend(["", "å¤±æ•—çš„æª”æ¡ˆ:"])
            for failed_file in failed_files:
                report.append(f"  - {failed_file.name}")
        
        return "\n".join(report)


# å–®ä¾‹å¯¦ä¾‹
_advanced_converter = None

def get_advanced_converter() -> AdvancedModelConverter:
    """å–å¾—é€²éšè½‰æ›å™¨å¯¦ä¾‹"""
    global _advanced_converter
    if _advanced_converter is None:
        _advanced_converter = AdvancedModelConverter()
    return _advanced_converter


def advanced_convert_tflite_files(tflite_files: List[Path], output_dir: Path) -> Tuple[List[Dict], List[Path]]:
    """å¿«é€Ÿé€²éšè½‰æ›"""
    converter = get_advanced_converter()
    return converter.batch_convert_with_fallback(tflite_files, output_dir)


if __name__ == "__main__":
    # æ¸¬è©¦ç¨‹å¼
    converter = AdvancedModelConverter()
    test_tflite = Path("/Users/andycyw/mvp_fall_detection_starter/src/models/raw/face_detector.tflite")
    test_output = Path("/Users/andycyw/mvp_fall_detection_starter/src/models/onnx")
    
    if test_tflite.exists():
        result = converter.convert_tflite_to_onnx_fixed(test_tflite, test_output)
        print(f"è½‰æ›çµæœ: {result}")
    else:
        print("æ¸¬è©¦æª”æ¡ˆä¸å­˜åœ¨")
