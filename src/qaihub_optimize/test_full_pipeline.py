"""
æ¸¬è©¦å®Œæ•´å·¥ä½œæµç¨‹
é©—è­‰å¾æ¨¡å‹æƒæåˆ°å„ªåŒ–æ¨¡å‹ä¸‹è¼‰çš„å®Œæ•´æµç¨‹
"""
import sys
import os
import time
from pathlib import Path

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.qaihub_optimize.modules.pipeline import get_pipeline


def test_full_pipeline():
    """æ¸¬è©¦å®Œæ•´å·¥ä½œæµç¨‹"""
    print("=" * 60)
    print("ğŸš€ æ¸¬è©¦å®Œæ•´ QAI Hub å·¥ä½œæµç¨‹")
    print("=" * 60)
    
    try:
        # å‰µå»º pipeline å¯¦ä¾‹
        pipeline = get_pipeline()
        
        print("ğŸ“‹ æ¸¬è©¦æ­¥é©Ÿ:")
        print("1. æƒææ¨¡å‹æª”æ¡ˆ")
        print("2. æª¢æŸ¥æ¨¡å‹æ ¼å¼")
        print("3. æäº¤ç·¨è­¯ä»»å‹™")
        print("4. ç›£æ§ä»»å‹™ç‹€æ…‹ï¼ˆå¯¦æ™‚é¡¯ç¤ºï¼‰")
        print("5. è™•ç†éŒ¯èª¤ï¼ˆå¦‚æœæœ‰ï¼‰")
        print("6. ä¸‹è¼‰å„ªåŒ–æ¨¡å‹")
        print("7. é©—è­‰æ¨¡å‹ä¿å­˜ä½ç½®")
        
        print("\n" + "-" * 40)
        print("1ï¸âƒ£ æƒææ¨¡å‹æª”æ¡ˆ...")
        
        # æƒææ¨¡å‹
        models = pipeline.scan_models()
        if not models:
            print("âŒ æ²’æœ‰æ‰¾åˆ°æ¨¡å‹æª”æ¡ˆ")
            return False
        
        print(f"âœ… æ‰¾åˆ° {sum(len(files) for files in models.values())} å€‹æ¨¡å‹æª”æ¡ˆ")
        for ext, files in models.items():
            print(f"   - {ext.upper()}: {len(files)} å€‹")
        
        print("\n" + "-" * 40)
        print("2ï¸âƒ£ æª¢æŸ¥è£ç½®æ”¯æ´å’Œæ¨¡å‹æ ¼å¼...")
        
        # æª¢æŸ¥è£ç½®æ”¯æ´
        support_info = pipeline.qaihub_client.check_device_support()
        print("ğŸ“‹ è£ç½®æ”¯æ´æ ¼å¼:")
        for framework, supported in support_info.items():
            status = "âœ…" if supported else "âŒ"
            print(f"   {status} {framework.upper()}: {'æ”¯æ´' if supported else 'ä¸æ”¯æ´'}")
        
        # æ ¹æ“šè£ç½®æ”¯æ´æ±ºå®šä½¿ç”¨å“ªç¨®æ ¼å¼
        source_format = 'onnx' if support_info.get('onnx', False) else 'tflite'
        print(f"ğŸ“ å°‡ä½¿ç”¨ {source_format.upper()} æ ¼å¼é€²è¡Œç·¨è­¯")
        
        print("\n" + "-" * 40)
        print("3ï¸âƒ£ åŸ·è¡Œç·¨è­¯å·¥ä½œæµç¨‹...")
        print("âš ï¸  æ³¨æ„ï¼šé€™å°‡å¯¦éš›æäº¤ä»»å‹™åˆ° QAI Hubï¼Œå¯èƒ½éœ€è¦ä¸€äº›æ™‚é–“")
        print("ğŸ’¡ æ‚¨å¯ä»¥è§€å¯Ÿå¯¦æ™‚ç‹€æ…‹æ›´æ–°å’Œé€²åº¦é¡¯ç¤º")
        
        # åŸ·è¡Œç·¨è­¯æµç¨‹
        success = pipeline.run_compile_pipeline(source_format)
        
        print("\n" + "-" * 40)
        print("4ï¸âƒ£ æª¢æŸ¥ç·¨è­¯çµæœå’Œå„ªåŒ–æ¨¡å‹...")
        
        if success:
            print("âœ… ç·¨è­¯æµç¨‹æˆåŠŸå®Œæˆï¼")
            
            # æª¢æŸ¥å„ªåŒ–æ¨¡å‹ä¸‹è¼‰ç‹€æ…‹
            downloaded_models = []
            for model_name, model_info in pipeline.qaihub_client.qai_hub_models.items():
                if model_info.get('optimized_model_downloaded', False):
                    downloaded_models.append({
                        'name': model_name,
                        'path': model_info.get('optimized_model_path', 'æœªçŸ¥')
                    })
            
            if downloaded_models:
                print(f"ğŸ’¾ æˆåŠŸä¸‹è¼‰ {len(downloaded_models)} å€‹å„ªåŒ–æ¨¡å‹:")
                for model in downloaded_models:
                    print(f"   - {model['name']} -> {model['path']}")
                    
                    # é©—è­‰æª”æ¡ˆç¢ºå¯¦å­˜åœ¨
                    model_path = Path(model['path'])
                    if model_path.exists():
                        print(f"     âœ… æª”æ¡ˆå­˜åœ¨ï¼Œå¤§å°: {model_path.stat().st_size} bytes")
                    else:
                        print(f"     âŒ æª”æ¡ˆä¸å­˜åœ¨ï¼")
            else:
                print("âš ï¸  æ²’æœ‰ä¸‹è¼‰å„ªåŒ–æ¨¡å‹")
                
        else:
            print("âŒ ç·¨è­¯æµç¨‹å¤±æ•—")
            
            # é¡¯ç¤ºè©³ç´°éŒ¯èª¤ä¿¡æ¯
            failed_jobs = []
            for model_name, model_info in pipeline.qaihub_client.qai_hub_models.items():
                compile_job = model_info.get('compile_job')
                if compile_job and hasattr(compile_job, 'status'):
                    status = getattr(compile_job.status, 'code', str(compile_job.status))
                    if str(status).upper() in ['FAILED', 'ERROR']:
                        error_msg = getattr(compile_job.status, 'error', 'æœªçŸ¥éŒ¯èª¤')
                        failed_jobs.append({
                            'name': model_name,
                            'status': status,
                            'error': error_msg
                        })
            
            if failed_jobs:
                print(f"âŒ å¤±æ•—çš„ä»»å‹™ ({len(failed_jobs)} å€‹):")
                for job in failed_jobs:
                    print(f"   - {job['name']}: {job['status']} - {job['error']}")
        
        print("\n" + "-" * 40)
        print("5ï¸âƒ£ é©—è­‰å„ªåŒ–æ¨¡å‹ç›®éŒ„çµæ§‹...")
        
        # æª¢æŸ¥å„ªåŒ–æ¨¡å‹ç›®éŒ„
        optimized_dir = project_root / 'src' / 'models' / 'qaihub_optimized'
        print(f"ğŸ“ å„ªåŒ–æ¨¡å‹ç›®éŒ„: {optimized_dir}")
        print(f"ğŸ“ ç›®éŒ„æ˜¯å¦å­˜åœ¨: {optimized_dir.exists()}")
        
        if optimized_dir.exists():
            optimized_files = list(optimized_dir.glob('*'))
            print(f"ğŸ“Š ç›®éŒ„ä¸­çš„æª”æ¡ˆæ•¸é‡: {len(optimized_files)}")
            
            for file in optimized_files:
                if file.is_file():
                    print(f"   - {file.name} ({file.stat().st_size} bytes)")
        
        print("\n" + "-" * 40)
        print("6ï¸âƒ£ æ¸…ç†é‡è¤‡çš„ç›®éŒ„çµæ§‹...")
        
        # æª¢æŸ¥ä¸¦æ¸…ç†å¯èƒ½çš„é‡è¤‡ç›®éŒ„
        duplicate_dirs = [
            project_root / 'src' / 'models' / 'models' / 'qaihub_optimized',
            project_root / 'src' / 'models' / 'qaihub_optimized',
            project_root / 'src' / 'qaihub_optimized'
        ]
        
        for dir_path in duplicate_dirs:
            if dir_path.exists() and dir_path != optimized_dir:
                print(f"ğŸ—‘ï¸  ç™¼ç¾é‡è¤‡ç›®éŒ„: {dir_path}")
                # é€™è£¡å¯ä»¥æ·»åŠ æ¸…ç†é‚è¼¯ï¼Œä½†ç‚ºäº†å®‰å…¨å…ˆåªé¡¯ç¤ºä¿¡æ¯
        
        print("\n" + "=" * 60)
        if success:
            print("ğŸ‰ å®Œæ•´å·¥ä½œæµç¨‹æ¸¬è©¦æˆåŠŸå®Œæˆï¼")
            print("âœ… å¯¦æ™‚ç‹€æ…‹é¡¯ç¤ºæ­£å¸¸")
            print("âœ… éŒ¯èª¤è™•ç†åŠŸèƒ½æ­£å¸¸")
            print("âœ… å„ªåŒ–æ¨¡å‹ä¸‹è¼‰æ­£å¸¸")
        else:
            print("âš ï¸  å·¥ä½œæµç¨‹æ¸¬è©¦å®Œæˆï¼Œä½†æœ‰ä»»å‹™å¤±æ•—")
            print("ğŸ’¡ è«‹æª¢æŸ¥éŒ¯èª¤ä¿¡æ¯ä¸¦èª¿æ•´æ¨¡å‹æˆ–é…ç½®")
        
        return success
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_small_workflow():
    """æ¸¬è©¦å°å‹å·¥ä½œæµç¨‹ï¼ˆåªè™•ç†1-2å€‹æ¨¡å‹ï¼‰"""
    print("\n" + "=" * 60)
    print("ğŸ§ª æ¸¬è©¦å°å‹å·¥ä½œæµç¨‹ï¼ˆåªè™•ç†1å€‹æ¨¡å‹ï¼‰")
    print("=" * 60)
    
    try:
        pipeline = get_pipeline()
        
        # æƒææ¨¡å‹
        models = pipeline.scan_models()
        if not models:
            print("âŒ æ²’æœ‰æ‰¾åˆ°æ¨¡å‹æª”æ¡ˆ")
            return False
        
        # åªé¸æ“‡ç¬¬ä¸€å€‹æ¨¡å‹é€²è¡Œæ¸¬è©¦
        test_model = None
        for ext, files in models.items():
            if files:
                test_model = files[0]
                break
        
        if not test_model:
            print("âŒ æ²’æœ‰å¯ç”¨çš„æ¨¡å‹æª”æ¡ˆ")
            return False
        
        print(f"ğŸ” é¸æ“‡æ¸¬è©¦æ¨¡å‹: {test_model.name}")
        
        # é€™è£¡å¯ä»¥å¯¦ç¾åªè™•ç†å–®ä¸€æ¨¡å‹çš„é‚è¼¯
        # ä½†ç”±æ–¼ pipeline è¨­è¨ˆæ˜¯è™•ç†æ‰€æœ‰æ¨¡å‹ï¼Œæˆ‘å€‘æš«æ™‚ä½¿ç”¨å®Œæ•´æµç¨‹
        
        print("âš ï¸  ç”±æ–¼æ¶æ§‹é™åˆ¶ï¼Œå°‡åŸ·è¡Œå®Œæ•´æµç¨‹ä½†åªç›£æ§é€²åº¦")
        print("ğŸ’¡ æ‚¨å¯ä»¥è§€å¯Ÿå¯¦æ™‚ç‹€æ…‹æ›´æ–°")
        
        return pipeline.run_compile_pipeline('tflite')
        
    except Exception as e:
        print(f"âŒ å°å‹å·¥ä½œæµç¨‹æ¸¬è©¦å¤±æ•—: {e}")
        return False


if __name__ == "__main__":
    print("ğŸ¤– QAI Hub å®Œæ•´å·¥ä½œæµç¨‹æ¸¬è©¦")
    print("ğŸ’¡ é€™å€‹æ¸¬è©¦å°‡å¯¦éš›é€£æ¥åˆ° QAI Hub ä¸¦æäº¤ç·¨è­¯ä»»å‹™")
    print("â° å¯èƒ½éœ€è¦ä¸€äº›æ™‚é–“å®Œæˆï¼Œè«‹è€å¿ƒç­‰å¾…")
    
    # è©¢å•ç”¨æˆ¶æ˜¯å¦è¦ç¹¼çºŒ
    response = input("\næ˜¯å¦è¦ç¹¼çºŒåŸ·è¡Œå®Œæ•´æ¸¬è©¦ï¼Ÿ(y/n): ").strip().lower()
    if response != 'y':
        print("â­ï¸ è·³éå®Œæ•´æ¸¬è©¦")
        # åŸ·è¡Œå°å‹æ¸¬è©¦ instead
        test_small_workflow()
    else:
        # åŸ·è¡Œå®Œæ•´æ¸¬è©¦
        test_full_pipeline()
